<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code R</title>
    <link>/en/</link>
    <description>Recent content on Code R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es-es</language>
    <lastBuildDate>Sun, 16 Apr 2023 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/en/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>11 tricks to level up your rmarkdown documents</title>
      <link>/en/2023/04/knitr-rmarkdown-tricks/</link>
      <pubDate>Sun, 16 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/en/2023/04/knitr-rmarkdown-tricks/</guid>
      <description>


&lt;p&gt;For a while I wanted to write a post to compile some of the tricks I’ve learnt over the years of using rmarkdown.
I also wanted other people’s input so &lt;a href=&#34;https://mastodon.social/@eliocamp/110192939201292092&#34;&gt;I asked for suggestions on Mastodon&lt;/a&gt;.
So here are the 12 tips I decided to include in no particular order.&lt;/p&gt;
&lt;div id=&#34;make-chunk-options-non-optional&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Make chunk options non-optional&lt;/h2&gt;
&lt;p&gt;I use this trick to force myself to write captions to all figures:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::opts_hooks$set(label = function(options) {
   if (is.null(options$fig.cap)) {
    stop(&amp;quot;Every figure has to have a caption!&amp;quot;)  
   }
   return(options)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This “&lt;a href=&#34;https://yihui.org/knitr/hooks/&#34;&gt;hook&lt;/a&gt;” runs once for each chunk in which &lt;code&gt;label&lt;/code&gt; is not &lt;code&gt;NULL&lt;/code&gt; –which is all of them– and throws an error if the &lt;code&gt;fig.cap&lt;/code&gt; option is &lt;code&gt;NULL&lt;/code&gt; (missing).
This will absolutely force your lazy ass to actually put captions in all your figures.&lt;/p&gt;
&lt;p&gt;Inspired by &lt;a href=&#34;https://fosstodon.org/@zkamvar/110188164791881811&#34;&gt;Zhian N Kamvar&lt;/a&gt; I’m now also using this to force myself to always name all my chunks:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::opts_hooks$set(label = function(options) {
  # Check if the label comes from the default label for unnamed chuncks
  default_label &amp;lt;- knitr::opts_knit$get(&amp;quot;unnamed.chunk.label&amp;quot;)
  has_default_label &amp;lt;- grepl(default_label, options$label)
  
  if (has_default_label) {
    stop(&amp;quot;Name your chunks!&amp;quot;)
  }
  return(options)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code can’t just check for &lt;code&gt;is.NULL(options$label)&lt;/code&gt; because unnamed chunks get default labels, so it gets the default label with &lt;code&gt;knitr::opts_knit$get(&#34;unnamed.chunk.label&#34;)&lt;/code&gt; and then checks if the name of the chunk is auto-generated.
This fails in the ridiculously edge case of manually-defined labels that contain the same text as the default label.&lt;/p&gt;
&lt;p&gt;You can use these principles to run all kinds of checks on your chunk options.
The only issue with this approach is that the knitting process ends when it finds the first “bad” instance.
It might be better to record all the offending chunks and their reasons and then throw a message or error at the end.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;captions-using-text-references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Captions using text references&lt;/h2&gt;
&lt;p&gt;Good captions tend to be long and they sometimes include complex strings like &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; notation or references to previous figures (e.g. “Same as Fig. 2 but for clowns with red noses.”).
These kinds of captions can be hard to parse visually as chunk options and need a lot of escaped characters if written as a string.
Bookdown offers &lt;a href=&#34;https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html#text-references&#34;&gt;text references&lt;/a&gt; as a solution.&lt;/p&gt;
&lt;p&gt;You can start a line of text with &lt;code&gt;(ref:label)&lt;/code&gt; and then use &lt;code&gt;(ref:label)&lt;/code&gt; to refer to it in your chunk options.
So you can write&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(ref:red-noses-cap) Same as Figure \@ref(fig:blue-noses) but for clowns with *red* noses. And this is a mathematical formula just as an example: $\pi=3$.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then write the chunk as&lt;/p&gt;
&lt;pre class=&#34;default&#34;&gt;&lt;code&gt;```{r, fig.cap = &amp;quot;(ref:red-noses-cap)&amp;quot;}
plot(red_noses)
```&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;default-caption&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Default caption&lt;/h2&gt;
&lt;p&gt;When using text references to define captions, I’ve found that it’s a bit annoying and redundant to explicitly set the &lt;code&gt;fig.cap&lt;/code&gt; option.
Instead I prefer to set up a default caption of the form &lt;code&gt;(ref:label-cap)&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::opts_hooks$set(label = function(options) {
  if (is.null(options$fig.cap)) {
    options$fig.cap &amp;lt;- paste0(&amp;quot;(ref:&amp;quot;, options$label, &amp;quot;-cap)&amp;quot;)
  }
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this, every chunk will have a default text-referenced caption with a predictable name.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;save-plots-in-multiple-formats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Save plots in multiple formats&lt;/h2&gt;
&lt;p&gt;Did you know that the &lt;code&gt;dev&lt;/code&gt; chunk option can be a vector of formats?
This enables you to save figures in multiple formats at once.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::opts_chunk$set(dev = c(&amp;#39;png&amp;#39;, &amp;#39;svg&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This simple but possibly overlook feature (suggested by &lt;a href=&#34;https://mastodon.social/@rmflight/110193102637427843&#34;&gt;Robert Flight&lt;/a&gt;) can be useful if you want to use vector graphics in your document but also need raster versions to share more easily with your colleges or online.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exit-prematurely&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exit prematurely&lt;/h2&gt;
&lt;p&gt;With long and complex documents sometimes come weird errors that are hard to pin down.
Or you might want to work on some early part of the document even if some later parts are unfinished and don’t knit.
Both &lt;a href=&#34;https://mastodon.social/@MickaelCanouil@fosstodon.org/110192950640461658&#34;&gt;Mickaël CANOUIL&lt;/a&gt; and &lt;a href=&#34;https://mastodon.social/@superboreen/110192967243702258&#34;&gt;superboreen&lt;/a&gt; pointed out that you can use &lt;code&gt;knitr::knit_exit()&lt;/code&gt; to end document rendering “before it gets to the hideous code I haven’t fixed yet”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::knit_exit()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;get-the-output-format&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get the output format&lt;/h2&gt;
&lt;p&gt;While the promise of rmarkdown is to have portable code that can be rendered into any document, but &lt;a href=&#34;https://en.wikipedia.org/wiki/Leaky_abstraction&#34;&gt;abstractions are leaky&lt;/a&gt; and this doesn’t always work out.
For example, I’ve found that there’s not a single table-generating package that does a good job of rendering decent-looking LaTeX, HTML and Word tables without changes in the code.
So sometimes the code needs to know to which document format it’s going to render.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;knitr::pandoc_to()&lt;/code&gt; returns the “final destination” of the document, which can be “latex”, “html” or “docx”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::pandoc_to()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can also return a logical indicating if the output format is the one specified in the argument.
This enables code that only runs for some formats and not others:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (knitr::pandoc_to(&amp;quot;docx&amp;quot;)) {
   # Something to do only if the output is docx
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Beware that &lt;code&gt;knitr::pandoc_to()&lt;/code&gt; will return &lt;code&gt;NULL&lt;/code&gt; when run interactively, so you might want to catch that case.&lt;/p&gt;
&lt;p&gt;Other similar functions are &lt;code&gt;is_latex_output()&lt;/code&gt; and &lt;code&gt;is_html_output()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;configure-cache-path&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Configure cache path&lt;/h2&gt;
&lt;p&gt;My documents often have some code that takes a while to run so I make liberal use of the cache feature.
But sometimes I like to control &lt;strong&gt;where&lt;/strong&gt; that cache is stored.
That can be done with &lt;code&gt;knitr::opts_chunk$set(cache.path = path)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This is a good solution when rendering to multiple formats, since changing the format seems to invalidate the cache and make it useless.
So what I do is set up one cache for each format:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;format &amp;lt;- knitr::pandoc_to()

knitr::opts_chunk$set(
  cache.path = file.path(&amp;quot;cache&amp;quot;, format, &amp;quot;&amp;quot;)  # The last &amp;quot;&amp;quot; is necessary
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;get-current-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get current file&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;knitr::current_input()&lt;/code&gt; returns the input file being rendered by knitr.
This can be useful in a bunch of cases, but I use it to, again, control cache and figure locations.&lt;/p&gt;
&lt;p&gt;On a bookdown document, I like each chapter to use its own folder for cache and figures, so I have this in my setup chunk:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;format &amp;lt;- knitr::pandoc_to() 
chapter &amp;lt;- tools::file_path_sans_ext(knitr::current_input())

knitr::opts_chunk$set(
  fig.path   = file.path(&amp;quot;figures&amp;quot;, chapter, &amp;quot;&amp;quot;),
  cache.path = file.path(&amp;quot;cache&amp;quot;, chapter, format, &amp;quot;&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;easily-invalidate-cache&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Easily invalidate cache&lt;/h2&gt;
&lt;p&gt;Speaking of cache, sometimes I want to run your document from scratch without the cache.
Either as a final test that all the code runs well, or when faced with strange bugs that I suspect might be cache-related.&lt;/p&gt;
&lt;p&gt;So I almost always set up a &lt;code&gt;cache.extra&lt;/code&gt; chunk option that will invalidate the cache each time it changes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::opts_chunk$set(cache.extra = 42)  # Change the number to invalidate cache&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;do-stuff-after-knitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Do stuff after knitting&lt;/h2&gt;
&lt;p&gt;Knitr runs the “document” hook after knitting.
You can customise that hook to do whatever you want:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First save the default hook to use later. 
knit_doc &amp;lt;- knitr::knit_hooks$get(&amp;quot;document&amp;quot;)

knitr::knit_hooks$set(document = function(x) {
   # So stufff
   knit_doc(x)  # Then do whatever knitr was going to do anyway
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, I sometimes like to add this so I get a desktop notification when my computer finishes knitting&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This needs the notify-send cli. 
# https://manpages.ubuntu.com/manpages/bionic/man1/notify-send.1.html
notify &amp;lt;- function(title = &amp;quot;title&amp;quot;, text = NULL, time = 2) {
   time &amp;lt;- time*1000
   system(paste0(&amp;#39;notify-send &amp;quot;&amp;#39;, title, &amp;#39;&amp;quot; &amp;quot;&amp;#39;, text, &amp;#39;&amp;quot; -t &amp;#39;, time, &amp;#39; -a rstudio&amp;#39;))
}


start_time &amp;lt;- unclass(Sys.time())
min_time &amp;lt;- 5*3600  # Only notify for long-running jobs (5 minutes)

knit_doc &amp;lt;- knitr::knit_hooks$get(&amp;quot;document&amp;quot;)
knitr::knit_hooks$set(document = function(x) {
   
   took &amp;lt;- unclass(Sys.time()) - start_time
   if (took &amp;gt;= min_time) {
      notify(&amp;quot;Done knitting!&amp;quot;, 
             paste0(&amp;quot;Took &amp;quot;, round(took), &amp;quot; seconds&amp;quot;),
             time = 5)
   }  
   
   
   knit_doc(x)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might use this to get notifications to your phone with &lt;a href=&#34;https://eddelbuettel.github.io/rpushbullet/&#34;&gt;RPushbullet&lt;/a&gt; or send emails with &lt;a href=&#34;https://datawookie.github.io/emayili/&#34;&gt;emayili&lt;/a&gt;.
You might also want to check the &lt;a href=&#34;https://github.com/gaborcsardi/notifier&#34;&gt;notifier&lt;/a&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scripts-to-and-from-rmarkdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scripts to and from RMarkdown&lt;/h2&gt;
&lt;p&gt;Finally, &lt;a href=&#34;https://mastodon.social/@katieontheridge@fosstodon.org/110194745010839834&#34;&gt;Katie&lt;/a&gt; highlighted the &lt;code&gt;knitr::spin()&lt;/code&gt; function, which turns specially formatted R scripts and turns them into RMarkdown documents.
And for the exact opposite workflow, &lt;a href=&#34;https://mastodon.social/@nxskok@mastodon.cloud/110194991404418910&#34;&gt;Ken Butler&lt;/a&gt; points out the &lt;code&gt;knitr::purl()&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Making data available with dataset functions</title>
      <link>/en/2023/02/dataset-functions/</link>
      <pubDate>Mon, 20 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/en/2023/02/dataset-functions/</guid>
      <description>


&lt;p&gt;An important part of a scientific project, such as a journal paper or a PhD thesis, is accessing datasets.
To keep things reproducible datasets should be accessible, either provided in the repository itself or in a remote location.
Also for reproducibility, it’s important to be able to check if the data you get is the same as the data you expect.&lt;/p&gt;
&lt;p&gt;I wanted to share my technique for downloading and accessing datasets that strives for maximum reproducibility and user-friendliness.&lt;/p&gt;
&lt;div id=&#34;the-short-version&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The short version&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;../images/data-cloud.png&#34; alt=&#34;A drawing of a cloud with mechanical bits, such as a pump and tubing.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Downloading data from “The Cloud” automatically.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Instead of having a specific script that downloads all the necessary data, I create a function for each dataset.
This function checks if the data exists and downloads it if needed.
To ensure data integrity, it hashes the file compares the checksum with an expected hash , warning the user if they don’t match.
Finally, it returns the location on disk of the file to be read.&lt;/p&gt;
&lt;p&gt;I like this automated approach.
The data is downloaded the first time is needed and I don’t need to keep a separate download script in sync with the data requirements of my project.
If after trying things out I decide to chuck away a dataset, I just delete the code that uses that function inside my analysis script and that’s all.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-it-works&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How it works&lt;/h2&gt;
&lt;p&gt;The core of the whole process is this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_dataset &amp;lt;- function(name,
                        file,
                        source) {
   dataset &amp;lt;- list(
      name = name,
      file = file,
      source = source
   )
   
   # Returns a function. 
   function(force_download = FALSE) {
      # Download only if the user forces download or if 
      # the file doesn&amp;#39;t exist. 
      will_download &amp;lt;- isTRUE(force_download) || !file.exists(dataset$file)
      
      if (will_download) {
         dir.create(dirname(dataset$file), showWarnings = FALSE, recursive = TRUE)
         message(&amp;quot;Downloading dataset &amp;quot;, dataset$name, &amp;quot; from remote source.&amp;quot;)
         dataset$source(dataset$file)
      } 
      
      # Check or create md5 checksum
      md5_file &amp;lt;- paste0(dataset$file, &amp;quot;.md5&amp;quot;)
      md5 &amp;lt;- digest::digest(file = dataset$file, algo = &amp;quot;md5&amp;quot;)
      
      if (file.exists(md5_file)) {
         md5_previous &amp;lt;- readLines(md5_file)
         
         if (md5_previous != md5) {
            warning(&amp;quot;File for dataset &amp;quot;, dataset$name, &amp;quot; has incorrect checksum.&amp;quot;)
         }
         
      } else {
         message(&amp;quot;Creating md5 file for dataset &amp;quot;, dataset$name, &amp;quot;.&amp;quot;)
         writeLines(md5, md5_file)
      }
      
      return(dataset$file)
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a &lt;a href=&#34;https://adv-r.hadley.nz/function-factories.html&#34;&gt;function factory&lt;/a&gt;, which is a fancy name for a function that returns a function.
It takes the name of the dataset, the file location and the source function, which is a function that takes a file location and downloads the data there.&lt;/p&gt;
&lt;p&gt;It returns a function that the user can call inside their analysis script and which will do all the heavy lifting before returning the file location.&lt;/p&gt;
&lt;p&gt;For example, the backbone of my research is the &lt;a href=&#34;https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5&#34;&gt;ERA5 reanalysis&lt;/a&gt;, which is a big global gridded dataset of the atmosphere and the surface of the planet.
These data are too big to share but, luckily, they are easy to get.
The &lt;a href=&#34;https://cds.climate.copernicus.eu/#!/home&#34;&gt;Climate Data Store&lt;/a&gt; serves these datasets to anyone for free.&lt;/p&gt;
&lt;p&gt;So let’s say I have a function called &lt;code&gt;download_era5()&lt;/code&gt; which takes a file location and downloads the relevant data using &lt;a href=&#34;https://bluegreen-labs.github.io/ecmwfr/&#34;&gt;the ecwmfr package&lt;/a&gt;.
Then I can define my dataset with&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ERA5 &amp;lt;- new_dataset(
   name = &amp;quot;era5&amp;quot;,
   file = &amp;quot;data_raw/era5.mon.mean.nc&amp;quot;,
   source = download_era5
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’d put this on my project package or where I put my scripts.
Then, in the main Rmd I just load the dataset with&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- ERA5() |&amp;gt; 
   metR::ReadNetCDF()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first time I run this line or knit the file on a new computer it will automatically download the dataset and check that the checksum is correct (the .md5 files need to be shared with the repository).&lt;/p&gt;
&lt;p&gt;An important note is to make sure that your source function always returns the same data.
This means being very explicit about things like date ranges.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;This usage pattern can be extended a lot, which is why I like it.
If the dataset is a function, you can go crazy and make it do a lot of background work!
For instance, you could include citation information in your function and make it populate the relevant .bib file only if the function is used and with the exact date the data was downloaded on.&lt;/p&gt;
&lt;p&gt;It can also be extended to add a Zenodo repository as a secondary source.
The first time you download from the original source, and then you create a Zenodo repository.
This will ensure better reproducibility, since the original source might change the data (in case of errors in the data, for instance) while also having a clear paper trail of how the dataset was obtained from the primary source.&lt;/p&gt;
&lt;p&gt;A small price to pay for not having a “download-data.R” file is that you can’t just download everything once and then go on to running or modifying the analysis.
This can be annoying as you might run the analysis expecting a quick look at the results and instead get to stare at a progress bar while part of the data is downloaded.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MIDI madness with ChatGPT: the AI-powered tunes that will make you laugh, cry, and dance</title>
      <link>/en/2022/12/chatpgt-midi-music/</link>
      <pubDate>Sun, 11 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/en/2022/12/chatpgt-midi-music/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;chat.openai.com/&#34;&gt;ChatGPT&lt;/a&gt; seems to be taking the world by storm.
This is version of the GPT3 language model which is somehow optimised for chat dominates my Mastodon feed and inspired countless articles and discussion. &lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A decent chunk of the discourse has been about how the outputs of the models sound very plausible and even authoritative but lack any connection with reality because the model is train to mimic language, not to give truth.
Another chunk of the discourse is dominated by funny responses and creations.
Things like poems, stories, limericks.&lt;/p&gt;
&lt;p&gt;This convinced me that that we should treat GPT like we treat image generation models: tools to create art, which is, in principle, unconcerned with truth.
I’ve been playing with Stable Diffusion (you can check &lt;a href=&#34;https://eliocamp.github.io/art/&#34;&gt;my gallery&lt;/a&gt; so I was interested to know if I could use GPT to create other things beside text.&lt;/p&gt;
&lt;p&gt;Sure, GPT’s will only respond with text, but since anything can be potentially encoded in (enough) text, it could potentially create anything.&lt;/p&gt;
&lt;div id=&#34;gpt-cant-create-images&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GPT can’t create images&lt;/h2&gt;
&lt;p&gt;My first thought was to try to create images using &lt;a href=&#34;https://en.wikipedia.org/wiki/Base64&#34;&gt;Base64 encoding&lt;/a&gt;.
Since images can be base64 encoded, then I could potentially ask GPT something like “Give me the base64 representation of a house at the foot of a mountain”.&lt;/p&gt;
&lt;p&gt;First I checked if GPT could understand base64 encoding at all.
It turns out, &lt;a href=&#34;https://mastodon.social/@eliocamp/109475795739588085&#34;&gt;it can&lt;/a&gt;!
However, in my tests it seems that GPT’s ability to decode from and encode to base64 was limited to short sentences and didn’t extend to images.&lt;/p&gt;
&lt;p&gt;I gave it the base64 representation of a 50px by 50px image of a black square and asked it to describe the image.
Even though GPT recognised the encoded image as a PNG file, it didn’t describe it properly, it just gave bullshit answers.
Furthermore, when asked to generate a base64-encoded image the resulting text wasn’t even valid and I think it was larger that the limit of tokens for each response.&lt;/p&gt;
&lt;p&gt;So images are a bust.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gpt-can-create-music&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GPT can create music&lt;/h2&gt;
&lt;p&gt;Having failed with images, I turned my attention to music.
There are several ways to represent music with text.
At first I tried with &lt;a href=&#34;https://en.wikipedia.org/wiki/ABC_notation&#34;&gt;ABC Notation&lt;/a&gt;, but asking it to create the ABC notation of the Happy Birthday tune resulted in invalid notation and I wasn’t able to nudge it to correct it.
I don’t know enough of ABC notation, though, so that could be also my fault.&lt;/p&gt;
&lt;p&gt;Then, I remembered that MIDI files can be encoded as text, so I asked it to create a MIDI text for the tune.
Unfortunately it didn’t work very well.
I could get valid MIDI notation, but it was just gibberish.&lt;/p&gt;
&lt;p&gt;But then I remembered a trick I’d seen posted on twitter: GPT can be bad at giving answers, but it can be good at creating code that returns the answer.
So I tried combinations of “Write a program in R/python/bash that crates a simple tune.”
(I couldn’t get it to play Happy Birthday.)
Eventually I settled for python and got my first song!&lt;/p&gt;
&lt;p&gt;Below is the full annotated conversation. Note that at some points I had to edit previous sections of the conversation, so what you’re seeing is just the end result.&lt;/p&gt;
&lt;div id=&#34;making-gpt-sing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Making GPT sing&lt;/h3&gt;
&lt;div id=&#34;creating-a-python-program-to-write-midi-files&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Creating a python program to write midi files&lt;/h4&gt;
&lt;p&gt;After a few tries I decided to use python.
In some examples, GPT wrote code that added each note manually, so I had to ask it explicitly to use a for loop.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;I want to write a midi file.
Can you provide python3 code that writes a simple tune using a for loop to add each note?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Here is a simple example using the python-midi library:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# create the MIDIFile object with 1 track
midi = MIDIFile(1)

# add the track name and tempo
midi.addTrackName(0, 0, &amp;quot;My Simple Tune&amp;quot;)
midi.addTempo(0, 0, 120)

# create a list of notes to add to the track
notes = [60, 62, 64, 65, 67, 69, 71]

# use a for loop to add each note to the track
for i, note in enumerate(notes):
   # add the note on event
   midi.addNote(0, 0, note, i, 1, 100)
   # add the note off event
   midi.addNote(0, 0, note, i+1, 1, 0)

# write the MIDIFile to a file
with open(&amp;quot;simple_tune.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code will create a simple tune with a single track and 7 notes, with each note lasting for 1 beat at 120 beats per minute.
The resulting MIDI file can be played back using a MIDI player or imported into a DAW for further editing.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here’s out first tune!&lt;/p&gt;
&lt;div class=&#39;audio-container&#39;&gt;

&lt;audio controls&gt;
&lt;source src=&#34;../post/gptsong/tune1.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
&lt;/audio&gt;
&lt;/div&gt;
&lt;p&gt;Now let’s start improving to the script by adding more options.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Great! Can you modify the program so each note has a potentially different length?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, we can use the &lt;code&gt;duration&lt;/code&gt; parameter in the &lt;code&gt;addNote&lt;/code&gt; method to specify the length of each note. Here is an updated version of the code that allows for different note lengths:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# create the MIDIFile object with 1 track
midi = MIDIFile(1)

# add the track name and tempo
midi.addTrackName(0, 0, &amp;quot;My Simple Tune&amp;quot;)
midi.addTempo(0, 0, 120)

# create a list of notes and durations to add to the track
notes = [60, 62, 64, 65, 67, 69, 71]
durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]

# use a for loop to add each note to the track
for i, (note, duration) in enumerate(zip(notes, durations)):
   # add the note on event
   midi.addNote(0, 0, note, i, duration, 100)
   # add the note off event
   midi.addNote(0, 0, note, i+duration, duration, 0)

# write the MIDIFile to a file
with open(&amp;quot;simple_tune.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we have added a &lt;code&gt;durations&lt;/code&gt; list which specifies the length of each note in beats. We then use this list in the for loop to set the duration of each note. Note that we also need to update the time of the note off event to account for the different note lengths.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Fantastic. One thing, though is that I don’t think the program needs note on and note off events, because the addNote method already defines the duration of each note, let’s remove that and only have one addNote in the for loop.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;You are correct - the &lt;code&gt;addNote&lt;/code&gt; method already includes the duration of each note, so we don’t need to add separate note on and note off events. Here is an updated version of the code that only uses the &lt;code&gt;addNote&lt;/code&gt; method once per note:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# create the MIDIFile object with 1 track
midi = MIDIFile(1)

# add the track name and tempo
midi.addTrackName(0, 0, &amp;quot;My Simple Tune&amp;quot;)
midi.addTempo(0, 0, 120)

# create a list of notes and durations to add to the track
notes = [60, 62, 64, 65, 67, 69, 71]
durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]

# use a for loop to add each note to the track
for i, (note, duration) in enumerate(zip(notes, durations)):
   # add the note with the specified duration
   midi.addNote(0, 0, note, i, duration, 100)

# write the MIDIFile to a file
with open(&amp;quot;simple_tune.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we only use the &lt;code&gt;addNote&lt;/code&gt; method once per note, and the duration of each note is specified in the &lt;code&gt;duration&lt;/code&gt; parameter. This allows us to create a simple tune with varying note lengths.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Note that I had to do a little thinking about the script and also looking at &lt;a href=&#34;https://midiutil.readthedocs.io/en/1.2.1/common.html#adding-notes&#34;&gt;midiutil’s documentation&lt;/a&gt; to find that subtle issue with the program.&lt;/p&gt;
&lt;p&gt;The next bit fixes an issue that I only noticed after trying to create some more stuff with the script.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Great. However, now that notes can have different duration, the timing of each note is not constant. Let’s compute the timing based on the duration of each note.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;To compute the timing of each note based on its duration, we can keep track of the total time elapsed and use that as the starting time of each note. Here is an updated version of the code that does this:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# create the MIDIFile object with 1 track
midi = MIDIFile(1)

# add the track name and tempo
midi.addTrackName(0, 0, &amp;quot;My Simple Tune&amp;quot;)
midi.addTempo(0, 0, 120)

# create a list of notes and durations to add to the track
notes = [60, 62, 64, 65, 67, 69, 71]
durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]

# initialize a variable to keep track of the total time elapsed
total_time = 0

# use a for loop to add each note to the track
for i, (note, duration) in enumerate(zip(notes, durations)):
   # add the note with the specified duration starting at the current total time
   midi.addNote(0, 0, note, total_time, duration, 100)
   # increment the total time by the duration of the current note
   total_time += duration

# write the MIDIFile to a file
with open(&amp;quot;simple_tune.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we initialize a &lt;code&gt;total_time&lt;/code&gt; variable to keep track of the time elapsed so far. Then, in the for loop, we use the &lt;code&gt;total_time&lt;/code&gt; variable as the starting time of each note, and increment it by the duration of the current note. This ensures that each note is spaced out according to its duration.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Fantastic. Let’s now add the option of having a different volume for each note.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;To add the option of having a different volume for each note, we can add a &lt;code&gt;volumes&lt;/code&gt; list that specifies the volume of each note, and use that in the &lt;code&gt;addNote&lt;/code&gt; method. Here is an updated version of the code that does this:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# create the MIDIFile object with 1 track
midi = MIDIFile(1)

# add the track name and tempo
midi.addTrackName(0, 0, &amp;quot;My Simple Tune&amp;quot;)
midi.addTempo(0, 0, 120)

# create a list of notes, durations, and volumes to add to the track
notes = [60, 62, 64, 65, 67, 69, 71]
durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]
volumes = [100, 80, 60, 50, 40, 30, 20]

# initialize a variable to keep track of the total time elapsed
total_time = 0

# use a for loop to add each note to the track
for i, (note, duration, volume) in enumerate(zip(notes, durations, volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(0, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# write the MIDIFile to a file
with open(&amp;quot;simple_tune.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we have added a &lt;code&gt;volumes&lt;/code&gt; list that specifies the volume of each note, and we use this in the &lt;code&gt;addNote&lt;/code&gt; method as the &lt;code&gt;volume&lt;/code&gt; parameter. This allows us to have different volumes for each note in the tune.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Great. Now, what’s the maximum volume?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;In MIDI files, the maximum volume is represented by the value 127. This is the maximum value that can be used in the &lt;code&gt;volume&lt;/code&gt; parameter of the &lt;code&gt;addNote&lt;/code&gt; method. In the code above, we have used the values 100, 80, 60, 50, 40, 30, and 20 for the volumes of each note, which are all less than the maximum value of 127. If you want to use the maximum volume for any of the notes, you can simply use the value 127 in the &lt;code&gt;volumes&lt;/code&gt; list. For example:&lt;/p&gt;
&lt;pre class=&#34;css&#34;&gt;&lt;code&gt;volumes = [100, 80, 60, 127, 40, 30, 20]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This would set the volume of the 4th note to the maximum value of 127.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;So now I had a script that could create a tune with many interesting note variations.
Here’s the tune so far:&lt;/p&gt;
&lt;div class=&#39;audio-container&#39;&gt;

&lt;audio controls&gt;
&lt;source src=&#34;../post/gptsong/tune2.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
&lt;/audio&gt;
&lt;/div&gt;
&lt;p&gt;So now I wanted to go a bit further.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Perfect. Now, I will be using the program to create midi files of piano songs, which have a right hand part playing the melody and a left hand part that plays the base. Let’s modify the program to play each hand in it’s own track.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;To create a MIDI file with multiple tracks, we can simply create a &lt;code&gt;MIDIFile&lt;/code&gt; object with multiple tracks and use the &lt;code&gt;addNote&lt;/code&gt; method for each track. Here is an updated version of the code that creates a MIDI file with two tracks for a piano song:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# create the MIDIFile object with 2 tracks
midi = MIDIFile(2)

# add the track names and tempo
midi.addTrackName(0, 0, &amp;quot;Right Hand&amp;quot;)
midi.addTrackName(1, 0, &amp;quot;Left Hand&amp;quot;)
midi.addTempo(0, 0, 120)

# create a list of notes, durations, and volumes for the right hand part
right_notes = [60, 62, 64, 65, 67, 69, 71]
right_durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]
right_volumes = [100, 80, 60, 50, 40, 30, 20]

# create a list of notes, durations, and volumes for the left hand part
left_notes = [48, 50, 52, 53, 55, 57, 59]
left_durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]
left_volumes = [100, 80, 60, 50, 40, 30, 20]

# initialize a variable to keep track of the total time elapsed
total_time = 0

# use a for loop to add each note to the right hand track
for i, (note, duration, volume) in enumerate(zip(right_notes, right_durations, right_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(0, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# reset the total time to 0 for the left hand track
total_time = 0

# use a for loop to add each note to the left hand track
for i, (note, duration, volume) in enumerate(zip(left_notes, left_durations, left_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(1, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# write the MIDIFile to a file
with open(&amp;quot;piano_song.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we create a &lt;code&gt;MIDIFile&lt;/code&gt; object with 2 tracks and add track names for each track. We then create separate lists of notes, durations, and volumes for each track, and use a for loop to add each note to the appropriate track. This allows us to create a MIDI file with multiple tracks for a piano song with a right hand and left hand part.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Not the most elegant script ever crated, but it works!
I was quite surprised by the fact that GPT actually used notes with lower pitch for the left hand part!
Also notice that the name of the output file is now “piano_song.mid”.&lt;/p&gt;
&lt;p&gt;This was going so well that I decided to try go further.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Great. Now, can you add an option to change the instrument. Let’s test it with a flute.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;To change the instrument of a track in a MIDI file, we can use the &lt;code&gt;addProgramChange&lt;/code&gt; method to specify the instrument for each track. Here is an updated version of the code that adds this option:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# create the MIDIFile object with 2 tracks
midi = MIDIFile(2)

# add the track names and tempo
midi.addTrackName(0, 0, &amp;quot;Right Hand&amp;quot;)
midi.addTrackName(1, 0, &amp;quot;Left Hand&amp;quot;)
midi.addTempo(0, 0, 120)

# set the instrument for each track
midi.addProgramChange(0, 0, 0, 74)  # flute for right hand track
midi.addProgramChange(1, 0, 0, 74)  # flute for left hand track

# create a list of notes, durations, and volumes for the right hand part
right_notes = [60, 62, 64, 65, 67, 69, 71]
right_durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]
right_volumes = [100, 80, 60, 50, 40, 30, 20]

# create a list of notes, durations, and volumes for the left hand part
left_notes = [48, 50, 52, 53, 55, 57, 59]
left_durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]
left_volumes = [100, 80, 60, 50, 40, 30, 20]

# initialize a variable to keep track of the total time elapsed
total_time = 0

# use a for loop to add each note to the right hand track
for i, (note, duration, volume) in enumerate(zip(right_notes, right_durations, right_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(0, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# reset the total time to 0 for the left hand track
total_time = 0

# use a for loop to add each note to the left hand track
for i, (note, duration, volume) in enumerate(zip(left_notes, left_durations, left_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(1, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# write the MIDIFile to a file
with open(&amp;quot;piano_song.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we have added two &lt;code&gt;addProgramChange&lt;/code&gt; calls to set the instrument for each track. We have used the value 74 for the instrument, which corresponds to the flute. You can use a different instrument by specifying a different value in the &lt;code&gt;addProgramChange&lt;/code&gt; method. A list of available instruments and their corresponding values can be found here: &lt;a href=&#34;https://www.midi.org/specifications/item/gm-level&#34;&gt;https://www.midi.org/specifications/item/gm-level&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;That was incredible!
GPT actually correctly decoded the number corresponding to the Flute.
The link it gave wasn’t very helpful, so had to google the list of midi instruments.&lt;/p&gt;
&lt;p&gt;Now I wanted my program to decode that list so I could just use the name of the instrument instead of the number.
My idea was to have a csv with the data and load it in python.
As you will see, GPT had other idea.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Great. Can you give me a csv string with columns “instrument” and “value” with the name and value of instruments 0 to 23? The names of the instruments should be quoted.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is a CSV string with the names and values of instruments 0 to 23:&lt;/p&gt;
&lt;pre class=&#34;csv&#34;&gt;&lt;code&gt;&amp;quot;instrument&amp;quot;,&amp;quot;value&amp;quot;
&amp;quot;Acoustic Grand Piano&amp;quot;,&amp;quot;0&amp;quot;
&amp;quot;Bright Acoustic Piano&amp;quot;,&amp;quot;1&amp;quot;
&amp;quot;Electric Grand Piano&amp;quot;,&amp;quot;2&amp;quot;
&amp;quot;Honky-tonk Piano&amp;quot;,&amp;quot;3&amp;quot;
&amp;quot;Electric Piano 1&amp;quot;,&amp;quot;4&amp;quot;
&amp;quot;Electric Piano 2&amp;quot;,&amp;quot;5&amp;quot;
&amp;quot;Harpsichord&amp;quot;,&amp;quot;6&amp;quot;
&amp;quot;Clavi&amp;quot;,&amp;quot;7&amp;quot;
&amp;quot;Celesta&amp;quot;,&amp;quot;8&amp;quot;
&amp;quot;Glockenspiel&amp;quot;,&amp;quot;9&amp;quot;
&amp;quot;Music Box&amp;quot;,&amp;quot;10&amp;quot;
&amp;quot;Vibraphone&amp;quot;,&amp;quot;11&amp;quot;
&amp;quot;Marimba&amp;quot;,&amp;quot;12&amp;quot;
&amp;quot;Xylophone&amp;quot;,&amp;quot;13&amp;quot;
&amp;quot;Tubular Bells&amp;quot;,&amp;quot;14&amp;quot;
&amp;quot;Dulcimer&amp;quot;,&amp;quot;15&amp;quot;
&amp;quot;Drawbar Organ&amp;quot;,&amp;quot;16&amp;quot;
&amp;quot;Percussive Organ&amp;quot;,&amp;quot;17&amp;quot;
&amp;quot;Rock Organ&amp;quot;,&amp;quot;18&amp;quot;
&amp;quot;Church Organ&amp;quot;,&amp;quot;19&amp;quot;
&amp;quot;Reed Organ&amp;quot;,&amp;quot;20&amp;quot;
&amp;quot;Accordion&amp;quot;,&amp;quot;21&amp;quot;
&amp;quot;Harmonica&amp;quot;,&amp;quot;22&amp;quot;
&amp;quot;Tango Accordion&amp;quot;,&amp;quot;23&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this CSV string, the first column contains the name of the instrument, and the second column contains its corresponding value. You can use this string to create a lookup table for the available instruments and their values.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Fantastic. I saved this information in a file called “instruments.csv”. Can you write a python function called decode_instrument that takes a string with the name of the instrument and returns its value?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is a python function called &lt;code&gt;decode_instrument&lt;/code&gt; that takes a string with the name of the instrument and returns its value:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def decode_instrument(instrument_name):
    # create a dictionary mapping instrument names to their values
    instrument_values = {
        &amp;quot;Acoustic Grand Piano&amp;quot;: 0,
        &amp;quot;Bright Acoustic Piano&amp;quot;: 1,
        &amp;quot;Electric Grand Piano&amp;quot;: 2,
        &amp;quot;Honky-tonk Piano&amp;quot;: 3,
        &amp;quot;Electric Piano 1&amp;quot;: 4,
        &amp;quot;Electric Piano 2&amp;quot;: 5,
        &amp;quot;Harpsichord&amp;quot;: 6,
        &amp;quot;Clavi&amp;quot;: 7,
        &amp;quot;Celesta&amp;quot;: 8,
        &amp;quot;Glockenspiel&amp;quot;: 9,
        &amp;quot;Music Box&amp;quot;: 10,
        &amp;quot;Vibraphone&amp;quot;: 11,
        &amp;quot;Marimba&amp;quot;: 12,
        &amp;quot;Xylophone&amp;quot;: 13,
        &amp;quot;Tubular Bells&amp;quot;: 14,
        &amp;quot;Dulcimer&amp;quot;: 15,
        &amp;quot;Drawbar Organ&amp;quot;: 16,
        &amp;quot;Percussive Organ&amp;quot;: 17,
        &amp;quot;Rock Organ&amp;quot;: 18,
        &amp;quot;Church Organ&amp;quot;: 19,
        &amp;quot;Reed Organ&amp;quot;: 20,
        &amp;quot;Accordion&amp;quot;: 21,
        &amp;quot;Harmonica&amp;quot;: 22,
        &amp;quot;Tango Accordion&amp;quot;: 23
    }

    # return the value corresponding to the given instrument name
    return instrument_values[instrument_name]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this function, we have created a dictionary that maps instrument names to their values. We then use the given instrument name to look up the corresponding value in this dictionary and return it. You can use this function to quickly lookup the value of a given instrument name. For example, calling &lt;code&gt;decode_instrument(&#34;Acoustic Grand Piano&#34;)&lt;/code&gt; would return the value 0, and calling &lt;code&gt;decode_instrument(&#34;Electric Piano 2&#34;)&lt;/code&gt; would return the value 5.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Well, using code as data wasn’t what I was looking for, but I’ll take it.
Now I had to go back to the code and add this decoder.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Excellent. I saved this function into a file called decode_instrument.py. Can you now modify the program we were working on to import this function and use it to decode the instrument from a string?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is an updated version of the code that imports the &lt;code&gt;decode_instrument&lt;/code&gt; function and uses it to decode the instrument from a string:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# import the decode_instrument function
from decode_instrument import decode_instrument

# create the MIDIFile object with 2 tracks
midi = MIDIFile(2)

# add the track names and tempo
midi.addTrackName(0, 0, &amp;quot;Right Hand&amp;quot;)
midi.addTrackName(1, 0, &amp;quot;Left Hand&amp;quot;)
midi.addTempo(0, 0, 120)

# set the instrument for each track using the decode_instrument function
right_instrument = &amp;quot;Electric Piano 1&amp;quot;
left_instrument = &amp;quot;Electric Piano 2&amp;quot;
midi.addProgramChange(0, 0, 0, decode_instrument(right_instrument))
midi.addProgramChange(1, 0, 0, decode_instrument(left_instrument))

# create a list of notes, durations, and volumes for the right hand part
right_notes = [60, 62, 64, 65, 67, 69, 71]
right_durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]
right_volumes = [100, 80, 60, 50, 40, 30, 20]

# create a list of notes, durations, and volumes for the left hand part
left_notes = [48, 50, 52, 53, 55, 57, 59]
left_durations = [1, 0.5, 0.25, 1, 0.75, 0.5, 2]
left_volumes = [100, 80, 60, 50, 40, 30, 20]

# initialize a variable to keep track of the total time elapsed
total_time&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Oops.
I got intro trouble.
I think that I was once again coming up to the limit of tokens GPT will respond with.
The script is now too long for it to fit into one response.
Fortunately, I could get the rest.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Oops, you didn’t finish the code there. That’s fine, can you write the code beginning from line 27?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is the code starting from line 27:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# initialize a variable to keep track of the total time elapsed
total_time = 0

# use a for loop to add each note to the right hand track
for i, (note, duration, volume) in enumerate(zip(right_notes, right_durations, right_volumes)):
# add the note with the specified duration and volume starting at the current total time
midi.addNote(0, 0, note, total_time, duration, volume)
# increment the total time by the duration of the current note
total_time += duration

# reset the total time to 0 for the left hand track
total_time = 0

# use a for loop to add each note to the left hand track
for i, (note, duration, volume) in enumerate(zip(left_notes, left_durations, left_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(1, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# write the MIDIFile to a file
with open(&amp;quot;piano_song.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)      &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we import the &lt;code&gt;decode_instrument&lt;/code&gt; function and use it to decode the instrument from a string. We then use the &lt;code&gt;addProgramChange&lt;/code&gt; method to set the instrument for each track using the decoded values. This allows us to specify the instrument for each track using its name&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;At this point I should’ve started to refactor the code to make it more concise and split things in different functions.
This would make each part fit into a single response and also better overall.
In the end I decided I was happy with the script as it was except for one detail.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Awesome. Now let’s assume that I have a file called song.py which has the notes, durations and volumes and instrument of each track. Modify the program to load the values from that file.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is an updated version of the code that loads the values for the notes, durations, volumes, and instruments from a file called &lt;code&gt;song.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from midiutil.MidiFile import MIDIFile

# import the decode_instrument function
from decode_instrument import decode_instrument

# create the MIDIFile object with 2 tracks
midi = MIDIFile(2)

# add the track names and tempo
midi.addTrackName(0, 0, &amp;quot;Right Hand&amp;quot;)
midi.addTrackName(1, 0, &amp;quot;Left Hand&amp;quot;)
midi.addTempo(0, 0, 120)

# load the notes, durations, volumes, and instruments from the song.py file
from song import right_notes, right_durations, right_volumes, right_instrument
from song import left_notes, left_durations, left_volumes, left_instrument

# set the instrument for each track using the decode_instrument function
midi.addProgramChange(0, 0, 0, decode_instrument(right_instrument))
midi.addProgramChange(1, 0, 0, decode_instrument(left_instrument))

# initialize a variable to keep track of the total time elapsed
total_time = 0

# use a for loop to add each note to the right hand track
for i, (note, duration, volume) in enumerate(zip(right_notes, right_durations, right_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(0, 0, note, total_time,&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Repeat the program starting from line 25.
[Again, hitting the limits]&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is the code starting from line 25:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# initialize a variable to keep track of the total time elapsed
total_time = 0

# use a for loop to add each note to the right hand track
for i, (note, duration, volume) in enumerate(zip(right_notes, right_durations, right_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(0, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# reset the total time to 0 for the left hand track
total_time = 0

# use a for loop to add each note to the left hand track
for i, (note, duration, volume) in enumerate(zip(left_notes, left_durations, left_volumes)):
   # add the note with the specified duration and volume starting at the current total time
   midi.addNote(1, 0, note, total_time, duration, volume)
   # increment the total time by the duration of the current note
   total_time += duration

# write the MIDIFile to a file
with open(&amp;quot;piano_song.mid&amp;quot;, &amp;quot;wb&amp;quot;) as output_file:
   midi.writeFile(output_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we load the values for the notes, durations, volumes, and instruments from the &lt;code&gt;song.py&lt;/code&gt; file using the &lt;code&gt;from&lt;/code&gt; keyword. We then use these values to set the instruments and add the notes to each track. This allows us to specify the notes, durations, volumes, and instruments for the song in a separate file, and use this code to generate the MIDI file.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;writing-a-song-with-gpt&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Writing a song with GPT&lt;/h4&gt;
&lt;p&gt;At this point I was happy enough with the program and annoyed at hitting the limit that I decided to leave it as it was.
Now it was time to write some music.&lt;/p&gt;
&lt;p&gt;The previous experience had convinced me that asking for a specific melody was a lost cause (there’s probably some prompt hack to do it, though) so I decided to go for a (mostly) original composition.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Excellent! Let’s write a song for this program.&lt;/p&gt;
&lt;p&gt;First, the chord progression should be D major, A major, B minor, F# minor, G major, D major, G major, and A major. Can you create a left hand part that plays those notes with whole notes? Remember that each beat is 1 duration, so whole notes should be 4 durations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is a left hand part that plays the chord progression using whole notes (4 durations):&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# create a list of notes, durations, and volumes for the left hand part
left_notes = [62, 57, 59, 54, 55, 62, 55, 57]
left_durations = [4, 4, 4, 4, 4, 4, 4, 4]
left_volumes = [100, 100, 100, 100, 100, 100, 100, 100]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we have created a list of notes that correspond to the chord progression (D major, A major, B minor, F# minor, G major, D major, G major, and A major). We have also specified a duration of 4 for each note, which corresponds to a whole note. Finally, we have set the volume for each note to 100, which is the maximum value. You can use this code as the left hand part of the song.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Good, but can you lower it an octave?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is a left hand part that plays the chord progression using whole notes (4 durations) in a lower octave:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# create a list of notes, durations, and volumes for the left hand part
left_notes = [50, 45, 47, 42, 43, 50, 43, 45]
left_durations = [4, 4, 4, 4, 4, 4, 4, 4]
left_volumes = [100, 100, 100, 100, 100, 100, 100, 100]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we have created a list of notes that correspond to the chord progression in a lower octave (D major, A major, B minor, F# minor, G major, D major, G major, and A major). We have also specified a duration of 4 for each note, which corresponds to a whole note. Finally, we have set the volume for each note to 100, which is the maximum value. You can use this code as the left hand part of the song, which will be played in a lower octave compared to the original version.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;So far, this is our song.
The right hand part is the same random tune from before; pay attention to the left hand part.
Notice that it did a pretty good job translating my description into midi notes!
Pretty amazing.&lt;/p&gt;
&lt;div class=&#39;audio-container&#39;&gt;

&lt;audio controls&gt;
&lt;source src=&#34;../post/gptsong/song1.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
&lt;/audio&gt;
&lt;/div&gt;
&lt;p&gt;You might recognise this chord progression &lt;a href=&#34;https://www.youtube.com/watch?v=uxC1fPE1QEE&#34;&gt;from somewhere else&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Perfect. Now lets move to the right hand part.
Each bar has 4 fourths. So in each bar let’s play an arpeggio of the corresponding triad plus the next octave. This is 4 fourths in each bar.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is a right hand part that plays an arpeggio of the corresponding triad plus the next octave for each chord in the progression:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# create a list of notes, durations, and volumes for the right hand part
right_notes = [
62, 65, 69, 72,  # D major
57, 60, 64, 67,  # A major
59, 62, 66, 69,  # B minor
54, 57, 61, 64,  # F# minor
55, 58, 62, 65,  # G major
62, 65, 69, 72,  # D major
55, 58, 62, 65,  # G major
57, 60, 64, 67   # A major
]
right_durations = [1, 1, 1, 1] * 8  # each note is 1 beat
right_volumes = [100, 90, 80, 70] * 8  # each note has a different volume&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we have created a list of notes that correspond to the arpeggios of each chord in the progression. We have also specified a duration of 1 for each note, which corresponds to a beat. Finally, we have set the volume for each note to a different value, which allows each note to have a different volume. You can use this code as the right hand part of the song, which will play the arpeggios of each chord in the progression.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now is when the cracks in my music theory formation were starting to show.
I bet that “main triad plus next octave” must have a name, but I don’t know it.
But in any case, GPT translated my ramblings into what I wanted.&lt;/p&gt;
&lt;div class=&#39;audio-container&#39;&gt;

&lt;audio controls&gt;
&lt;source src=&#34;../post/gptsong/song2.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
&lt;/audio&gt;
&lt;/div&gt;
&lt;p&gt;(I think there’s some dissonance somewhere; I could’ve looked closely at the notes to check it, but I decided that I wasn’t going to mess with GPT’s “vision”.)&lt;/p&gt;
&lt;p&gt;So far I was using GPT to translate a fairly strict description of what I wanted into python code.
But now for the real challenge.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;This sounds pretty good!
This is is good for a first verse. Describe a possible second verse that plays on this theme but adds some variation. Don’t show me the code, just describe it musically.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;For the second verse, we can keep the same chord progression and left hand part, but add some variation to the right hand part. One possible variation is to play the arpeggio of each chord in the progression using sixteenth notes instead of fourths. This will make the right hand part sound more energetic and lively. We can also add some notes in between the arpeggios to fill out the harmony and create a more complex melody. For example, we can add some chromatic passing notes or add a note from the chord a beat before the arpeggio starts. This will create a more interesting and varied melody. Overall, the second verse will have the same overall structure and harmony as the first verse, but with some added variation and complexity in the right hand part.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Well, that was interesting, I guess.
Let’s see how it works…&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Sounds good. Since the left hand part repeats I only need you to show me the code for the right hand part (both verses).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here is the code for the right hand part of both verses:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# create a list of notes, durations, and volumes for the right hand part (first verse)
right_notes_1 = [
62, 65, 69, 72,  # D major
57, 60, 64, 67,  # A major
59, 62, 66, 69,  # B minor
54, 57, 61, 64,  # F# minor
55, 58, 62, 65,  # G major
62, 65, 69, 72,  # D major
55, 58, 62, 65,  # G major
57, 60, 64, 67   # A major
]
right_durations_1 = [1, 1, 1, 1] * 8  # each note is 1 beat
right_volumes_1 = [100, 90, 80, 70] * 8  # each note has a different volume

# create a list of notes, durations, and volumes for the right hand part (second verse)
right_notes_2 = [
62, 63, 65, 66, 67, 69, 70, 72,  # D major
57, 58, 60, 61, 62, 64, 65, 67,  # A major
59, 60, 62, 63, 64, 66, 67, 69,  # B minor
54, 55, 57, 58, 59, 61, 62, 64,  # F# minor
55, 56, 58, 59, 60, 62, 63, 65,  # G major
62, 63, 65, 66, 67, 69, 70, 72,  # D major
55, 56, 58, 59, 60, 62, 63, 65,  # G major
57, 58, 60, 61, 62, 64, 65, 67   # A major
]
right_durations_2 = [0.25, 0.25, 0.25, 0.25] * 32  # each note is 1/4 beat
right_volumes_2 = [100, 90, 80, 70] * 32  # each note has a different volume&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we have created two lists of notes for the right hand part, one for each verse. The first verse uses the same arpeggio pattern as the original version, with a duration of 1 beat for each note. The second verse uses the same arpeggio pattern but with sixteenth notes, which have a duration of 1/4 beat. We have also specified different volumes for each note, which allows each note to have a different volume. You can use this code to generate the right hand part for both verses of the song.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Ok, I have the right_notes_1 and right_notes_2. How do I combine them into one variable called right_notes?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;To combine the &lt;code&gt;right_notes_1&lt;/code&gt; and &lt;code&gt;right_notes_2&lt;/code&gt; variables into one variable called &lt;code&gt;right_notes&lt;/code&gt;, you can use the &lt;code&gt;+&lt;/code&gt; operator to concatenate the two lists. Here is an example of how to do this:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;right_notes = right_notes_1 + right_notes_2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, we use the &lt;code&gt;+&lt;/code&gt; operator to concatenate the &lt;code&gt;right_notes_1&lt;/code&gt; and &lt;code&gt;right_notes_2&lt;/code&gt; lists, and store the result in a new list called &lt;code&gt;right_notes&lt;/code&gt;. You can then use this &lt;code&gt;right_notes&lt;/code&gt; list as the input for the &lt;code&gt;addNote&lt;/code&gt; method to add the notes to the MIDI file. This will combine the notes from both verses into one list, which can be used to generate the MIDI file for the entire song.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Notice that GPT split each verse in its own variable, which was great for readability but bad for the code because I’m a dummy who doesn’t know python.
I could’ve googled how to concatenate lists in python, but I for this experiment I wanted to do as much as I could with GPT alone.&lt;/p&gt;
&lt;p&gt;At I’m writing this post I realise that GPT actually made a mistake.
&lt;code&gt;right_notes_2&lt;/code&gt; has 64 elements, which corresponds to 8 bars when played with eighths.
But then &lt;code&gt;right_durations_2&lt;/code&gt; has 128 elements with value 0.25 (sixteenth notes) instead of 64 elements with value of 0.5.
Re-reading GPT’s description, which mentioned using sixteenths, it seems that GPT actually didn’t add enough notes in the arpeggios.
There are two was to fix it: duplicate every row in &lt;code&gt;right_notes_2&lt;/code&gt; or change &lt;code&gt;right_durations_2&lt;/code&gt; to be eighths.
I’ll fix it by using eighths because it sounds much better to my ears. &lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Anyway, here’s the funky new song by GPT (ft. me).&lt;/p&gt;
&lt;div class=&#39;audio-container&#39;&gt;

&lt;audio controls&gt;
&lt;source src=&#34;../post/gptsong/song3.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
&lt;/audio&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;coda&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Coda&lt;/h2&gt;
&lt;p&gt;As a final part of the conversation I wanted to probe GPT for next steps forward and also get a title for this post.
Here’s the rest of the conversation.&lt;/p&gt;
&lt;div class=&#34;conversation&#34;&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Great. I will share this song with my friends.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;I’m glad to hear that! I hope your friends enjoy the song. Let me know if you need any further assistance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Yes, I think there’s still things to improve in our program. Can you suggest 5 things to change in our code to make it better in order or more to least important?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here are 5 suggestions to improve the code we have been working on:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Use a class to organize the code and make it more modular and reusable. Instead of using global variables and functions, we can define a Song class that has attributes and methods to represent the data and operations for the song. This will allow us to create multiple songs and manipulate them independently, as well as make the code easier to understand and maintain.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Handle errors and exceptions gracefully. Currently, the code does not handle any errors or exceptions that may occur during execution. For example, if the song.py file does not exist or if the decode_instrument function fails to decode a valid instrument, the code will crash and produce an error message. To improve the code, we can add try-except blocks to catch and handle common errors and exceptions, and provide useful feedback and instructions to the user.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use more descriptive and meaningful variable names. Some of the variable names used in the code are not very descriptive or meaningful, which can make it difficult to understand the code. For example, the midi variable is used to represent the MIDI file object, but this does not provide much information about its purpose or contents. To improve the code, we can use more descriptive and meaningful variable names that accurately reflect their purpose and contents. For example, we can use midi_file instead of midi to represent the MIDI file object.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use standard Python formatting and style conventions. The code currently uses a mix of different formatting and style conventions, which can make it difficult to read and understand. For example, the indentation is not consistent, some lines are too long, and some variable names are not written in snake_case. To improve the code, we can follow the standard Python formatting and style conventions, such as using 4 spaces for indentation, splitting long lines into multiple lines, and using snake_case for variable names. This will make the code more readable and consistent, and improve its overall quality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add more comments and documentation to the code. The code currently has very few comments and no documentation, which can make it difficult to understand and use. For example, it is not clear what the decode_instrument function does, or how to use the addNote method to add a note to the MIDI file. To improve the code, we can add more comments and documentation to explain the purpose and usage of each component of the code. This will make it easier for other people to understand and use the code, and improve its overall maintainability and reliability.`&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Good suggestions. We might work on these in our next session, but now it’s getting late.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, we can work on these improvements in our next session. In the meantime, I hope you have a good rest and I look forward to our next session. Let me know if you have any further questions or need any assistance. Have a great day!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Thanks. Just to finish, can you summarise what we did in this session?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;In this session, we created a Python program that generates a MIDI file with a simple tune using a for loop to add each note. The program allows each note to have a different duration and volume, and it uses a function to decode the instrument from a string. We also discussed some suggestions to improve the code and make it more modular, error-resistant, readable, and documented. Finally, we discussed a possible second verse for the song, and provided the code for the right hand part of both verses.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;I want to write a blog post publishing this conversation and adding my comments. Can you suggests 5 possible titles? I want something somewhat funny, puns are particularly appreciated but not necessary.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here are 5 possible titles for the blog post that incorporate some humour or puns:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;“AI-generated tunes: the MIDI-nightmare that’s taking over the music world”&lt;/li&gt;
&lt;li&gt;“Pythoning a MIDI masterpiece: how AI is changing the way we create music”&lt;/li&gt;
&lt;li&gt;“MIDI madness: the AI-powered tunes that will make you laugh, cry, and dance”&lt;/li&gt;
&lt;li&gt;“AI, MIDI, and you: the future of music is here, and it’s hilarious”&lt;/li&gt;
&lt;li&gt;“Python and MIDI: the perfect duo for creating the craziest tunes you’ve ever heard”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These titles are meant to be humorous and playful, and incorporate some puns related to the topic of the blog post. You can choose the one that you like the most or modify them to better fit your needs and preferences.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Those are great. Can you suggest 5 more with ChatGPT in the title.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here are 5 more possible titles for the blog post that incorporate the term “ChatGPT”:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;“ChatGPT: the AI chatbot that helps you write MIDI tunes”&lt;/li&gt;
&lt;li&gt;“Creating music with ChatGPT: a step-by-step guide to MIDI madness”&lt;/li&gt;
&lt;li&gt;“ChatGPT and MIDI: the perfect combination for making the craziest tunes”&lt;/li&gt;
&lt;li&gt;“ChatGPT’s MIDI masterpieces: how AI is changing the way we create music”&lt;/li&gt;
&lt;li&gt;“ChatGPT’s MIDI magic: the AI chatbot that will make you dance and sing”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These titles all incorporate the term “ChatGPT” and highlight its role in creating MIDI tunes. You can choose the one that you like the most or modify them to better fit your needs and preferences.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Can you create 10 titles combining these 5 with the previous 5?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Sure, here are 10 possible titles that combine the previous 5 titles with the 5 new titles:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;“AI-generated tunes with ChatGPT: the MIDI-nightmare that’s taking over the music world”&lt;/li&gt;
&lt;li&gt;“Pythoning a MIDI masterpiece with ChatGPT: how AI is changing the way we create music”&lt;/li&gt;
&lt;li&gt;“MIDI madness with ChatGPT: the AI-powered tunes that will make you laugh, cry, and dance”&lt;/li&gt;
&lt;li&gt;“AI, MIDI, and ChatGPT: the future of music is here, and it’s hilarious”&lt;/li&gt;
&lt;li&gt;“Python, MIDI, and ChatGPT: the perfect trio for creating the craziest tunes you’ve ever heard”&lt;/li&gt;
&lt;li&gt;“ChatGPT: the AI chatbot that helps you write MIDI tunes like a pro”&lt;/li&gt;
&lt;li&gt;“Creating music with ChatGPT and MIDI: a step-by-step guide to MIDI madness”&lt;/li&gt;
&lt;li&gt;“ChatGPT and MIDI: the perfect combination for making the wildest, wackiest tunes”&lt;/li&gt;
&lt;li&gt;“ChatGPT’s MIDI masterpieces: how AI is revolutionizing the way we create music”&lt;/li&gt;
&lt;li&gt;“ChatGPT’s MIDI magic: the AI chatbot that will make your feet move and your heart sing”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These titles incorporate the previous 5 titles and the new 5 titles, and highlight the role of ChatGPT in creating MIDI tunes. You can choose the one that you like the most or modify them to better fit your needs and preferences.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;style&gt;

.audio-container {
   margin: 2rem 0 0 0;
   display: flex;
   justify-content: center;
   align-items: center;
}

.conversation {
   margin: 1rem 3rem 0 3rem;
}
.question {
   background-color: #F7F7F8;
   padding: 0.5rem 2rem 0.5rem 2rem;   
   font-weight: bold;
   border-bottom: 1px solid rgba(0,0,0,.1);

}

.answer {
   background-color: #F7F7F8;
   padding: 0.5rem 2rem 0.5rem 4rem;
   border-bottom: 1px solid rgba(0,0,0,.1);
}


&lt;/style&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;I think that the reason it’s become so popular has less to do with the technical details and more with the fact that is free to use with no token restrictions.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Writing about music in English is ugly as hell. In Spanish notes and durations have cool, interesting names like “&lt;em&gt;corcheas&lt;/em&gt;” instead of “eighths” and Do, Re, Mi, Fa, Sol, La, Si instead of C, D, E, F, G, A, B. I guess the English nomenclature is more clear and doesn’t require you to memorise names, but still, ugly and boring.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Labeling contour lines in R with ggplot2, metR and isoband</title>
      <link>/en/2021/09/contour-labels/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/en/2021/09/contour-labels/</guid>
      <description>
&lt;script src=&#34;../rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I started to use R full time for my research about 5 years ago when I started working on my Masters’ thesis and up until today there was one thing missing: proper contour labels.
Now, thanks to the wonderful isoband package, I finally got what I wished for and it’s bundled in the latest release of &lt;a href=&#34;https://cran.r-project.org/package=metR&#34;&gt;metR&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So let’s set up the stage for the problem.
I have a 2D field that I want to visualise as a contour map.
The canonical example in R is the volcano dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
data(volcano)
volcano_df &amp;lt;- reshape2::melt(volcano)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With ggplot2, one would use &lt;code&gt;geom_contour()&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(volcano_df, aes(Var1, Var2)) +
  geom_contour(aes(z = value)) +
  coord_equal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-09-19-contour-labels.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With this, one can see the overall shape of the mountain but it is impossible to know the height that each contour represents.
Is this an Everest-size mountain or a tiny little hill?
Where is the top of the mountain?
Where is the crater?&lt;/p&gt;
&lt;p&gt;One trick is to map the colour of each line to its level like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(volcano_df, aes(Var1, Var2)) +
  geom_contour(aes(z = value, colour = stat(level))) +
  scale_colour_viridis_c() +
  coord_equal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-09-19-contour-labels.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This helps immensely in identifying local minimums, maximums and get a sense of the high, but it’s not super easy to pair each line with its level.
There are some other tricks, but no workaround is as effective as just labelling those lines!
Just look at what can be done with the &lt;code&gt;contour()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;contour(volcano)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-09-19-contour-labels.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With labels on each contour, it’s trivial to know the height of each point without having to mentally map colours to numbers.
It would be great being able to do this with ggplot2.&lt;/p&gt;
&lt;p&gt;One possibility is to use the old &lt;code&gt;metR::geom_text_contour()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metR)      # version 0.11.0
ggplot(volcano_df, aes(Var1, Var2)) +
  geom_contour(aes(z = value, colour = stat(level))) +
  metR::geom_text_contour(aes(z = value)) +
  coord_equal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-09-19-contour-labels.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By default it places a label on every second contour level looking roughly for the flattest part of the contour (label placement can be tweaked with the &lt;code&gt;label.placer&lt;/code&gt; argument).
A complicating issue is that text drawn over a line can be hard to read.
One possible solution is to add a small stroke around the text so it pops against the background.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(volcano_df, aes(Var1, Var2)) +
  geom_contour(aes(z = value, colour = stat(level))) +
  metR::geom_text_contour(aes(z = value), stroke = 0.15) +
  coord_equal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-09-19-contour-labels.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But this is just a workaround and comes with its own hosts of problems.
For example, it doesn’t work all that well when the background colour is not roughly uniform, such as when painting filled contours.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(volcano_df, aes(Var1, Var2)) +
  metR::geom_contour_fill(aes(z = value)) +
  geom_contour(aes(z = value), colour = &amp;quot;black&amp;quot;) +
  metR::geom_text_contour(aes(z = value), stroke = 0.15) +
  coord_equal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-09-19-contour-labels.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The truth is that there is no substitute for actually clipping contour lines so that they don’t intersect with the text.
Which is what the isoband package by Claus Wilke &lt;a href=&#34;https://wilkelab.org/isoband/articles/isoband3.html&#34;&gt;implements&lt;/a&gt; and the new version of metR bundles with its own &lt;code&gt;geom_contor2()&lt;/code&gt;.
Simply map the label aesthetic to the level computed variable and you get lovely labelled contours.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(volcano_df, aes(Var1, Var2)) +
  metR::geom_contour_fill(aes(z = value)) +
  metR::geom_contour2(aes(z = value, label = stat(level))) +
  coord_equal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-09-19-contour-labels.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up a transparent reproducible R environment with Docker &#43; renv</title>
      <link>/en/2021/08/docker-renv/</link>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/en/2021/08/docker-renv/</guid>
      <description>
&lt;script src=&#34;../rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;For my PhD I’m currently &lt;a href=&#34;https://github.com/eliocamp/shceof&#34;&gt;writing a paper using rmarkdown&lt;/a&gt;.
Since I care about reproducibility, I’m using &lt;a href=&#34;https://rstudio.github.io/renv/index.html&#34;&gt;renv&lt;/a&gt; to register the versions of the R packages I use and to manage a local library that doesn’t affect the rest of my system.
With that, anyone who wants to reproduce my work could download all the code, run &lt;code&gt;renv::restore()&lt;/code&gt; and have an R environment very similar to the one I use.&lt;/p&gt;
&lt;p&gt;But while renv is nice, it doesn’t solve the whole problem, because system dependencies and even the R version itself can change.
Another issue is that downloading and installing all the R packages can take a while.
Like an hour or more.
This is not a deal-breaker, but I’d like to do better.
People trying to reproduce work are few and far between, so it’s important to make their lives as easy as possible.&lt;/p&gt;
&lt;p&gt;Thanks to &lt;a href=&#34;https://rweekly.fireside.fm/52&#34;&gt;a recent episode of the R Weekly Highlights podcast&lt;/a&gt;, which pointed me to &lt;a href=&#34;https://rweekly.fireside.fm/52&#34;&gt;this post&lt;/a&gt; by Rahul Sangole on how to set up a reproducible environment with Docker, I have now a better alternative that not only is more reproducible, but it’s potentially much more user-friendly.&lt;/p&gt;
&lt;p&gt;The core idea: &lt;a href=&#34;https://docs.docker.com/get-started/overview/&#34;&gt;Docker&lt;/a&gt; runs basically like a virtual machine inside your computer; you can control which R version you use and which packages are installed.
You can also host a docker image on &lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;, so that anyone can download it and spin it up on their computer within minutes.&lt;/p&gt;
&lt;p&gt;So I could create a docker image, do all the system dependencies and R package dependencies setup that can take an hour or more, and then publish that.
If someone wants to reproduce my work, they can just get the image, run it, and they are ready.
And not only that, but I could also add all the necessary data that also takes hours to download!&lt;/p&gt;
&lt;p&gt;But there’s a &lt;a href=&#34;https://youtu.be/KHMW8fV2NXo?t=1690&#34;&gt;trade-off here between reproducibility and transparency/reusability&lt;/a&gt;.
I could run everything inside the docker image and be completely reproducible.
But then the only way to access the code would be to download and run a heavy virtual machine using a particular technology that some people might not be used to or even have access to (for example, if they can’t install software on their work computers).&lt;/p&gt;
&lt;p&gt;Since I want to be a little more on the transparent side of the spectrum, I want to host the code outside the container in a way that is accessible for anyone and use docker as an easier alternative.
Here’s what I’ve come up with.&lt;/p&gt;
&lt;div id=&#34;my-docker-renv-github-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;My Docker + renv + GitHub solution&lt;/h2&gt;
&lt;p&gt;At the heart of the docker image is the Dockerfile, a plain-text file with a series of commands that are then executed inside the image.
Here’s the Dockerfile I built.
I’ll explain how it works step by step:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;# get the base image, the rocker/verse has R, RStudio and pandoc
FROM rocker/rstudio:4.1.1

# Get and install system dependencies
RUN R -e &amp;quot;install.packages(&amp;#39;remotes&amp;#39;)&amp;quot; \
 &amp;amp;&amp;amp; R -e &amp;quot;remotes::install_github(&amp;#39;r-hub/sysreqs&amp;#39;)&amp;quot;

WORKDIR /home/rstudio/shceof
COPY DESCRIPTION DESCRIPTION
RUN sudo apt update \
 &amp;amp;&amp;amp; R -e &amp;quot;system(sysreqs::sysreq_commands(&amp;#39;DESCRIPTION&amp;#39;, &amp;#39;linux-x86_64-ubuntu-gcc&amp;#39;))&amp;quot; \
 &amp;amp;&amp;amp; apt install -y libmagick++-dev

# Get and install R packages to local library
COPY renv.lock renv.lock
COPY renv/activate.R renv/activate.R
COPY .Rprofile .Rprofile
RUN chown -R rstudio . \
 &amp;amp;&amp;amp; sudo -u rstudio R -e &amp;#39;renv::restore()&amp;#39;

# Copy data to image
COPY analysis/data analysis/data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first line specifies the base image to use:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;# get the base image, the rocker/verse has R, RStudio and pandoc
FROM rocker/rstudio:4.1.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, I use &lt;a href=&#34;https://hub.docker.com/r/rocker/rstudio&#34;&gt;rocker/rstudio&lt;/a&gt;, which comes with R and RStudio pre-installed.
I also fixed the R version to 4.1.1 because is the same I’m using to work locally.&lt;/p&gt;
&lt;p&gt;The next step is to make sure all the necessary system dependencies are installed.
For that, I use the &lt;a href=&#34;https://github.com/r-hub/sysreqs&#34;&gt;sysreqs&lt;/a&gt; package, which can take a DESCRIPTION file and build the command that installs all the dependencies.
Of course, first you need to install it, which first requires the &lt;a href=&#34;https://remotes.r-lib.org/&#34;&gt;remotes&lt;/a&gt; package, because sysreqs is not on CRAN (yeah, it’s quite a ride).&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;# Get and install system dependencies
RUN R -e &amp;quot;install.packages(&amp;#39;remotes&amp;#39;)&amp;quot; \
  &amp;amp;&amp;amp; R -e &amp;quot;remotes::install_github(&amp;#39;r-hub/sysreqs&amp;#39;)&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that each line starts with &lt;code&gt;RUN&lt;/code&gt; followed by a command that could be run on the command-line.
For instance, &lt;code&gt;R -e &#34;install.packages(&#39;remotes&#39;)&#34;&lt;/code&gt; executes &lt;code&gt;install.packages(&#39;remotes&#39;)&lt;/code&gt; on an R session.&lt;/p&gt;
&lt;p&gt;Then, I use the &lt;code&gt;COPY&lt;/code&gt; command to grab the DESCRIPTION file form my local computer and put it in a file called DESCRIPTION in the docker container.
Where exactly?
In the working directory, that I previously set up with &lt;code&gt;WORKDIR&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;WORKDIR /home/rstudio/shceof
COPY DESCRIPTION DESCRIPTION&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally use that DESCRIPTION file to install all the dependencies.
For this project I also had to install libmagick++-dev, winch for some reason was necessary but not being installed.&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;RUN sudo apt update \
 &amp;amp;&amp;amp; R -e &amp;quot;system(sysreqs::sysreq_commands(&amp;#39;DESCRIPTION&amp;#39;, &amp;#39;linux-x86_64-ubuntu-gcc&amp;#39;))&amp;quot; \
 &amp;amp;&amp;amp; apt install -y libmagick++-dev&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now that the image has all the required system dependencies, it’s time to install the R packages.
Since I use renv, the list of packages, along with their versions and their sources are listed on the renv.lock file, so I need to grab that.
I also need the activate.R file in the renv folder, which is a nice little script that autoinstalls the correct version of the renv package.&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;# Get and install R packages to local library
COPY renv.lock renv.lock
COPY renv/activate.R renv/activate.R
COPY .Rprofile .Rprofile
RUN chown -R rstudio . \
 &amp;amp;&amp;amp; sudo -u rstudio R -e &amp;#39;renv::restore()&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that I also had to change the owner of the files to the rstudio user and also restore the packages as the rstudio user.&lt;/p&gt;
&lt;p&gt;At this point, the docker image has an R installation with the correct packages and the correct system dependencies installed.
As a last, optional step, I copy the data folder from my local computer to the image.&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;# Copy data to image
COPY analysis/data analysis/data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In my project, these are about 3 gb worth of data that are publicly available but are somewhat painful to get.
One needs to create an account in the &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/home&#34;&gt;Climate Data Store website&lt;/a&gt; and then set up the credentials as environmental variables.
Then, the process of requesting and downloading the data can take a couple of hours.&lt;/p&gt;
&lt;p&gt;With this Dockerfile done, all it’s left is to build the thing with&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker build . -t name/project&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that the image is built and in my machine, it’s time to publish it for anyone to download.
You need to go to &lt;a href=&#34;https://hub.docker.com/&#34;&gt;dockerhub&lt;/a&gt;, create an account and then log in locally with&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker login&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, just push the image with&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker push name/project&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since all the code is actually hosted outside the container, whoever wants to reproduce it will first have to clone the GitHub repository.
Then, from the root of the repository, they’d run this:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker run --rm -p 8787:8787 -e DISABLE_AUTH=true -v $(pwd):/home/rstudio/shceof -v /home/rstudio/shceof/renv -v /home/rstudio/shceof/analysis/data eliocamp/shceof&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This woudl download the image if necessary and then run it.
And then they’d go to localhost:8787 on any browser to be greeted with an RStudio session with all the things:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../images/docker-rstudio.png&#34; alt=&#34;Screenshot of a browser session with RStudio runnign inside.&#34;/&gt;&lt;/p&gt;
&lt;p&gt;The argument &lt;code&gt;-v $(pwd):/home/rstudio/shceof&lt;/code&gt; mounts the current working directory (the root of the repository) to &lt;code&gt;/home/rstudio/shceof&lt;/code&gt; on the container.
But there’s the detail that &lt;code&gt;/home/rstudio/shceof/renv&lt;/code&gt; and &lt;code&gt;/home/rstudio/shceof/analysis/data&lt;/code&gt; were pre-populated at build time with files that are not available on github.
To make sure that these are not replaced by the versions in the repository (which would be almost empty and completely useless), I added this to the command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;-v /home/rstudio/shceof/renv -v /home/rstudio/shceof/analysis/data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/29181032/add-a-volume-to-docker-but-exclude-a-sub-folder&#34;&gt;For some reason&lt;/a&gt; this functionally excludes these folders from the mount operation and the container then uses it’s own version of the folders.&lt;/p&gt;
&lt;p&gt;I think that this setup stands in a nice place in the reproducibility – transparency spectrum.
Using renv to manage the R dependencies makes it possible for all the code to be available publicly, including a more or less straightforward path to (approximately) replicate the computational environment.
And docker stands as a complementary and potentially faster entry-point that doesn’t hide all of that behind another layer of abstraction.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Make error messages your own</title>
      <link>/en/2021/07/wrapper-stop/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/en/2021/07/wrapper-stop/</guid>
      <description>
&lt;script src=&#34;../rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The &lt;code&gt;stop()&lt;/code&gt; function allows you to terminate the execution of a function if there is a fatal problem.&lt;/p&gt;
&lt;p&gt;For example, imagine this code that calculates the square root of a number but only if the input number is positive.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;real_root &amp;lt;- function(x) {
   if (x &amp;lt; 0) {
      stop(&amp;quot;&amp;#39;x&amp;#39; cannot be negative.&amp;quot;)   
   } 
   sqrt(x)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;real_root(2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.414214&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;real_root(-2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in real_root(-2): &amp;#39;x&amp;#39; cannot be negative.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If x is negative, the function throws an error.
Now let’s imagine that this function is part of a package and that the author wants all error messages to always be in upper case.
And instead of making sure that everything is capitalised, they prefer to use the &lt;code&gt;toupper()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toupper(&amp;quot;lowercase&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;LOWERCASE&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then they decide to write the &lt;code&gt;STOP()&lt;/code&gt; function, which is a loud version of &lt;code&gt;stop()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;STOP &amp;lt;- function(message) {
   stop(toupper(message))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now they create &lt;code&gt;REAL_ROOT()&lt;/code&gt; that uses that loud stop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;REAL_ROOT &amp;lt;- function(x) {
   if (x &amp;lt; 0) {
      STOP(&amp;quot;&amp;#39;x&amp;#39; cannot be negative.&amp;quot;)   
   } 
   sqrt(x)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;REAL_ROOT(2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.414214&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;REAL_ROOT(-2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in STOP(&amp;quot;&amp;#39;x&amp;#39; cannot be negative.&amp;quot;): &amp;#39;X&amp;#39; CANNOT BE NEGATIVE.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It seems to work fine, but there is a slight issue.
Before, the error was coming from inside &lt;code&gt;real_root()&lt;/code&gt;, so the error message gave the user a clue as to where the problem layed (&lt;code&gt;Error in real_root(-2) :...&lt;/code&gt;).
With this new setup, since the error technically occurs inside &lt;code&gt;STOP()&lt;/code&gt;, the error message becomes useless.
Worse, it confuses the user!&lt;/p&gt;
&lt;p&gt;One solution is to directly hide the call:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;STOP &amp;lt;- function(message) {
   stop(toupper(message), call. = FALSE)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;REAL_ROOT(-2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error: &amp;#39;X&amp;#39; CANNOT BE NEGATIVE.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the message isn’t that useful, but at least it’s not actively confusing&lt;/p&gt;
&lt;p&gt;But it would be nice to be able to somehow capture the previous call to be part of the error message.
That is, make the &lt;code&gt;STOP()&lt;/code&gt; function “know” which other expression called it and use that as text for the error message.
And that can be done with the &lt;code&gt;sys.call()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;sys.call()&lt;/code&gt; function captures the code that called a function, but has an argument that allows you to go “backwards” in the expression tree.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;outer_function &amp;lt;- function(x) {
   inner_function(x)
}

inner_function &amp;lt;- function(x) {
   sys.call(x)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;outer_function()&lt;/code&gt; calls &lt;code&gt;inner_function()&lt;/code&gt; with the code &lt;code&gt;inner_function(x)&lt;/code&gt;.
Since &lt;code&gt;x&lt;/code&gt; is 0, &lt;code&gt;inner_function()&lt;/code&gt; executes &lt;code&gt;sys.call(0)&lt;/code&gt;, which returns the last call, which is &lt;code&gt;inner_function(x).&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;outer_function(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## inner_function(x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But with the argument &lt;code&gt;x&lt;/code&gt; set to -1, &lt;code&gt;inner_function()&lt;/code&gt; executes &lt;code&gt;sys.call(-1)&lt;/code&gt;, which returns the penultimate call: &lt;code&gt;outer_function(-1).&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;outer_function(-1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## outer_function(-1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The other piece is the &lt;code&gt;simpleError()&lt;/code&gt; function, which can generate an error object that is then correctly interpreted by &lt;code&gt;stop()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;message &amp;lt;- &amp;quot;this is an error&amp;quot;
error &amp;lt;- simpleError(toupper(message))
stop(error)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error: THIS IS AN ERROR&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Putting the two pieces together, you get:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;STOP &amp;lt;- function(message) {
   error &amp;lt;- simpleError(toupper(message), call = sys.call(-1))
   stop(error)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now &lt;code&gt;REAL_ROOT()&lt;/code&gt; spits out an error as as useful as it is loud&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;REAL_ROOT(-2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in REAL_ROOT(-2): &amp;#39;X&amp;#39; CANNOT BE NEGATIVE.&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The new R pipe</title>
      <link>/en/2021/05/r-pipa-nativa/</link>
      <pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/en/2021/05/r-pipa-nativa/</guid>
      <description>
&lt;script src=&#34;../rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;R 4.1.0 is out!
And if version 4.0.0 made history with the revolutionary change of &lt;code&gt;stringAsFactors = FALSE&lt;/code&gt;, the big splashing news in this next version is the implementation of a native pipe.&lt;/p&gt;
&lt;div id=&#34;the-new-pipe&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The new pipe&lt;/h2&gt;
&lt;p&gt;The “pipe” is one of the most distinctive qualities of tidyverse/dplyr code.
I’m sure you’ve used or seen something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr) 

mtcars %&amp;gt;%
   group_by(cyl) %&amp;gt;% 
   summarise(mpg = mean(mpg)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##     cyl   mpg
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     4  26.7
## 2     6  19.7
## 3     8  15.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That &lt;code&gt;%&amp;gt;%&lt;/code&gt; is the operator that allows you to chain one function after another without the need to assign intermediate variables or deeply-nested parenthesis.
Technically what it’s doing under the hood is evaluating the expression on the right-hand side fo the pipe (or, more usually, on the next line) using the expression on the left (or same line) as the first argument.
The dplyr package depends on the &lt;a href=&#34;https://magrittr.tidyverse.org/&#34;&gt;magrittr&lt;/a&gt; package to do all that magic, and many other packages also import the magrittr pipe.&lt;/p&gt;
&lt;p&gt;With version 4.1.0, it’s now possible to write&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars |&amp;gt;
   group_by(cyl) |&amp;gt;
   summarise(mpg = mean(mpg))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##     cyl   mpg
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     4  26.7
## 2     6  19.7
## 3     8  15.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is the difference, other than one less character?
(Not that the number of characters matters much if one uses the RStudio shortcut Ctrl + Shift + M. And with the new version of RStudio &lt;a href=&#34;https://web.archive.org/web/20210525152348/https://www.rstudio.com/products/rstudio/download/preview/&#34;&gt;which is now in preview&lt;/a&gt;, one can choose which to use).&lt;/p&gt;
&lt;p&gt;The main difference, for me, is that now you can use the pipe without relying on the magrittr package.
Maybe this isn’t something you’ll lose sleep over, but as a rule of thumb it’s always desirable for your analysis to depend on as few different packages as possible.
The more dependencies, the higher the probability of some update changing something important that destroys everything you built.&lt;/p&gt;
&lt;p&gt;For those who use dplyr (or those maniacs that start their scripts with &lt;code&gt;library(tidyverse)&lt;/code&gt;), &lt;code&gt;|&amp;gt;&lt;/code&gt; and &lt;code&gt;%&amp;gt;%&lt;/code&gt; are probably interchangeable.
But there’s a whole multiverse outside the tidyverse.
I, for example, prefer data.table to dplyr and my preferred syntax combines data.table with magrittr.
With this change, I no longer need to start each script with &lt;code&gt;library(magrittr)&lt;/code&gt; (although see &lt;a href=&#34;#what-about-data.table&#34;&gt;the next section&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For those who have an (probably unhealthy?) obsession with speed and efficiency, &lt;code&gt;|&amp;gt;&lt;/code&gt; &lt;a href=&#34;https://michaelbarrowman.co.uk/post/the-new-base-pipe/&#34;&gt;appears to be faster&lt;/a&gt; than &lt;code&gt;%&amp;gt;%&lt;/code&gt;.
This is because magrittr does a lot of stuff behind the scenes, while the native pipe is just a syntax transformation.
In other words,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x %&amp;gt;%
   mean()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is not literally equivalent to &lt;code&gt;mean(x)&lt;/code&gt;; there is a lot of processing behind those three characters.
While&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x |&amp;gt; 
   mean()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is interpreted by R &lt;strong&gt;exactly&lt;/strong&gt; as &lt;code&gt;mean(x)&lt;/code&gt;.
That is, there is zero overhead for using &lt;code&gt;|&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But the reality is that except in very special cases, the difference is negligible.
In any worthwhile data analysis, the overhead of using magrittr is minuscule compared to the time it takes to do (and write!) the rest of the computations.
My advice is not to get bogged down into chasing microsecond-level differences.&lt;/p&gt;
&lt;p&gt;What you do need to pay attention to are the subtle (or not so subtle) differences between the two pipes.
Perhaps the single most important difference is that the magrittr has a placeholder element for when one doesn’t want the left hand side result to go to the &lt;em&gt;first&lt;/em&gt; argument of the right hand expression.
The canonical example is the linear model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
   lm(mpg ~ disp, data = .)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = mpg ~ disp, data = .)
## 
## Coefficients:
## (Intercept)         disp  
##    29.59985     -0.04122&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since the first argument of &lt;code&gt;lm()&lt;/code&gt; is not the data, you have to use &lt;code&gt;data = .&lt;/code&gt; to tell magrittr that &lt;code&gt;mtcars&lt;/code&gt; does not have to be the first argument of &lt;code&gt;lm()&lt;/code&gt;.
The native pipe currently &lt;strong&gt;doesn’t have a placeholder&lt;/strong&gt;.
The way to fix that is to create an anonymous function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars |&amp;gt; 
   (function(x) lm(mpg ~ cyl, data = x))()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = mpg ~ cyl, data = x)
## 
## Coefficients:
## (Intercept)          cyl  
##      37.885       -2.876&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is quite ugly, so R’s answer is to use another trick from R 4.1.0: the new function-creation syntax.
As of R 4.1.0 these two expressions are equivalent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;function(x) x + 1 
\(x) x + 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new “waving-person” syntax ( &lt;code&gt;\(x)&lt;/code&gt;) essentially saves characters when creating functions.
So by combining this with the native pipe, you can do&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars |&amp;gt; 
   (\(x) lm(mpg ~ disp, data = x))() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = mpg ~ disp, data = x)
## 
## Coefficients:
## (Intercept)         disp  
##    29.59985     -0.04122&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is marginally more readable, though still quite ugly.
The alternative syntax, which I think for now is a bit experimental, is this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Sys.setenv(`_R_USE_PIPEBIND_` = TRUE) 

mtcars |&amp;gt; 
   . =&amp;gt; lm(mpg ~ disp, data = .)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = mpg ~ disp, data = mtcars)
## 
## Coefficients:
## (Intercept)         disp  
##    29.59985     -0.04122&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Where the first line is indispensable and strongly signals that this code is not ready or prime time.)&lt;/p&gt;
&lt;p&gt;So you first set the placeholder symbol (in this case &lt;code&gt;.&lt;/code&gt;) and after the &lt;code&gt;=&amp;gt;&lt;/code&gt;, you can write the same code that you would use in the magrittr pipe.
In short, for cases where the &lt;code&gt;.&lt;/code&gt; placeholder &lt;code&gt;.&lt;/code&gt; is used, the replacement for &lt;code&gt;%&amp;gt;%&lt;/code&gt; would be &lt;code&gt;|&amp;gt; . =&amp;gt;&lt;/code&gt;.
(Although, again, I understand that this syntax is neither definitive nor officially supported yet).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-data.table&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What about data.table?&lt;/h2&gt;
&lt;p&gt;Which brings me to my beloved data.table + magrittr syntax:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars &amp;lt;- data.table::as.data.table(mtcars)
mtcars %&amp;gt;% 
   .[, .(mpg = mean(mpg)), by = cyl]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    cyl      mpg
## 1:   6 19.74286
## 2:   4 26.66364
## 3:   8 15.10000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given that the dot at the beginning of the first line is nothing less than magrittr’s placeholder, and that the new pipe has no placeholder, you might correctly guess that this syntax is not going to translate to the native pipe by simply changing &lt;code&gt;%&amp;gt;%&lt;/code&gt; to &lt;code&gt;|&amp;gt;&lt;/code&gt;.
There are also some limitations, such as that the new pipe does not accept “special symbols” like &lt;code&gt;[&lt;/code&gt;, &lt;code&gt;+&lt;/code&gt; or &lt;code&gt;*&lt;/code&gt; in the right expression.&lt;/p&gt;
&lt;p&gt;Remembering the &lt;code&gt;=&amp;gt;&lt;/code&gt; syntax thiny, you would think that the proper translation would be to add &lt;code&gt;|&amp;gt; . =&amp;gt;&lt;/code&gt; but, alas, this is not the case:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars |&amp;gt; 
   . =&amp;gt; .[, .(mpg = mean(mpg)), by = cyl]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error: function &amp;#39;[&amp;#39; not supported in RHS call of a pipe&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ah, the limitation of those special symbols appears.
Where do we go from here?&lt;/p&gt;
&lt;p&gt;The trick is that R only looks at the function name, so all you have to do is rename the &lt;code&gt;[&lt;/code&gt; function (I love that everything in R is a function).
For example, this code is perfectly cromulent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;.d &amp;lt;- `[` 

mtcars |&amp;gt; 
   .d(, .(mpg = mean(mpg)), by = cyl) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    cyl      mpg
## 1:   6 19.74286
## 2:   4 26.66364
## 3:   8 15.10000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which is not so bad.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;long-live-magrittr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Long live magrittr&lt;/h2&gt;
&lt;p&gt;So, do I have to dump &lt;code&gt;%&amp;gt;%&lt;/code&gt; and love &lt;code&gt;|&amp;gt;%&lt;/code&gt;?
Well… not necessarily.&lt;/p&gt;
&lt;p&gt;R 4.1.0 came out just a couple of weeks ago and it’s highly likely that most people haven’t upgraded and have no plans to upgrade anytime soon.
In corporate or server environments, many R users probably don’t even have control over which version they install and administrators are probably rather reticent to upgrade.
“Production-grade code” running on specific versions of R for stability and reproducibility will probably take years to upgrade, if they even upgrade at all.&lt;/p&gt;
&lt;p&gt;For all these reasons, while the magrittr’s days are indeed numbered, this number is still quite big.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Star Trek ratings on IMDB</title>
      <link>/en/2021/03/star-trek-rakings/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/en/2021/03/star-trek-rakings/</guid>
      <description>
&lt;script src=&#34;../rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;My girlfriend and I are watching Star Trek: The Next Generation (TNG). The first season it’s pretty lame, but it gets better further down the line. That piqued my curiosity – is that impression shared by the rest of The Internets? So I decided to download the rating of every TNG episode from IDMB. I quickly realised that IMDB provides much more than just mean reating, it also has the full rating histogram and also demographic breakdowns. So I decided to get those as well.&lt;/p&gt;
&lt;p&gt;And since I was at it, why not loot also at all the Star Trek series?&lt;/p&gt;
&lt;div id=&#34;scraping-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scraping the data&lt;/h2&gt;
&lt;p&gt;First, load the packages. data.table for data analysis, magrittr for cute chains, rvest to scrape and ggplot2 for visualising. ggsci is a package with many colour scales; I use it here becasue &lt;code&gt;ggsci::scale_colour_trek()&lt;/code&gt; is the only logical choice of colour scales in this context.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(rvest)
library(magrittr)
library(ggplot2)
library(ggsci)

theme_set(theme_minimal(14) + 
             theme(panel.grid = element_blank()))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, fucntions to scrape ratings. Each series has &lt;a href=&#34;https://www.imdb.com/title/tt0060028/&#34;&gt;a webpage&lt;/a&gt; with a list of seasons. &lt;code&gt;get_series()&lt;/code&gt; detects those links and scrapes each season with &lt;code&gt;get_season()&lt;/code&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_series_ &amp;lt;- function(id) {
   home_url &amp;lt;- paste0(&amp;quot;https://www.imdb.com/title/&amp;quot;, id)
   message(&amp;quot;Series: &amp;quot;, id)
   seasons &amp;lt;- html_session(home_url) %&amp;gt;% 
      html_nodes(&amp;quot;#title-episode-widget div:nth-child(4) a&amp;quot;) %&amp;gt;% 
      html_text() %&amp;gt;% 
      rev()
   
   data &amp;lt;- lapply(seasons, function(x) get_season(id, x))
   
   rbindlist(data)
}

get_series &amp;lt;- memoise::memoise(get_series_, 
                               cache = memoise::cache_filesystem(&amp;quot;data/star_trek/&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.imdb.com/title/tt0060028/episodes?season=1&#34;&gt;Each season’s webpage&lt;/a&gt; has a table with every episode with its mean rating. Since I also want the detailed breakdown, the function captures the link of each episode and scrapes the detailes with &lt;code&gt;get_details_episode()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_season_ &amp;lt;- function(id, season) {
   message(&amp;quot;Season: &amp;quot;, season)
   url &amp;lt;- paste0(&amp;quot;https://www.imdb.com/title/&amp;quot;, id, &amp;quot;/episodes?season=&amp;quot;, season)
   
   session &amp;lt;- rvest::html_session(url)
   
   titles &amp;lt;- rvest::html_nodes(session, &amp;quot;#episodes_content strong a&amp;quot;) %&amp;gt;% 
      html_attr(&amp;quot;title&amp;quot;) %&amp;gt;% 
      na.omit()
   
   stars &amp;lt;- rvest::html_nodes(session, &amp;quot;.ipl-rating-star.small .ipl-rating-star__rating&amp;quot;) %&amp;gt;% 
      html_text()
   
   if (length(stars) == 0) {
      return(NULL)
   }
   dates &amp;lt;- rvest::html_nodes(session, &amp;quot;.airdate&amp;quot;) %&amp;gt;% 
      html_text() %&amp;gt;% 
      lubridate::dmy()
   
   links &amp;lt;- html_nodes(session, &amp;quot;#episodes_content strong a&amp;quot;) %&amp;gt;% 
      html_attr(&amp;quot;href&amp;quot;) 
   
   links &amp;lt;- links[links != &amp;quot;#void&amp;quot;]
   
   ids &amp;lt;- strsplit(links, &amp;quot;/&amp;quot;) %&amp;gt;% 
      vapply(function(x) x[3], character(1))
   
   rating_details &amp;lt;- lapply(ids, get_details_episode)
   
   data &amp;lt;- data.table::data.table(date = dates, 
                                  number = seq_along(titles),
                                  title = titles,
                                  rating = as.numeric(stars), 
                                  season = season,
                                  details = rating_details
   )
}

get_season &amp;lt;- memoise::memoise(get_season_, 
                               cache = memoise::cache_filesystem(&amp;quot;data/star_trek/&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, &lt;code&gt;get_details_episode()&lt;/code&gt; goes into &lt;a href=&#34;https://www.imdb.com/title/tt0059753/ratings&#34;&gt;each episode’s ratings&lt;/a&gt; and scrapes the rating distribution, the mean rating by gender and the number of ratings by gender.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_details_episode &amp;lt;- function(id) {
   url &amp;lt;- paste0(&amp;quot;https://www.imdb.com/title/&amp;quot;, id, &amp;quot;/ratings&amp;quot;)
   
   session &amp;lt;- html_session(url) 
   
   ratings &amp;lt;- session %&amp;gt;% 
      html_nodes(&amp;quot;td:nth-child(3) .leftAligned&amp;quot;) %&amp;gt;% 
      html_text() %&amp;gt;% 
      trimws() %&amp;gt;% 
      gsub(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;, .) %&amp;gt;% 
      as.numeric()
   
   ratings_gender &amp;lt;- session %&amp;gt;% 
      html_nodes(&amp;quot;table:nth-child(11) .ratingTable:nth-child(2) .bigcell&amp;quot;) %&amp;gt;% 
      html_text() %&amp;gt;% 
      as.numeric()
   
   number_gender &amp;lt;- session %&amp;gt;% 
      html_nodes(&amp;quot;table:nth-child(11) .ratingTable:nth-child(2) a&amp;quot;) %&amp;gt;% 
      html_text() %&amp;gt;% 
      trimws() %&amp;gt;% 
      gsub(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;, .) %&amp;gt;% 
      as.numeric()
   
   data.table::data.table(gender = list(data.table::data.table(gender = c(&amp;quot;All&amp;quot;, &amp;quot;Males&amp;quot;, &amp;quot;Females&amp;quot;),
                                                               rating = ratings_gender,
                                                               N = number_gender)),
                          ratings = list(data.table::data.table(rating = 10:1,
                                                                N = ratings))
   )
   
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final step is manually searching the id of each series of Star Trek.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;star_treks &amp;lt;- c(tos        = &amp;quot;tt0060028&amp;quot;,
                tng        = &amp;quot;tt0092455&amp;quot;,
                ds9        = &amp;quot;tt0106145&amp;quot;,
                voyager    = &amp;quot;tt0112178&amp;quot;,
                enterprise = &amp;quot;tt0244365&amp;quot;,
                discovery  = &amp;quot;tt5171438&amp;quot;
)

labs_st &amp;lt;- setNames(
   c(&amp;quot;The Original Series&amp;quot;, 
     &amp;quot;The Next Generation&amp;quot;,
     &amp;quot;Deep Space 9&amp;quot;,
     &amp;quot;Voyager&amp;quot;, 
     &amp;quot;Enterprise&amp;quot;,
     &amp;quot;Discovery&amp;quot;),
   names(star_treks))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I apply &lt;code&gt;get_series()&lt;/code&gt; to each one and combine the results row-wise with &lt;code&gt;data.table::rbindlist()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- lapply(star_treks, get_series) %&amp;gt;% 
   rbindlist(idcol = &amp;quot;version&amp;quot;) %&amp;gt;% 
   .[, episode := 1:.N, by = version] %&amp;gt;%
   .[, version := factor(version, levels = names(star_treks), ordered = TRUE)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what the data looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    version       date number                        title rating season
## 1:     tos 1988-11-27      1                     The Cage    7.7      1
## 2:     tos 1966-09-08      2                 The Man Trap    7.3      1
## 3:     tos 1966-09-15      3                    Charlie X    7.1      1
## 4:     tos 1966-09-22      4 Where No Man Has Gone Before    7.8      1
## 5:     tos 1966-09-29      5               The Naked Time    7.9      1
## 6:     tos 1966-10-06      6             The Enemy Within    7.7      1
##              details episode
## 1: &amp;lt;data.table[1x2]&amp;gt;       1
## 2: &amp;lt;data.table[1x2]&amp;gt;       2
## 3: &amp;lt;data.table[1x2]&amp;gt;       3
## 4: &amp;lt;data.table[1x2]&amp;gt;       4
## 5: &amp;lt;data.table[1x2]&amp;gt;       5
## 6: &amp;lt;data.table[1x2]&amp;gt;       6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each row is an episode, which has the version of Star Trek that it belongs to, the emission date and other data. So far so good. It gets a bit more tricky with the column &lt;code&gt;details.&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[1, ]$details[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               gender            ratings
## 1: &amp;lt;data.table[3x3]&amp;gt; &amp;lt;data.table[10x2]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each row contains a list that itself contains two tables, “gender” and “ratings”. The “gender” table has the mean rating and number of ratings by gender.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[1, ]$details[[1]]$gender[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     gender rating    N
## 1:     All    7.7 5344
## 2:   Males    7.7 3390
## 3: Females    7.7  470&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The “ratings” table contains the number of ratings for each numeric rating.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[1, ]$details[[1]]$ratings[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     rating    N
##  1:     10  991
##  2:      9  644
##  3:      8 1447
##  4:      7 1271
##  5:      6  577
##  6:      5  220
##  7:      4   73
##  8:      3   40
##  9:      2   32
## 10:      1   49&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;a href=&#34;https://rstudio.com/resources/rstudioconf-2020/list-columns-in-data-table-reducing-the-cognitive-computational-burden-of-complex-data/&#34;&gt;nested table&lt;/a&gt; format is a bit complicated at first, but it’s pretty much the natural choice for these sort of data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysing the data&lt;/h2&gt;
&lt;p&gt;Now that I have all these data, the first thing I want to answer is the original question. How did the public perception of The Next Generation changed for each season?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[version == &amp;quot;tng&amp;quot;] %&amp;gt;% 
   ggplot(aes(episode, rating)) +
   geom_line(aes(color = season, group = 1)) +
   geom_line(data = function(x) copy(x)[, rating := mean(rating), by = season],
             aes(color = season), size = 1) +
   scale_color_startrek(guide = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-03-01-star-trek-ratings.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Did you catch the small trick in the second &lt;code&gt;geom_line()&lt;/code&gt; call? If the &lt;code&gt;data&lt;/code&gt;argument inside geoms is a function, then the data plotted by the geom will be the result of applying that function to the “global” dataframe defined in the &lt;code&gt;ggplot()&lt;/code&gt; call. In this case, it replaces each episode’s rating which the mean rating of the corresponding season).&lt;/p&gt;
&lt;p&gt;The effect is pretty clear. The first two seasons rated rather mediocrely and the show achieved it’s glory only after the third season. After that, the show’s reception is more or less stable, with a slight setback in the seventh and final season. As I translate this from &lt;a href=&#34;../2021/03/star-trek-rakings/&#34;&gt;the Spanish version&lt;/a&gt;, we are on the beginning of the last season and I can confirm that seasons 3 through 6 where quite solid.&lt;/p&gt;
&lt;p&gt;The last episode of the second season jumps out from the screen due to its dreadful reception. And with good reason. For cost-saving reasons, the show producers decided to end the second season with a dreadful clipshow! It’s amazing that the show went on after such terrible season finale.&lt;/p&gt;
&lt;p&gt;How does TNG’s ratings compare with the rest of the Star Trek catalogue?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;% 
   ggplot(aes(episode, rating)) +
   geom_line(aes(color = season, group = 1)) +
   geom_line(data = function(x) copy(x)[, rating := mean(rating), by = .(version, season)],
             aes(color = season), size = 1) +
   scale_color_startrek(guide = &amp;quot;none&amp;quot;) +
   facet_wrap(~version, scales = &amp;quot;free_x&amp;quot;, labeller = labeller(version = labs_st))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-03-01-star-trek-ratings.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It seems like Star Trek, like fine wine, commonly gets better with time. Besides TNG, Deep Space 9, Voyager and Enterprise, they all reached their potential only after a few relatively rocky seasons. The Original Series and Discovery are the exceptions. Both series have only three seasons, and in both series, the third season was the worst rated.&lt;/p&gt;
&lt;p&gt;But, are the fall of Discovery the same as the fall of The Original Series? I’ve seen Discovery’s third season and I didn’t think it was that much worse than the other two. Also, because I live in this century, not only makes me run away screaming from the slow episodes of The Original Series, but also allowed me to experience the popular reaction to Discovery. I know it fell victim of the extreme polarisation that characterises our era.&lt;/p&gt;
&lt;p&gt;A clear symptom of this polarisation is the huge difference between critic reception and audience scores. In Rotten Tomatoes, Discovery’s third season is actually the best rated of the three, with &lt;a href=&#34;https://www.rottentomatoes.com/tv/star_trek_discovery/s03&#34;&gt;a 90% positive score&lt;/a&gt;, even though the audience score is a low 46%. Same goes for &lt;a href=&#34;https://www.metacritic.com/tv/star-trek-discovery&#34;&gt;Metacritic&lt;/a&gt;: the critic mean score – 7.3 – is much higher than the user score – 3.8.&lt;/p&gt;
&lt;p&gt;This is commonly seen when a movie or show offends some subgroup’s sensibilities. Suddenly, you get thousands of trolls rating 1 star en masse. This can be clearly seen by plotting the proportion of 1s and 10s for each episode.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[, details[[1]]$ratings[[1]], by = .(version, season, episode, number)] %&amp;gt;% 
   .[, .(one_star = N[rating == 1]/sum(N),
         ten_star = N[rating == 10]/sum(N)), by = .(episode, version)] %&amp;gt;% 
   melt(id.vars = c(&amp;quot;episode&amp;quot;, &amp;quot;version&amp;quot;)) %&amp;gt;% 
   ggplot(aes(episode, value)) +
   geom_line(aes(color = variable)) +
   scale_color_startrek(name = &amp;quot;Rating %&amp;quot;, labels = c(one_star = &amp;quot;One Star&amp;quot;, 
                                                      ten_star = &amp;quot;Ten Stars&amp;quot;)) +
   facet_wrap(~version, scales = &amp;quot;free_x&amp;quot;, labeller = labeller(version = labs_st))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-03-01-star-trek-ratings.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Save some exceptions, no episode of the old shows has an appreciable proportion of ones. Discovery, on the other hand, consistently has a ~10% of low ratings. In the last episodes, they even outnumber the tens.&lt;/p&gt;
&lt;p&gt;An interesting piece of data in the IMDB website is the breakdown by gender. Sci-fi sadly tends to be a genre dominated by the male gender. Is that reflected in the amount of user ratings?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;% 
   .[, details[[1]]$gender[[1]] , by = .(version, season, episode, number)] %&amp;gt;% 
   .[gender != &amp;quot;All&amp;quot;] %&amp;gt;%
   .[, .(n = sum(N)), by = .(episode, version, gender)] %&amp;gt;% 
   ggplot(aes(episode, n)) +
   geom_line(aes(color = gender)) + 
   scale_color_startrek() +
   scale_y_log10() +
   facet_wrap(~version, scales = &amp;quot;free_x&amp;quot;, labeller = labeller(version = labs_st))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-03-01-star-trek-ratings.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Most definitely! There are so few ratings by women that I had to use a logarithmic scale; otherwise the red line would’ve been almost indistinguishable from zero.&lt;/p&gt;
&lt;p&gt;Interestingly, for every Star Trek and for both genders reported by IMDB there’s a clear tendency of fewer ratings as the episodes progress. I’d wager this is a survivorship effect. Many people begin watching each show from the first episode and register their rating and eventually they get bored and give up. It’s therefore natural that there’s simply more people who watched and are willing to rate the first episodes than the later ones.&lt;/p&gt;
&lt;p&gt;With respect to the gender distribution, the ratio of ratings seems to be more or less stable, with the obvious exception of four episodes from Enterprise which have almost as many female as male ratings.&lt;/p&gt;
&lt;p&gt;These are the 10 episodes with the greatest proportion of female ratings:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;% 
   .[, details[[1]]$gender[[1]] , by = .(version, season, episode, number)] %&amp;gt;% 
   .[gender != &amp;quot;All&amp;quot;] %&amp;gt;%
   .[, .(n = sum(N)), by = .(episode, version, gender)] %&amp;gt;% 
   dcast(episode + version ~ gender, value.var = &amp;quot;n&amp;quot;) %&amp;gt;% 
   .[, ratio := Females/Males] %&amp;gt;% 
   
   data[., on = .NATURAL] %&amp;gt;% 
   .[order(-ratio)] %&amp;gt;%
   .[1:10] %&amp;gt;% 
   .[, .(version, season, number, title, rating, ratio = scales::percent(ratio, accuracy = 0.1))] %&amp;gt;% 
   knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;version&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;season&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;number&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;title&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;rating&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;enterprise&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Home&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;enterprise&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Shockwave, Part II&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;68.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;enterprise&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Regeneration&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;enterprise&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Broken Bow&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;51.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tos&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;The Trouble with Tribbles&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;18.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;voyager&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Retrospect&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;17.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;voyager&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Resolutions&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;voyager&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Blood Fever&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tos&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Requiem for Methuselah&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tos&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Journey to Babel&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I’ve never seen Enterprise so I have absolutely no idea if there’s anything special about those four episodes which seem to be uncharacteristically popular with women.&lt;/p&gt;
&lt;p&gt;Still, it’s not easy to compare the ratio of ratings by men and women in the previous figure, so it’s better to just plot that variable.¡&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;% 
   .[, details[[1]]$gender[[1]] , by = .(version, season, episode, number)] %&amp;gt;% 
   .[gender != &amp;quot;All&amp;quot;] %&amp;gt;%
   .[, .(n = sum(N)), by = .(episode, version, gender)] %&amp;gt;% 
   dcast(episode + version ~ gender, value.var = &amp;quot;n&amp;quot;) %&amp;gt;% 
   .[, run := scales::rescale(episode, to = c(0, 1)), by = version] %&amp;gt;% 
   ggplot(aes(run, Females/Males)) +
   geom_line(aes(color = version)) +
   scale_y_log10() +
   scale_color_startrek( labels = labs_st) +
   coord_cartesian(ylim = c(NA, 0.2)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-03-01-star-trek-ratings.en_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Beside those Enterprise peaks, what’s more salient is the brutal drop in the proportion of female ratings towards the last season of Discovery. What happened there? My hypothesis is that men where overrepresented in the the troll horde that attacked Discovery.&lt;/p&gt;
&lt;p&gt;Setting aside those four episodes of Enterprise, The Original Series and Voyager are neck to neck as the shows with the greatest overall proportion of female ratings. The differences are not huge, though, and to the extent that IDMB ratings are representative of the overall Star Trek audience, about 80% of the viewers are male.&lt;/p&gt;
&lt;p&gt;So men rate more episode than women, is there a difference in the mean score?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;% 
   .[, details[[1]]$gender[[1]] , by = .(version, season, episode, number)] %&amp;gt;% 
   .[gender != &amp;quot;All&amp;quot;] %&amp;gt;%
   ggplot(aes(episode, rating)) +
   geom_line(aes(color = gender))  +
   scale_color_startrek() + 
   facet_wrap(~version, scales = &amp;quot;free_x&amp;quot;, labeller = labeller(version = labs_st))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-03-01-star-trek-ratings.en_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, but not much. In general, women tend to score episodes with higher ratings. This might be a selection bias effect. Start Trek is a show generally marketed towards men, so the few women who watch the series and take the time to go to IMDB to rate it are a self selected group who might like the show more than the average viewer. Strangely to me, women don’t seem to score particularly high those episodes of Enterprise particularly popular with women.&lt;/p&gt;
&lt;p&gt;Discovery is, again, a clear outlier. The mean score difference between genders reported by IMDB is a bit higher at the start of the series and it widens dramatically in its final season. Women scores tended to be reactively constant, but men appear to not have liked that season at all. This is consistent with my “male trolls” hypothesis.&lt;/p&gt;
&lt;p&gt;To somehow quantify this “troll effect”, I’ll use the fact that women’s ratings remained constant both in amount and mean score. Assuming then that this subpopulation of users behaved the same during the whole run of the show, I’ll use it as a predictor to predict the amount of ratings by men. This will serve as a first approximation of the number of “extra” ratings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;discovery_ratings &amp;lt;- data %&amp;gt;% 
   .[, details[[1]]$gender[[1]] , by = .(version, season, episode, number)] %&amp;gt;% 
   # .[gender != &amp;quot;All&amp;quot;] %&amp;gt;%
   .[, .(n = sum(N)), by = .(episode, version, season, gender)] %&amp;gt;% 
   .[version == &amp;quot;discovery&amp;quot;] %&amp;gt;%
   dcast(version + episode + season ~ gender, value.var = &amp;quot;n&amp;quot;) 

model &amp;lt;- discovery_ratings %&amp;gt;% 
   .[episode &amp;lt;= 20] %&amp;gt;% 
   lm(Males ~ Females-1, data = .)

discovery_ratings[, predicted := predict(model, newdata = discovery_ratings)]

extra &amp;lt;- discovery_ratings %&amp;gt;% 
   .[, .(Males = sum(Males),
         Females = sum(Females),
         predicted = sum(predicted)), by = .(version, season)]

discovery_ratings %&amp;gt;% 
   ggplot(aes(Females, Males)) +
   
   geom_segment(data = ~.x[season == 3], aes(xend = Females, yend = predicted)) +
   geom_point(aes(color = season)) +
   # geom_line(aes(color = season, y = predicted)) +
   
   geom_smooth(method = &amp;quot;lm&amp;quot;, formula = y ~ x-1, data = ~.x[episode &amp;lt; 20], fullrange = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2021-03-01-star-trek-ratings.en_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Those blue dots above the line represent the extra ratings by men during the third season. In total they sum to 5138 ratings, which translate to about 25% of all male ratings.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Note that I use &lt;code&gt;memomise&lt;/code&gt; to cache the results. This is great to speed up the iterative development of these functions and also to annoy IMDB a little less.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Rammstein vs. Lacrimosa</title>
      <link>/en/2019/11/rammstein-vs-lacrimosa/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/en/2019/11/rammstein-vs-lacrimosa/</guid>
      <description>
&lt;script src=&#34;../rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;../rmarkdown-libs/pymjs/pym.v1.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;../rmarkdown-libs/widgetframe-binding/widgetframe.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Some time ago, someone I follow on twitter posted about having to buy a whole book with rules to tease out grammatical gender in German. Further down the replies, someone reminisced about trying (and failing) to learn German just by listening to Rammstein’s lyrics. I studied about drei Jahre of German at the same time I started listening to Rammstein and other German-speaking bands and I’ve always found Rammstein’s lyrics to be surprisingly simple. So simple, in fact, that I suspect that Till Lindemann intentionally dumbs down his writing to cater to the English speaking word and, in particular, to beginner-level German students&lt;/p&gt;
&lt;p&gt;I decided I wanted to see if this vague idea had any merit. So I downloaded Rammstein’s lyrics and measured it’s complexity. As a benchmark, I compared them with Lacrimosa’s lyrics, another German-speaking band from my youth.&lt;/p&gt;
&lt;div id=&#34;a-taste-of-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A taste of the data&lt;/h2&gt;
&lt;p&gt;For those not familiar with either band, this is the chorus from Rammstein’s &lt;a href=&#34;https://www.youtube.com/watch?v=StZcUAPRRac&#34;&gt;Sonne&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Eins, hier kommt die Sonne.&lt;br /&gt;
Zwei, hier kommt die Sonne.&lt;br /&gt;
Drei, sie ist der hellste Stern von allen.&lt;br /&gt;
Vier, hier kommt die Sonne.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, the song does have some complex meaning and interesting uses of metaphor, but the sentence structure is painfully simple. Not only that, but since it repeats the numbers one through ten over and over again, I cannot shake the feeling that it’s a song designed to help children learn the numbers.&lt;/p&gt;
&lt;p&gt;On the other hand, here’s a part of Lacrimosa’s &lt;a href=&#34;https://www.youtube.com/watch?v=cSXaWvFFXuI&#34;&gt;Warum so Tief&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Warum so tief - und warum gerade jetzt?&lt;br /&gt;
Warum vor ihr - warum diese Ironie?&lt;br /&gt;
Warum so hart - und warum nicht einfach besiegt?&lt;br /&gt;
Muss ich denn wirklich für jede Begegnung&lt;br /&gt;
für immer und ewig mit all meiner Liebe bezahlen?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Einmal ohne das eine und endgültige Gefühl - verloren zu sein&lt;br /&gt;
Nur einmal bei ihr - keine Tobsucht in Ketten&lt;br /&gt;
Doch ich kann es nicht ’mal bestreiten - dass ich euch liebe&lt;br /&gt;
Mutter Angst und Vater Schmerz&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I believe the contrast is obvious. In particular, the last two verses of the first stanza make up a surprisingly long sentence, specially for a song.&lt;/p&gt;
&lt;p&gt;These two examples were, of course, cherry-picked to make a point. So let’s try to quantify and analyse all songs from each band.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting the data&lt;/h2&gt;
&lt;p&gt;I want lyrics for every studio album by each band. I could try to automate this by scrapping, say, the respective &lt;a href=&#34;https://en.wikipedia.org/wiki/Lacrimosa_(band)&#34;&gt;wikipedia article&lt;/a&gt;, but it was easier to do it by hand.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(magrittr)
library(ggplot2)

theme_set(hrbrthemes::theme_ipsum_rc())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lacrimosa &amp;lt;- data.table(
   album = c(&amp;quot;Angst&amp;quot;, &amp;quot;Einsemkeit&amp;quot;, &amp;quot;Satura&amp;quot;, &amp;quot;Inferno&amp;quot;, &amp;quot;Stille&amp;quot;, &amp;quot;Elodia&amp;quot;, &amp;quot;Fassade&amp;quot;, &amp;quot;Echos&amp;quot;, 
             &amp;quot;Lichtgestalt&amp;quot;, &amp;quot;Sehnsucht&amp;quot;, &amp;quot;Revolution&amp;quot;, &amp;quot;Hoffnung&amp;quot;, &amp;quot;Testimonium&amp;quot;),
   year = c(1991, 1992, 1993, 1995, 1997, 1999, 2001, 2003,
            2005, 2009, 2012, 2015, 2017)
)

rammstein &amp;lt;- data.table(
   album = c(&amp;quot;Herzeleid&amp;quot;, &amp;quot;Sehnsucht&amp;quot;, &amp;quot;Mutter&amp;quot;, &amp;quot;Reise Reise&amp;quot;, &amp;quot;Rosenrot&amp;quot;, 
             &amp;quot;Liebe ist fur alle da&amp;quot;,  &amp;quot;Rammstein&amp;quot;),
   year = c(1995, 1997, 2001, 2004, 2005, 2009, 2019)
)

albums &amp;lt;- rbindlist(list(Lacrimosa = lacrimosa, 
                         Rammstein = rammstein), 
                    idcol = &amp;quot;artist&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, there’s a neat &lt;a href=&#34;https://github.com/JosiahParry/genius&#34;&gt;genius&lt;/a&gt; package that can download lyrics from, you guessed it, the popular website &lt;a href=&#34;https://genius.com/&#34;&gt;Genius&lt;/a&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. You can “enrich” a dataframe with all the lyrics for each album of each artist like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;albums &amp;lt;- albums %&amp;gt;% 
   genius::add_genius(artist, album) %&amp;gt;% 
   as.data.table() %&amp;gt;% 
   .[artist == &amp;quot;Lacrimosa&amp;quot; &amp;amp; album == &amp;quot;Sehnsucht&amp;quot;, album := &amp;quot;Sehnsucht (L)&amp;quot;]  
# (Both bands have an album named Sehnsucht)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now each row of &lt;code&gt;albums&lt;/code&gt; holds each verse of each song of each album of each artist.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DT::datatable(albums) %&amp;gt;% 
   widgetframe::frameWidget()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:480px;&#34; class=&#34;widgetframe html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;url&#34;:&#34;/post/2019-11-20-rammstein-vs-lacrimosa.en_files/figure-html//widgets/widget_unnamed-chunk-4.html&#34;,&#34;options&#34;:{&#34;xdomain&#34;:&#34;*&#34;,&#34;allowfullscreen&#34;:false,&#34;lazyload&#34;:false}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;readability-of-rammsteins-lyrics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Readability of Rammstein’s lyrics&lt;/h2&gt;
&lt;p&gt;With these data I can begin to test my hypothesis. But how? I’ll score the &lt;a href=&#34;https://en.wikipedia.org/wiki/Readability&#34;&gt;readability&lt;/a&gt; of each song lyric. My hunch is that Rammstein’s lyrics will have a low score on readability (i.e. they are simpler) than Lacrimosa’s. The issue here is that, from what I can tell, most measures of readability are based on the English language. This is a huge problem for text analysis in any language other than English. In this case, a bit of quick googling lead me to the &lt;a href=&#34;https://en.wikipedia.org/wiki/SMOG&#34;&gt;SMOG&lt;/a&gt; readability score, which has a variant adapted to German implemented in the &lt;a href=&#34;https://quanteda.io/&#34;&gt;quantea&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;Related to this, that not all songs by these bands are in German. Most albums by Lacrimosa, for example, have at least one song in English (often voiced by Anne Nurmi instead of Tilo Wolff). So I’ll need to detect them and remove them from my analysis. Again, a bit of googling lead me to the &lt;a href=&#34;https://cran.r-project.org/web/packages/textcat/index.html&#34;&gt;textcat&lt;/a&gt; package, which I will consider a black box algorithm because at this point I’m done going through rabbit holes. 🐰&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Join all verses from each song
full_lyrics &amp;lt;- albums %&amp;gt;% 
   na.omit() %&amp;gt;% 
   .[, .(lyric = paste0(lyric, collapse = &amp;quot;.\n&amp;quot;) ), 
     by = .(artist, album, year, track_title)]

# Get the language
full_lyrics[, language := textcat::textcat(lyric), 
            by = .(track_title, artist, album)]

# How many songs for each language?
full_lyrics %&amp;gt;% 
   .[, .N, by = .(artist, language)] %&amp;gt;% 
   .[order(-N)] %&amp;gt;% 
   knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;artist&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;language&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Lacrimosa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;german&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Rammstein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;german&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;75&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Lacrimosa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;english&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Rammstein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;scots&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Lacrimosa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;scots&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Lacrimosa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;catalan&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Lacrimosa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;romanian&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Lacrimosa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;finnish&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Rammstein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;english&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Rammstein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;portuguese&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As expected, most songs by either band are in German and a non negligible part of Lacrimosa’s are in English. The algorithm seems to be fooled by some lyrics, though. I inspected the individual cases. All songs marked as “scots” are actually in English. The songs allegedly in Catalan or Romanian are actually a instrumental songs which {genius} seems to have messed up. The one in “Portuguese” is actually Rammstein’s “Te quiero, Puta” which is actually in Spanish. Finally, Lacrimosa’s Vankina is really in Finnish.&lt;/p&gt;
&lt;p&gt;Note that since song lyrics are in verse and don’t have punctuation I had to make the bold choice of assuming that each verse is it’s own sentence.&lt;/p&gt;
&lt;p&gt;Another important limitation is that since these readability scores are based on prose, their validity is not garanteed in the case of poetry.&lt;/p&gt;
&lt;p&gt;In any case, computing the readability score for only the German lyrics we get this&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_lyrics[language == &amp;quot;german&amp;quot;,
            &amp;quot;SMOG&amp;quot; := quanteda::textstat_readability(lyric, measure = &amp;quot;SMOG.de&amp;quot;)$SMOG.de]

full_lyrics %&amp;gt;%  
   .[language %in% &amp;quot;german&amp;quot;] %&amp;gt;% 
   ggplot(aes(SMOG)) +
   geom_density(aes(color = artist)) +
   geom_rug(aes(color = artist)) +
   scale_color_brewer(&amp;quot;Artist&amp;quot;, palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-11-20-rammstein-vs-lacrimosa.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So…hypothesis confirmed? Rammstein’s lyrics are definitely on the simple side. That said, they do own the 3 most complex songs in the dataset. However, this might be a bit misleading. Let’s look at the most complex song.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_lyrics[which.max(SMOG)] %&amp;gt;% 
   with(cat(lyric))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Bewahret einander vor Herzeleid.
## Denn kurz ist die Zeit die ihr beisammen seid.
## Denn wenn euch auch viele Jahre vereinen.
## Einst werden sie wie Minuten euch scheinen.
## Herzeleid.
## Bewahret einander vor der Zweisamkeit&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Herzeleid is a short song (lyric-wise) and not terribly complicated. But it does feature some longer words. Ironically, these lyrics are actually based on a tradicional poem that can be found adorning several homes&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;../post/2019-11-20-rammstein-vs-lacrimosa_files/herzeleid.png&#34; alt=&#34;Herzeleid poem&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Herzeleid poem&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;SImilarly, the second most complex song -Zeig dich- features almost exclusively two-word verses. So really I’m not terribly confident about this result. On the other end of the spectrum, though, it really makes sense.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_lyrics[which.min(SMOG)] %&amp;gt;% 
   with(cat(lyric))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Du, du hast, du hast mich.
## Du, du hast, du hast mich.
## Du, du hast, du hast mich.
## Du, du hast, du hast mich.
## Du, du hast, du hast mich, du hast mich.
## Du hast mich gefragt, du hast mich gefragt.
## Du hast mich gefragt und ich hab&amp;#39; nichts gesagt.
## Willst du bis der Tod euch scheidet.
## Treu ihr sein für alle Tage?(Ja) Nein.
## (Ja) Nein.
## Willst du bis zum Tod, der scheide.
## Sie lieben auch in schlechten Tagen?(Ja) Nein.
## (Ja) Nein.
## Du, du hast, du hast mich.
## Du, du hast, du hast mich.
## Du, du hast, du hast mich, du hast mich.
## Du hast mich gefragt, du hast mich gefragt.
## Du hast mich gefragt und ich hab&amp;#39; nichts gesagt.
## Willst du bis der Tod euch scheidet.
## Treu ihr sein für alle Tage?(Ja) Nein.
## (Ja) Nein.
## Willst du bis zum Tod, der scheide.
## Sie lieben auch in schlechten Tagen?(Ja) Nein.
## (Ja) Nein.
## Willst du bis der Tod euch scheidet.
## Treu ihr sein(Ja) Nein.
## (Ja) Nein&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The simplest song of all is, no surprise, Du hast. It’s a rather ‘dumb’ song, at least in terms of readability. It’s got very short verses, very short words and very simple structure. What the SMOG score doesn’t capture, though, is that it’s also very repetitive. There are essentially only 3 distinct stanzas!&lt;/p&gt;
&lt;p&gt;This observation again resonates with my experience with both bands. Rammstein adheres fully to the traditional song structure of verses, choruses and bridges while Lacrimosa is no stranger to more “prose-like” lyrics with little in the way of repetition. For example, &lt;a href=&#34;https://www.youtube.com/watch?v=qdzI88X4YZk&#34;&gt;Der Strasse der Zeit&lt;/a&gt; has no chorus at all and, thus, counting the proportion of unique verses in that song we see that only about 7% of the lines are duplicated.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;albums[track_title == &amp;quot;Die Strasse der Zeit&amp;quot;] %&amp;gt;% 
   .[, mean(duplicated(lyric))]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.07017544&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Extending this counting method to both band’s respective discographies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;albums %&amp;gt;% 
   .[, .(repetition = mean(duplicated(lyric)), .N), by = .(track_title, artist)] %&amp;gt;% 
   ggplot(aes(repetition)) +
   geom_density(aes(color = artist)) +
   geom_rug(aes(color = artist)) +
   scale_color_brewer(&amp;quot;Artist&amp;quot;, palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-11-20-rammstein-vs-lacrimosa.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Woah! The difference here is outstanding! Unlike Rammstein, who happily write lyrics with 30% of repetition or higher, few of Lacrimosas’s songs repeat more than 20% of its verses. Indeed, a sizeable chunk of their songs feature no repetition at all!&lt;/p&gt;
&lt;p&gt;Putting both measures together, we get a clear separation between both bands.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_lyrics %&amp;gt;% 
   .[language == &amp;quot;german&amp;quot;] %&amp;gt;% 
   .[, repetition := mean(duplicated(strsplit(lyric, &amp;quot;.\n&amp;quot;)[[1]])), 
     by = .(track_title, artist)] %&amp;gt;% 
   ggplot(aes(repetition, SMOG)) +
   geom_point(aes(color = artist)) +
   geom_density_2d(aes(color = artist), adjust = 1.5, bins = 4) +
   scale_color_brewer(&amp;quot;Artist&amp;quot;, palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-11-20-rammstein-vs-lacrimosa.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rammstein’s songs are generally simpler and feature a boatload more repetition.&lt;/p&gt;
&lt;p&gt;Not only Rammstein repeats verses willy-nilly, but those verses are often not even full-fledged sentences. This can be inferred by using log odds ratios between both artists to distinguish very “rammstein-like” vs “lacrimosa-like” pairs of words:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_lyrics %&amp;gt;% 
   .[language == &amp;quot;german&amp;quot;] %&amp;gt;% 
   .[, tidytext::unnest_tokens(.SD, word, lyric, token = &amp;quot;ngrams&amp;quot;, n = 2), 
     by = .(track_title, artist)] %&amp;gt;% 
   .[, .N, by = .(word, artist)] %&amp;gt;% 
   .[!is.na(word)] %&amp;gt;% 
   tidylo::bind_log_odds(artist, word, N) %&amp;gt;% 
   .[order(-log_odds)] %&amp;gt;% 
   .[, .SD[1:10], by = artist] %&amp;gt;% 
   .[, word := tidytext::reorder_within(word, log_odds, artist)] %&amp;gt;% 
   ggplot(aes(word, log_odds)) +
   geom_col() +
   tidytext::scale_x_reordered() +
   coord_flip() +
   facet_wrap(~artist, scales = &amp;quot;free&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-11-20-rammstein-vs-lacrimosa.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The pair of words that distinguish Lacrimsoa’s lyrics are common parts of syntactically correct sentences, such as “so wie” (“such as”) or “das ist” (“this is”). Rammstein lyrics, on the other hand, are distinguished by repeated pairs of words with no syntactic structure, such as “bang bang”, “link zwo” (“left two”; the complete verse is “left two three four”), and “zwiter zwiter”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simplicity-lack-of-quality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simplicity ≠ lack of quality&lt;/h2&gt;
&lt;p&gt;I had some fun learning some crude and basic tools of text data manipulation, but there’s nothing earth-shattering about the conclusion that Rammstein’s lyrics are generally simpler and more “song-like” than Lacrimosa’s. You don’t need webscrapping or R, you just need the ability to listen to music.&lt;/p&gt;
&lt;p&gt;What’s more important, no law states that longer, more complex lyrics equal better songs. Du Hast might be exceedingly simple by any measure, but it does feature some interesting word play and reversal of expectations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;There is also the &lt;a href=&#34;https://github.com/ewenme/geniusr&#34;&gt;geniusr&lt;/a&gt; package which makes use of the official genius API and therefore should be preferred for more intensive use. However, I discovered after I’ve already written most of this code.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why I love data.table</title>
      <link>/en/2019/07/why-i-love-data-table/</link>
      <pubDate>Sat, 06 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/en/2019/07/why-i-love-data-table/</guid>
      <description>


&lt;p&gt;I’ve been an R user for a few years now and the &lt;a href=&#34;https://github.com/Rdatatable/data.table/wiki&#34;&gt;data.table&lt;/a&gt; package has been my staple package for most of it. In this post I wanted to talk about why almost every script and RMarkdown report I write start with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;my-memory-issues&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;My memory issues&lt;/h1&gt;
&lt;p&gt;I started working on my &lt;a href=&#34;https://en.wikipedia.org/wiki/Licentiate_(degree)&#34;&gt;licenciate&lt;/a&gt; thesis (the argentinian equivalent to a Masters Degree) around mid 2016. I had been using R for school work and fun for some time and knew that I wanted to perform all my analysis in R and write my thesis in RMarkdown. In the end, &lt;a href=&#34;https://github.com/eliocamp/tesis/&#34;&gt;I did&lt;/a&gt; but in the process I had to learn new tools and also create my own (which materialised in the &lt;a href=&#34;https://eliocamp.github.io/metR/&#34;&gt;metR package&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The big problem I encountered early on was how to store and manipulate data. My main source of data were the output of atmospheric models which are stored usually in regularly spaced grids. The most natural way to store that kind of data would be in a multidimensional array like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;file &amp;lt;- &amp;quot;~/DATOS/NCEP Reanalysis/air.mon.mean.nc&amp;quot;
subset &amp;lt;- list(level = 1000:800, 
               time = c(&amp;quot;1979-01-01&amp;quot;, &amp;quot;2018-12-01&amp;quot;))
temperature &amp;lt;- metR::ReadNetCDF(file, 
                                subset = subset,
                                out = &amp;quot;array&amp;quot;)[[1]]
str(temperature)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  num [1:144, 1:73, 1:3, 1:473] -30.5 -30.5 -30.5 -30.5 -30.5 ...
##  - attr(*, &amp;quot;dimnames&amp;quot;)=List of 4
##   ..$ lon  : chr [1:144] &amp;quot;0&amp;quot; &amp;quot;2.5&amp;quot; &amp;quot;5&amp;quot; &amp;quot;7.5&amp;quot; ...
##   ..$ lat  : chr [1:73] &amp;quot;90&amp;quot; &amp;quot;87.5&amp;quot; &amp;quot;85&amp;quot; &amp;quot;82.5&amp;quot; ...
##   ..$ level: chr [1:3] &amp;quot;1000&amp;quot; &amp;quot;925&amp;quot; &amp;quot;850&amp;quot;
##   ..$ time : chr [1:473] &amp;quot;1979-01-01&amp;quot; &amp;quot;1979-02-01&amp;quot; &amp;quot;1979-03-01&amp;quot; &amp;quot;1979-04-01&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is very memory-efficient, but it doesn’t play well with a tidydata framework. Subsetting, filtering and operating on groups using arrays is rather awkward –not to mention that dimensions can only be characters! Furthermore, I had to transform it to a dataframe each time I wanted to plot it with ggplot2. What I needed was something more like this&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temperature &amp;lt;- metR::ReadNetCDF(file, subset = subset)
str(temperature)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;data.table&amp;#39; and &amp;#39;data.frame&amp;#39;:   14916528 obs. of  5 variables:
##  $ level: num  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
##  $ lat  : num  90 90 90 90 90 90 90 90 90 90 ...
##  $ lon  : num  0 2.5 5 7.5 10 12.5 15 17.5 20 22.5 ...
##  $ air  : num  -30.5 -30.5 -30.5 -30.5 -30.5 ...
##  $ time : POSIXct, format: &amp;quot;1979-01-01&amp;quot; &amp;quot;1979-01-01&amp;quot; ...
##  - attr(*, &amp;quot;.internal.selfref&amp;quot;)=&amp;lt;externalptr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem is that this representation is much less memory-efficient and my aging laptop couldn’t handle it. While it would eventually read it, even the simplest operation would crash my R session. This was due to the fact that R loooves to &lt;a href=&#34;http://adv-r.had.co.nz/memory.html#modification&#34;&gt;copy on modify&lt;/a&gt; and this is deadly if you’re dealing with data that fits on your memory but just barely.&lt;/p&gt;
&lt;p&gt;Enter data.table and its &lt;a href=&#34;https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reference-semantics.html&#34;&gt;modify by reference&lt;/a&gt; functionality. Unlike regular data.frames or tibbles, data.table objects can be easily modified without copying the entire object! And this means that you can safely work with objects that take more than half your available RAM.&lt;/p&gt;
&lt;p&gt;For this reason I often say that without data.table I wouldn’t have gotten my degree!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;come-for-the-performance-stay-for-the-syntax&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Come for the performance, stay for the syntax&lt;/h1&gt;
&lt;p&gt;But while my introduction to data.table was inspired by the need for memory optimisation, I quickly learned to love it’s minimalistic syntax.&lt;/p&gt;
&lt;p&gt;The basic form of data.table syntax is a very elegant extension of the classic data.frame. This is great because if you already use data.frames, then there’s no need to learn about a whole nother family of functions to do what you already did. In fact, data.tables are mostly just smarter data.frames. For example, if I wanted to filter only the northern hemisphere on my temperature dataset, with a regular data.frame I would have to use&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temperature_df &amp;lt;- as.data.frame(temperature)
head(temperature_df[temperature_df$lat &amp;gt;= 0, ])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   level lat  lon       air       time
## 1  1000  90  0.0 -30.49999 1979-01-01
## 2  1000  90  2.5 -30.49999 1979-01-01
## 3  1000  90  5.0 -30.49999 1979-01-01
## 4  1000  90  7.5 -30.49999 1979-01-01
## 5  1000  90 10.0 -30.49999 1979-01-01
## 6  1000  90 12.5 -30.49999 1979-01-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But who’s got the time to write all that? I can barely stay awake after typing &lt;code&gt;temperature_df&lt;/code&gt; so many times 😴! data.table is smart enough to realise that when I write “lat” inside my data, I’m talking about the column whose name is “lat” –what else could I mean? It’s also smart enough that if I omit that last comma, it knows that I want every column (good riddance, “undefined columns selected”!). So it all reduces to&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(temperature[lat &amp;gt;= 0])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    level lat  lon       air       time
## 1:  1000  90  0.0 -30.49999 1979-01-01
## 2:  1000  90  2.5 -30.49999 1979-01-01
## 3:  1000  90  5.0 -30.49999 1979-01-01
## 4:  1000  90  7.5 -30.49999 1979-01-01
## 5:  1000  90 10.0 -30.49999 1979-01-01
## 6:  1000  90 12.5 -30.49999 1979-01-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Isn’t that gorgeous? But there’s even more. The second argument inside the brackets allows one to select columns, so if I wanted to get the mean temperature, I could write this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(temperature_df[, &amp;quot;air&amp;quot;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.916081&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But with all those quotes I fear for the integrity of my “shift” and “two” keys. Also, what if I wanted to apply complex operation on multiple columns? I would be repeating &lt;code&gt;temperature_df&lt;/code&gt; like a broken record while drowning in a sea of quotation marks! Again, since data.table is smart enough to know that when I’m inside a data.table I’m usually operating on its columns, I can just write this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temperature[, mean(air)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.916081&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Exquisite! The beautiful thing is that this works with &lt;strong&gt;any expresion&lt;/strong&gt;QQ, which means that, again, I can apply all my previous base R knowledge without having to learn a whole new set of functions or operations.&lt;/p&gt;
&lt;p&gt;The last wonderful basic building block of data.table syntax is the &lt;code&gt;by&lt;/code&gt; argument. I often need to split the data in groups, apply some function and the join it all together. Using a normal data.frame this could be done artisanally with a for loop, or the more industrialised &lt;code&gt;by()&lt;/code&gt; function or &lt;code&gt;tapply()&lt;/code&gt; (maybe, I’ve never really understood how it works). But not only would I hurt my hand due to repetitive typing, but I would also fall prey to memory issues. With data.table, applying any function to each group of the data is a breeze:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(temperature[, mean(air), by = .(lat, level)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     lat level        V1
## 1: 90.0  1000 -15.11903
## 2: 87.5  1000 -15.18808
## 3: 85.0  1000 -15.07319
## 4: 82.5  1000 -14.25968
## 5: 80.0  1000 -12.75084
## 6: 77.5  1000 -11.06509&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With just a slight change I can create a new column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temperature[, mean_air := mean(air), by = .(lat, level)]
head(temperature)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    level lat  lon       air       time  mean_air
## 1:  1000  90  0.0 -30.49999 1979-01-01 -15.11903
## 2:  1000  90  2.5 -30.49999 1979-01-01 -15.11903
## 3:  1000  90  5.0 -30.49999 1979-01-01 -15.11903
## 4:  1000  90  7.5 -30.49999 1979-01-01 -15.11903
## 5:  1000  90 10.0 -30.49999 1979-01-01 -15.11903
## 6:  1000  90 12.5 -30.49999 1979-01-01 -15.11903&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here lays maybe the biggest departure from the classic data.frame. The &lt;code&gt;:=&lt;/code&gt; operator adds columns by reference, which means that there’s no need to assign the result to a new variable! That is, there’s no need to use &lt;code&gt;temperature &amp;lt;- temperature[, mean_air := mean(air), by = .(lat, level)]&lt;/code&gt;. If you remember all the stuff above about memory efficiency then you understand why it’s a very useful feature for me.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;this-is-not-a-pipe&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;This is not a pipe&lt;/h1&gt;
&lt;p&gt;data.table has its own idiomatic way of chaining operation but I prefer to use pipes (&lt;code&gt;%&amp;gt;%&lt;/code&gt;). The trick is to realised that when using a pipe, the dot (&lt;code&gt;.&lt;/code&gt;) is a stand-in for the previous result. In practice this means that data.table operations can be chained thus:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(magrittr)
library(ggplot2)
temperature %&amp;gt;% 
   .[level == 1000] %&amp;gt;% 
   .[, mean(air), by = .(lat, lon)] %&amp;gt;% 
   .[lat &amp;gt; 0] %&amp;gt;% 
   ggplot(aes(lon, lat)) +
   geom_raster(aes(fill = V1), interpolate = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-07-06-why-i-love-data-table.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;and-more&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;…and more!&lt;/h1&gt;
&lt;p&gt;Of course this only scratches the surface of all the goodness of the data.table package. Inside the hood there are lots of optimisations to give it extra speed. It’s got special symbols that allow for more complex operations and optimised logical operators such as &lt;code&gt;%like%&lt;/code&gt; and &lt;code&gt;%between%&lt;/code&gt;. The &lt;code&gt;fread()&lt;/code&gt; and &lt;code&gt;fwrite()&lt;/code&gt; functions not only are insanely fast but also are packed with functionality. And so on…&lt;/p&gt;
&lt;p&gt;So why I love data.table? I love that allows me to work with big and small datasets with the same elegant syntax and with great performance without even thinking about it. It is a wonderful package and you should give it a try!&lt;/p&gt;
&lt;div id=&#34;now-i-love-data.table-too&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;“Now I love data.table too!”&lt;/h3&gt;
&lt;p&gt;If my love for data.table rubbed on you even a little bit, then a good summary of the basic functionality is the &lt;a href=&#34;https://github.com/Rdatatable/data.table/wiki/Getting-started&#34;&gt;Getting Started&lt;/a&gt; set of articles. If you already know a the basics and want to take your skills to the next level, the &lt;a href=&#34;http://brooksandrew.github.io/simpleblog/articles/advanced-data-table/&#34;&gt;Advanced tips and tricks with data.table&lt;/a&gt;, is chock full of advanced tricks.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using ecmwfr to measure global warming</title>
      <link>/en/2019/04/ecmwfr-global-warming/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/en/2019/04/ecmwfr-global-warming/</guid>
      <description>


&lt;p&gt;For my research I needed to download gridded weather data from ERA-Interim, which is a big dataset generated by the &lt;a href=&#34;https://www.ecmwf.int/&#34;&gt;ECMWF&lt;/a&gt;. Getting long term data through their website is &lt;strong&gt;very&lt;/strong&gt; time consuming and requires &lt;strong&gt;a lot&lt;/strong&gt; of clicks. Thankfuly, I came accross the nifty &lt;a href=&#34;https://github.com/khufkens/ecmwfr&#34;&gt;ecmwfr&lt;/a&gt; R package that allowed me to do it with ease. One of the great things about open source is that users can also be collaborators, so I made a few suggestions and offered some code.&lt;/p&gt;
&lt;p&gt;Now that a new version is on it’s way to CRAN, I wanted to show a quick example of what you can do with the package.&lt;/p&gt;
&lt;p&gt;To download data from the ECMWF servers you need to have an account. So if you’re following at home, you’ll need create one and add the API key to the ecmwfr keyring. This is all done interactivelly with this command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ecmwfr)

wf_set_key(service = &amp;quot;webapi&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will take you to the correct URL where you can get your key, and then sorts everything out to use it.&lt;/p&gt;
&lt;p&gt;Now, in order to get data from the ECMWF servers I need to have a valid request. Unfortunatelly, since it hosts a huge number of different datasets with different data streams and time resolution, building a valid request from scratch is rather complicated. The easiest way to work with it is going to their &lt;a href=&#34;https://apps.ecmwf.int/datasets/&#34;&gt;to the website&lt;/a&gt; and use their point and click interface to create a basic request for the dataset of interest. In my case, I will use monthly data from &lt;a href=&#34;https://apps.ecmwf.int/datasets/data/interim-full-daily/levtype=sfc/&#34;&gt;ERA Interim&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;../post/2019-04-19-como-cambio-el-tiempo-desde-que-naci_files/webapi-erainterim.png&#34; alt=&#34;ERA Interim request&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;ERA Interim request&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As you can see, there’s no way of retreiving every year in one request using the web interface. But a the bottom of the page there’s a link that says “View the MARS request”.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;../post/2019-04-19-como-cambio-el-tiempo-desde-que-naci_files/webapi-erainterim2.png&#34; alt=&#34;ERA Interim MARS&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;ERA Interim MARS&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Here, I get a valid request that I can modify slightly. In R, I converted this template into a list using the “MARS to list” RStudio addin (but you can do it manually). I added &lt;code&gt;format  = &amp;quot;netcdf&amp;quot;&lt;/code&gt; at the end to get the data as a NetCDF file.&lt;/p&gt;
&lt;p&gt;I then pass that list to the &lt;code&gt;wf_archetype()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ERAI_monthly &amp;lt;- wf_archetype(
   request = list(
      class   = &amp;quot;ei&amp;quot;,
      dataset = &amp;quot;interim&amp;quot;,
      date    = &amp;quot;19790101/19790201/19790301/19790401/19790501/19790601/19790701/19790801/19790901/19791001/19791101/19791201&amp;quot;,
      expver  = &amp;quot;1&amp;quot;,
      grid    = &amp;quot;0.75/0.75&amp;quot;,
      levtype = &amp;quot;sfc&amp;quot;,
      param   = &amp;quot;167.128&amp;quot;,
      stream  = &amp;quot;moda&amp;quot;,
      type    = &amp;quot;an&amp;quot;,
      target  = &amp;quot;output&amp;quot;,
      format  = &amp;quot;netcdf&amp;quot;),
   dynamic_fields = c(&amp;quot;date&amp;quot;, &amp;quot;grid&amp;quot;, &amp;quot;target&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now &lt;code&gt;ERAI_montly&lt;/code&gt; is a function with arguments “date”, “grid” and “target”. The reason I don’t just change the list willi nilli is that I want to be sure to always get a valid request pointing to the ERA Interim dataset. For this short example is probably overkill, but it’s usefull in a bigger project with multiple data requests.&lt;/p&gt;
&lt;p&gt;As you can see, the MARS format for dates can be rather long to type, so I’ll create a custom function to make this easier:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;format_dates &amp;lt;- function(dates) {
   dates &amp;lt;- as.Date(dates)
   paste0(lubridate::year(dates),
          formatC(lubridate::month(dates), width = 2, flag = &amp;quot;0&amp;quot;),
          formatC(lubridate::day(dates), width = 2, flag = &amp;quot;0&amp;quot;),
          collapse = &amp;quot;/&amp;quot;)
}

format_dates(c(&amp;quot;2018-01-01&amp;quot;, &amp;quot;2018-02-01&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;20180101/20180201&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’m ready to downlaod data! I was bown in august 1988, so I will be looking at how the month of august changed since that year. I’m also not terribly interested in local changes, so I’ll use a 3° by 3° resolution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dates &amp;lt;- seq.Date(as.Date(&amp;quot;1988-08-01&amp;quot;), as.Date(&amp;quot;2018-08-01&amp;quot;), &amp;quot;1 year&amp;quot;)

my_request &amp;lt;- ERAI_monthly(date = format_dates(dates), 
                           grid = &amp;quot;3/3&amp;quot;,
                           target = &amp;quot;august_monthly.nc&amp;quot;)
str(my_request)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 11
##  $ class  : chr &amp;quot;ei&amp;quot;
##  $ dataset: chr &amp;quot;interim&amp;quot;
##  $ date   : chr &amp;quot;19880801/19890801/19900801/19910801/19920801/19930801/19940801/19950801/19960801/19970801/19980801/19990801/200&amp;quot;| __truncated__
##  $ expver : chr &amp;quot;1&amp;quot;
##  $ grid   : chr &amp;quot;3/3&amp;quot;
##  $ levtype: chr &amp;quot;sfc&amp;quot;
##  $ param  : chr &amp;quot;167.128&amp;quot;
##  $ stream : chr &amp;quot;moda&amp;quot;
##  $ type   : chr &amp;quot;an&amp;quot;
##  $ target : chr &amp;quot;august_monthly.nc&amp;quot;
##  $ format : chr &amp;quot;netcdf&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now, &lt;code&gt;wf_request()&lt;/code&gt; to download the data. This will take some. Not because I’m downloading a huge file (is not, about 455kb) but because the ECMWF has to process the request and collect the data. So if you’re following at home, you can go make some tea or, if you’re like me, mate. 🍵&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wf_request(request = my_request,
           user = &amp;quot;eliocampitelli@gmail.com&amp;quot;, 
           transfer = TRUE,
           path = &amp;quot;data&amp;quot;, 
           verbose = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that I have my data saved as “august_monthly.nc”, I’ll just need to load it and analyse it. I’ll be using my &lt;a href=&#34;https://eliocamp.github.io/metR/&#34;&gt;metR&lt;/a&gt; package for that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metR)
library(ggplot2)
library(data.table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;august_temp &amp;lt;- ReadNetCDF(&amp;quot;data/august_monthly.nc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First a quick look at the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(august_temp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;data.table&amp;#39; and &amp;#39;data.frame&amp;#39;:   226920 obs. of  4 variables:
##  $ longitude: int  0 3 6 9 12 15 18 21 24 27 ...
##  $ latitude : int  90 90 90 90 90 90 90 90 90 90 ...
##  $ t2m      : num  273 273 273 273 273 ...
##  $ time     : POSIXct, format: &amp;quot;1988-08-01&amp;quot; &amp;quot;1988-08-01&amp;quot; ...
##  - attr(*, &amp;quot;.internal.selfref&amp;quot;)=&amp;lt;externalptr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s a data frame with a value of &lt;code&gt;t2m&lt;/code&gt; for each longitude, latitude and time. The temperature is in Kelvin. Let’s take a look at one field.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# world map
world &amp;lt;- list(geom_path(data = map_data(&amp;quot;world2&amp;quot;), 
                        aes(long, lat, group = group), 
                        size = 0.2, color = &amp;quot;gray50&amp;quot;),
              coord_quickmap(),
              scale_x_longitude(),
              scale_y_latitude())

ggplot(august_temp[time == time[1]], aes(longitude, latitude)) +
   geom_contour_fill(aes(z = t2m - 273.15)) +
   world +
   scale_fill_divergent(&amp;quot;2m temperature (°C)&amp;quot;) +
   metR:::theme_field()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-04-19-como-cambio-el-tiempo-desde-que-naci.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The tropis are warmer than the poles, as it should be.&lt;/p&gt;
&lt;p&gt;After getting to know the data, I’ll compute the linear trend of temperature at each gridpoint. I’ll use a &lt;strong&gt;very crude&lt;/strong&gt; method to get the statistical signficance of the trend.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trends &amp;lt;- august_temp[, FitLm(year = year(time), t2m, se = TRUE), 
                      by = .(longitude, latitude)] 
trends[, p.value :=  pt(abs(estimate)/std.error, df, lower.tail = FALSE)]

ggplot(trends[term == &amp;quot;year&amp;quot;], aes(longitude, latitude)) +
   geom_contour_fill(aes(z = estimate*10), 
                     breaks = AnchorBreaks(0, 0.25, exclude = 0)) +
   stat_subset(aes(subset = p.value &amp;lt;= 0.01), 
               geom = &amp;quot;point&amp;quot;, size = 0.1, alpha = 0.5) +
   world +
   scale_fill_divergent(&amp;quot;2m temperature \ntrend (°C/decade)&amp;quot;) +
   metR:::theme_field() +
   labs(subtitle = &amp;quot;August mean temperature change 1988-2018&amp;quot;, 
        caption = &amp;quot;Data: ERA Interim&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-04-19-como-cambio-el-tiempo-desde-que-naci.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not surprisingly, the trend is positive almost everywhere, although not everywhere statistically significant (using this &lt;strong&gt;very crude&lt;/strong&gt; method). Of note, there hasn’t been much increase in august mean temperature where I live.&lt;/p&gt;
&lt;p&gt;I will construct a (&lt;strong&gt;crude&lt;/strong&gt;) global mean august temperature (“GMAT”) timeseries by averaging all gridpoint for each year (weighing by the cosine of latitude).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gmat &amp;lt;- august_temp[, .(t2m = weighted.mean(t2m, cos(latitude*pi/180))), 
                   by = year(time)]

ggplot(gmat, aes(year, t2m - 273.15)) +
   geom_line() +
   geom_smooth(method = &amp;quot;lm&amp;quot;) +
   scale_y_continuous(&amp;quot;Global august 2m temperature (°C)&amp;quot;) +
   hrbrthemes::theme_ipsum_rc()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../post/2019-04-19-como-cambio-el-tiempo-desde-que-naci.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, not surprisingly, global temperature is going up. Let’s compute the rate of increase&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trend &amp;lt;- lm(t2m ~ I(year/10), data = gmat)
summary(trend)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = t2m ~ I(year/10), data = gmat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.28121 -0.05954 -0.01535  0.06890  0.28129 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 255.78307    4.71318  54.270  &amp;lt; 2e-16 ***
## I(year/10)    0.16756    0.02353   7.121 7.77e-08 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.1172 on 29 degrees of freedom
## Multiple R-squared:  0.6362, Adjusted R-squared:  0.6236 
## F-statistic: 50.71 on 1 and 29 DF,  p-value: 7.772e-08&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The rate of 1.68 °C/decade is consistent with &lt;a href=&#34;https://www.ipcc.ch/site/assets/uploads/2018/02/AR5_SYR_FINAL_SPM.pdf&#34;&gt;estimates using better methods&lt;/a&gt;. 🔥&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statistical metamerism</title>
      <link>/en/2019/01/statistical-metamerism/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/en/2019/01/statistical-metamerism/</guid>
      <description>


&lt;div id=&#34;summary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/eliocamp/metamer&#34;&gt;metamer&lt;/a&gt; package implements &lt;span class=&#34;citation&#34;&gt;Matejka and Fitzmaurice (&lt;a href=&#34;#ref-Matejka2017&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; algorithm for generating datasets with distinct appearance but identical statistical properties. I propose to call them “metamers” as an analogy with the colorimetry concept.&lt;/p&gt;
&lt;div id=&#34;metamers-in-vision&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Metamers in vision&lt;/h2&gt;
&lt;p&gt;This is &lt;strong&gt;not&lt;/strong&gt; a prism separating white light into its component wavelengths. It is an &lt;em&gt;image&lt;/em&gt; of a prism separating white light into its component wavelengths.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:prism&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../images/Prism_flat_rainbow.jpg&#34; alt=&#34;C&#39;est ne pas un prisme.&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Fig. 1: C’est ne pas un prisme.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is not just a Magritte-style observation. The important distinction comes into play when you realise that the monitor you are looking at has just three LEDs that emit light in just three wavelengths (sort of). How can it still reproduce a full spectrum of light? It doesn’t. For each (approximately) monochromatic colour in that rainbow, your monitor is actually emitting an unique mixture of red, green and blue light that tricks your visual system (and mine) into seeing the colour associated with that wavelength.&lt;/p&gt;
&lt;p&gt;How that works is unreasonably complex and beyond what I can explain in this article (I do recommend this &lt;a href=&#34;http://jamie-wong.com/post/color/&#34;&gt;amazing article&lt;/a&gt;, though) but the core insight is that our eyes have only three colour receptors that are sensible to wide range of short (S), medium (M) and long (L) wavelengths. Any spectrum distribution that reaches our eyes is reduced to just three numbers: the excitation of the S, M and L receptors. Hence, any spectrum distribution that excites them in the same way will be perceived as the same colour, even if they are wildly different. In colorimetry this is known as &lt;em&gt;metamerism&lt;/em&gt; &lt;span class=&#34;citation&#34;&gt;(Hunt &lt;a href=&#34;#ref-Hunt2004-7&#34;&gt;2004&lt;/a&gt;)&lt;/span&gt;. The monochromatic yellow emitted by the prism looks to you identical as the red, green and blue mixture emitted by of your monitor even though their spectrum distribution is not even remotely similar. They are metamers.&lt;/p&gt;
&lt;p&gt;Coming up with metameric matches is the basis for colour reproduction in computer screens, printing and painting, but it also has a dark side. Two pigments can be metameric matches under certain light conditions but have very different colours when illuminated with another type light. This can be a problem, for example, when buying clothes in a store with artificial lighting and then wearing them outside.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;metamers-in-statistics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Metamers in statistics&lt;/h2&gt;
&lt;p&gt;Now let’s focus our attention on the famous Anscombe quartet&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:anscombe-plot&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../post/2018-12-18-metamerismo-estad%C3%ADstico.en_files/figure-html/anscombe-plot-1.png&#34; alt=&#34;Anscombe quartet&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Fig. 2: Anscombe quartet
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Even though they are very different datasets, the members of the quartet have the same mean and standard deviation of each variable as well as the correlation between the two &lt;span class=&#34;citation&#34;&gt;(Anscombe &lt;a href=&#34;#ref-Anscombe1973&#34;&gt;1973&lt;/a&gt;)&lt;/span&gt;. From the point of view of that statistical transformation, the four datasets look the same even though they are not even remotely similar. They are metamers.&lt;/p&gt;
&lt;p&gt;And exactly the same as metameric colour matches, statistical metamers reveal their differences when viewed under a new light. In this case, when plotted.&lt;/p&gt;
&lt;p&gt;The concept of “data with different graphs but same statistics” is still relevant, with multiple published papers describing methods for their creation &lt;span class=&#34;citation&#34;&gt;(e.g. Chatterjee and Firat &lt;a href=&#34;#ref-Chatterjee2007&#34;&gt;2007&lt;/a&gt;; Govindaraju and Haslett &lt;a href=&#34;#ref-Govindaraju2008&#34;&gt;2008&lt;/a&gt;; Haslett and Govindaraju &lt;a href=&#34;#ref-Haslett2009&#34;&gt;2009&lt;/a&gt;; Matejka and Fitzmaurice &lt;a href=&#34;#ref-Matejka2017&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;. In this post I will use the term “metamers” to refer to sets of datasets that have the same behaviour under some statistical transformation as an analogy with the colorimetry concept.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/eliocamp/metamer&#34;&gt;metamer&lt;/a&gt; package implements &lt;span class=&#34;citation&#34;&gt;Matejka and Fitzmaurice (&lt;a href=&#34;#ref-Matejka2017&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; algorithm to construct metamers. The main function, &lt;code&gt;metamerize()&lt;/code&gt;, generates metamers from an initial dataset and the statistical transformation that needs to be preserved. Optionally, it can take a function that will be minimised in each successive metamer.&lt;/p&gt;
&lt;p&gt;First, the function &lt;code&gt;delayed_with()&lt;/code&gt; is useful for defining the statistical transformation that need to be preserved. The four datasets in the Anscombe quartet share these properties up to three significant figures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metamer)

summ_fun &amp;lt;- delayed_with(mean_x = mean(x), 
                         mean_y = mean(y), 
                         sd_x = sd(x), 
                         sd_y = sd(y), 
                         cor_xy = cor(x, y))
summ_names &amp;lt;-  c(&amp;quot;$\\overline{x}$&amp;quot;, &amp;quot;$\\overline{y}$&amp;quot;, 
                 &amp;quot;$S_x$&amp;quot;,  &amp;quot;$S_y$&amp;quot;, &amp;quot;$r(x, y)$&amp;quot;)

anscombe[, as.list(signif(summ_fun(.SD), 3)), by = quartet] %&amp;gt;% 
   knitr::kable(col.names = c(&amp;quot;Quartet&amp;quot;, summ_names),
                escape = FALSE, 
                caption = &amp;quot;Statistical properties of the Anscombe quartet.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:anscombe-summ&#34;&gt;Tab. 1: &lt;/span&gt;Statistical properties of the Anscombe quartet.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Quartet&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\overline{x}\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\overline{y}\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(S_x\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(S_y\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(r(x, y)\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.817&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To find metamers “between” the first and second quartet, one can start from one and generate metamers that minimise the mean distance to the other. The &lt;code&gt;mean_dist_to()&lt;/code&gt; function is a handy utility for that case.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extracts the first quartet and removes the `quartet` column.
start_data &amp;lt;- subset(anscombe, quartet == 1)
start_data$quartet &amp;lt;- NULL

# Extracts the second quartet and removes the `quartet` column.
target &amp;lt;- subset(anscombe, quartet == 2)
target$quartet &amp;lt;- NULL

set.seed(42)  # for reproducibility
metamers &amp;lt;- metamerize(start_data, 
                       preserve = summ_fun,
                       minimize = mean_dist_to(target), 
                       signif = 3,
                       change = &amp;quot;y&amp;quot;,
                       perturbation = 0.008, 
                       N = 30000)
print(metamers)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4690 metamers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The process generates 4689 metamers plus the original dataset. Selecting only 10 of them with &lt;code&gt;trim()&lt;/code&gt; and applying &lt;code&gt;summ_fun()&lt;/code&gt; to each one, it is confirmed that they have the same properties up to three significant figures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metamers %&amp;gt;% 
   trim(10) %&amp;gt;% 
   lapply(summ_fun) %&amp;gt;% 
   lapply(signif, digits = 3) %&amp;gt;% 
   do.call(rbind, .) %&amp;gt;% 
   knitr::kable(col.names = c(summ_names),
                caption = &amp;quot;Statistical properties of the generated metamers (rounded to three significant figures).&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:anscombe-metamers&#34;&gt;Tab. 2: &lt;/span&gt;Statistical properties of the generated metamers (rounded to three significant figures).&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\overline{x}\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\overline{y}\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(S_x\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(S_y\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(r(x, y)\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.816&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With &lt;a href=&#34;https://github.com/thomasp85/gganimate&#34;&gt;gganimate&lt;/a&gt; it is possible to visualise the transformation. Every intermediate step is a metamer of the original.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

metamers %&amp;gt;% 
   trim(100) %&amp;gt;% 
   as.data.frame() %&amp;gt;% 
   ggplot(aes(x, y)) +
   geom_point() +
   transition_manual(.metamer)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:anscombe-animate&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../post/2018-12-18-metamerismo-estad%C3%ADstico.en_files/figure-html/anscombe-animate-1.gif&#34; alt=&#34;Metamorphosys of the first two quartets.&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Fig. 3: Metamorphosys of the first two quartets.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The discussion around statistical metamerism is usually framed as the importance of visualising data instead of relying on summary statistics. Anscombe created his quartet to rebut the idea that “numerical calculations are exact, but graphs are rough”. Now this is still the interpretation of the phenomenon:&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:tweet&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../images/datasaurus_tweet.png&#34; alt=&#34;Download the datasaurus. ([Tweet](https://twitter.com/albertocairo/status/770267777169035264))&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Fig. 4: Download the datasaurus. (&lt;a href=&#34;https://twitter.com/albertocairo/status/770267777169035264&#34;&gt;Tweet&lt;/a&gt;)
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;However, I believe there is a more fundamental principle at play. The problem with &lt;em&gt;summary statistics&lt;/em&gt; is the &lt;em&gt;summary&lt;/em&gt; part. In many cases, the role of statistics is to sum up data. To take a big set of observations that cannot be grasped in their entirety because the limitations of our comprehension, and condense them into a few numbers or properties that we can easily get. The problem is that what is gained in understanding is lost in information.&lt;/p&gt;
&lt;p&gt;For example, a complete earnings census is a huge amount of data, but as raw numbers they are impossible to understand. One can start by taking the average (first moment) to get some idea of the “typical” earning of a citizen. Of course, this single number hides a great deal of income inequality, so one can compute the standard deviation (second moment) to get an idea of the variability. It is very likely, though, that the distribution is not symmetrical, and one can use the skewness (third moment) to quantify that.&lt;/p&gt;
&lt;p&gt;With each subsequent moment one can get a richer picture of the underlying data. The limit is when one has the same amount of moments as the sample size. A single univariate sample of size N can be unequivocally described by its N first moments. This makes sense intuitively –why should you need more than N numbers to describe N numbers?– but it can be &lt;a href=&#34;https://math.stackexchange.com/questions/3033407/is-a-sample-of-size-n-uniquely-described-by-n-sample-moments&#34;&gt;demonstrated&lt;/a&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In other words, the transformation “first N moments” has no metamers for samples smaller than N, except for any permutation of the same sample (but see &lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;But this property is not exclusive to statistical moments. The same goes for the fourier transform, principal component analysis, factor analysis, clustering, etc….&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; The issue is not plots vs. numbers but “all the numbers” vs. “just some numbers”. The big advantage of plots is that they can show an enormous amount of numbers efficiently and intuitively, in addition allowing to see a &lt;em&gt;gestalt&lt;/em&gt; that is impossible to get by just looking at series of numbers.&lt;/p&gt;
&lt;p&gt;With this in mind, it is possible to predict when it will be easy to find metamers and in which cases it is a mathematical impossibility. For example, it is impossible to find metamers of a sample of size 10 that preserves 10 moments.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42) 
start_data &amp;lt;- data.frame(x = rnorm(10))

metamerize(start_data, 
           moments_n(1:10),
           signif = 3,
           perturbation = 0.05,
           N = 30000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1 metamers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But it is possible to find metamers that preserve just two.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42) 
metamerize(start_data, 
           moments_n(1:2), 
           signif = 3,
           perturbation = 0.01,
           N = 30000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 310 metamers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Boxplots try to represent a sample with about 5 numbers. Hence, it is expected to have metamerism for samples with &lt;span class=&#34;math inline&#34;&gt;\(N&amp;gt;5\)&lt;/span&gt;. A density estimation using parametric methods, on the other hand, can be evaluated at potentially infinite points even for small samples. The possibility of metamerism in this case depends on the “resolution” with which the curve is described. If it is rendered with fewer points than the sample size, then it will metamerise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coarse_density &amp;lt;- function(data) {
   density(data$x, n = 16)$y
}
set.seed(42) 
metamerize(data.frame(x = rnorm(100)),
           preserve = coarse_density,
           N = 5000,
           signif = 3,
           perturbation = 0.001)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 11 metamers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, if it is rendered with more points, it will not metamerise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;highdef_density &amp;lt;- function(data) {
   density(data$x, n = 200)$y
}
set.seed(42) 
metamerize(data.frame(x = rnorm(100)),
           preserve = highdef_density,
           N = 5000,
           signif = 3,
           perturbation = 0.001)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1 metamers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The general principle works, but it is not complete. Imagine a statistical transformation defined as the sample mean repeated N times. Even though it returns N numbers from a N-sized sample, it does not have more information than just the mean. Generating metamers is then trivial.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_n_times &amp;lt;- function(data) {
   rep(mean(data$x), length.out = length(data$x))
}
set.seed(42) 
metamerize(data.frame(x = rnorm(100)),
           preserve = mean_n_times,
           perturbation = 0.1, 
           N = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 43 metamers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This motivates to define the category of “effective” statistical transformations as transformation that can uniquely describe a univariate sample of size N with, at most, N numbers. Under this definition, “the first N moments” is effective, while “the first moment repeated N times” is no. At this point, this is pure speculation, so take it with a grain of salt.&lt;/p&gt;
&lt;p&gt;It is worth noticing that when searching for metamers empirically there is a need to set the numerical tolerance (with the argument &lt;code&gt;signif&lt;/code&gt;). Being pedantic, these are more like “semi-metamers” than true metamers. With a high enough tolerance it is possible to find (semi) metamers even when it should not be possible.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42) 
metamerize(data.frame(x = rnorm(3)),
                       moments_n(1:4), 
                       signif = 1, 
                       perturbation = 0.001, 
                       N = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1000 metamers&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;advanced-metamers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Advanced metamers&lt;/h2&gt;
&lt;p&gt;I would like to close with a showcase of some utilities in the metamer package. &lt;code&gt;draw_data()&lt;/code&gt; opens up a shiny interface to freehand draw datasets with an optional dataset as backdrop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;start_data &amp;lt;- subset(datasauRus::datasaurus_dozen, dataset == &amp;quot;dino&amp;quot;)
start_data$dataset &amp;lt;- NULL

smiley &amp;lt;- draw_data(start_data)
simley$.group &amp;lt;- NULL&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:draw-data&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../images/draw_data.png&#34; alt=&#34;`draw_data()` interface.&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Fig. 5: &lt;code&gt;draw_data()&lt;/code&gt; interface.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Moreover, &lt;code&gt;metamerize()&lt;/code&gt; can be piped, saving the parameters of each call (except &lt;code&gt;N&lt;/code&gt; and &lt;code&gt;trim&lt;/code&gt;). This way one can perform sequences.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- subset(datasauRus::datasaurus_dozen, dataset == &amp;quot;x_shape&amp;quot;)
X$dataset &amp;lt;- NULL

star &amp;lt;- subset(datasauRus::datasaurus_dozen, dataset == &amp;quot;star&amp;quot;)
star$dataset &amp;lt;- NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metamers &amp;lt;- metamerize(start_data, 
                       preserve = delayed_with(mean(x), mean(y), cor(x, y)),
                       minimize = mean_dist_to(smiley), 
                       perturbation = 0.08,
                       N = 30000,
                       trim = 150) %&amp;gt;% 
   metamerize(minimize = NULL, 
              N = 3000, trim = 10) %&amp;gt;% 
   metamerize(minimize = mean_dist_to(X), 
              N = 30000, trim = 150) %&amp;gt;% 
   metamerize(minimize = NULL, 
              N = 3000, trim = 10) %&amp;gt;% 
   metamerize(minimize = mean_dist_to(star), 
              N = 30000, trim = 150) %&amp;gt;%
   metamerize(minimize = NULL, 
              N = 3000, trim = 10) %&amp;gt;% 
   metamerize(minimize = mean_dist_to(start_data),
              N = 30000, trim = 150)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This metamers show the datasaurus metamorphosing into different figures, always preserving the same statistical properties. This replicates &lt;a href=&#34;https://www.autodeskresearch.com/publications/samestats&#34;&gt;Justin Matejka’s y George Fitzmaurice’s animation&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metamers %&amp;gt;% 
   as.data.frame() %&amp;gt;% 
   ggplot(aes(x, y)) +
   geom_point() +
   transition_manual(.metamer)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:metamer-chain-anim&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../post/2018-12-18-metamerismo-estad%C3%ADstico.en_files/figure-html/metamer-chain-anim-1.gif&#34; alt=&#34;Datasaurus metamorphisis.&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Fig. 6: Datasaurus metamorphisis.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Anscombe1973&#34;&gt;
&lt;p&gt;Anscombe, F J. 1973. “Graphs in Statistical Analysis.” &lt;em&gt;The American Statistician&lt;/em&gt; 27 (1): 17–21. &lt;a href=&#34;https://doi.org/10.1007/978-3-540-71915-1_35&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1007/978-3-540-71915-1_35&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Chatterjee2007&#34;&gt;
&lt;p&gt;Chatterjee, Sangit, and Aykut Firat. 2007. “Generating data with identical statistics but dissimilar graphics: A follow up to the anscombe dataset.” &lt;em&gt;American Statistician&lt;/em&gt; 61 (3): 248–54. &lt;a href=&#34;https://doi.org/10.1198/000313007X220057&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1198/000313007X220057&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Govindaraju2008&#34;&gt;
&lt;p&gt;Govindaraju, K., and S. J. Haslett. 2008. “Illustration of regression towards the means.” &lt;em&gt;International Journal of Mathematical Education in Science and Technology&lt;/em&gt; 39 (4): 544–50. &lt;a href=&#34;https://doi.org/10.1080/00207390701753788&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1080/00207390701753788&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Haslett2009&#34;&gt;
&lt;p&gt;Haslett, S. J., and K. Govindaraju. 2009. “Cloning data: Generating datasets with exactly the same multiple linear regression fit.” &lt;em&gt;Australian and New Zealand Journal of Statistics&lt;/em&gt; 51 (4): 499–503. &lt;a href=&#34;https://doi.org/10.1111/j.1467-842X.2009.00560.x&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1111/j.1467-842X.2009.00560.x&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Hunt2004-7&#34;&gt;
&lt;p&gt;Hunt, R. W. G. 2004. “The Colour Triangle.” In &lt;em&gt;The Reproduction of Colour&lt;/em&gt;, 6th ed., 68–91. &lt;a href=&#34;https://doi.org/10.1002/0470024275&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1002/0470024275&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Matejka2017&#34;&gt;
&lt;p&gt;Matejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs.” &lt;em&gt;Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ’17&lt;/em&gt;, 1290–4. &lt;a href=&#34;https://doi.org/10.1145/3025453.3025912&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1145/3025453.3025912&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Technically, the solution is unique up to any permutation. This is not an accident. If the order matters, then it is a case of bivariate samples (each “datum” is actually a pair of values (x; y)). Intuition tells that besides the moment of each variable, the joint moments (covariance and such) are needed. So it seems plausible that in this case the matrix &lt;span class=&#34;math inline&#34;&gt;\(A^{N\times N}\)&lt;/span&gt;, where the element in the ith row and jth column is &lt;span class=&#34;math inline&#34;&gt;\(x^iy^j\)&lt;/span&gt; would be needed; which implies the need of &lt;span class=&#34;math inline&#34;&gt;\(N^2 -1\)&lt;/span&gt; moments.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;The fourier transform case is interesting because it describes an &lt;em&gt;ordered&lt;/em&gt; sample of size &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; with two ordered series of &lt;span class=&#34;math inline&#34;&gt;\(N/2\)&lt;/span&gt; numbers (one real and one imaginary) which sum up to &lt;span class=&#34;math inline&#34;&gt;\(2N\)&lt;/span&gt; numbers (the two series plus their respective order). This is much less than the assumed &lt;span class=&#34;math inline&#34;&gt;\(N^1-1\)&lt;/span&gt; needed in general. I suspect that this is because for this to happen, a regularly sampled series is needed. With this restriction, the fourier transform can “compress” the information.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multiple color (and fill) scales with ggplot2</title>
      <link>/en/2018/09/multiple-color-fill-scales-ggplot2/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/en/2018/09/multiple-color-fill-scales-ggplot2/</guid>
      <description>

&lt;p&gt;tl;dr: The functionality shown in this post is now on the &lt;a href=&#34;https://github.com/eliocamp/ggnewscale&#34;&gt;&lt;code&gt;ggnewscale&lt;/code&gt;&lt;/a&gt; package! 📦. You can find the original code &lt;a href=&#34;https://gist.github.com/eliocamp/eabafab2825779b88905954d84c82b32&#34;&gt;in this gist&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A somewhat common annoyance for some &lt;code&gt;ggplot2&lt;/code&gt; users is the lack of support for multiple colour and fill scales. Perusing StackOverflow you can find many questions relating to this issue:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/search?q=ggplot2+two+color+scales&#34;&gt;&lt;img src=&#34;../images/ggplo2_twoscales_so_small.jpg&#34; alt=&#34;preguntas stack overflow&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, this deluge of questions is met with a shortage of conclusive answers, most of them being some variation of &amp;ldquo;you can&amp;rsquo;t, but here&amp;rsquo;s how to hack it or visualise the data differently&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Recently I came up with a way of tricking &lt;code&gt;ggplot2&lt;/code&gt; into displaying multiple scales. It relies on &lt;a href=&#34;https://github.com/tidyverse/ggplot2/pull/2555&#34;&gt;a recent addition&lt;/a&gt; by Claus Wilke that allows the usage of &amp;ldquo;non standard aesthetics&amp;rdquo; &amp;ndash;&lt;code&gt;scale_color_continuous(aesthetics = &amp;quot;fill&amp;quot;)&lt;/code&gt; sets a &lt;code&gt;fill&lt;/code&gt; scale&amp;ndash; and the use of &lt;code&gt;ggplot_add()&lt;/code&gt; that I learnt thanks to &lt;a href=&#34;https://yutani.rbind.io/post/2017-11-07-ggplot-add&#34;&gt;this post&lt;/a&gt; by Hiroaki Yutani.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s be serious for a moment and acknowledge that using multiple color scales is not for the faint of heart. There&amp;rsquo;s a very real risk of ending up with a plot with is at best confusing and at worst, misleading. But that doesn&amp;rsquo;t mean there are not situations that call for this kind of plot. Using very different scales allows you to condense more information in a single plot, letting you visualise more relationships between variables. In the Atmospheric Sciences, for example, plotting temperature and pressure in contour lines with different color scales is a common practice.&lt;/p&gt;

&lt;p&gt;But &lt;em&gt;res non verba&lt;/em&gt;; this is how it looks like in action (with an example taken from &lt;a href=&#34;https://stackoverflow.com/questions/16129876/ggplot2-multiple-scales-legends-per-aesthetic-revisited&#34;&gt;this&lt;/a&gt; StackOverlow question)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(pd[pd$score1 != 0,], aes(x=x, y=species)) +
   geom_tile(aes(fill  =score1)) +
   scale_fill_gradient2(&amp;quot;Score 1&amp;quot;, limits = c(0, 4), 
                        low = &amp;quot;#762A83&amp;quot;, mid = &amp;quot;white&amp;quot;, high = &amp;quot;#1B7837&amp;quot;) +
   
   new_scale(&amp;quot;fill&amp;quot;) +
   
   geom_tile(aes(fill = score2), data = subset(pd, score2 != 0)) +
   scale_fill_gradient2(&amp;quot;Score 2&amp;quot;, limits = c(0, 3), 
                        low = &amp;quot;#1B7837&amp;quot;, mid = &amp;quot;white&amp;quot;, high = &amp;quot;#762A83&amp;quot;) +
   
   geom_text(data=pd, aes(label = letters, color = factor(change))) +
   scale_color_manual(&amp;quot;Change&amp;quot;, values = c(&amp;quot;black&amp;quot;, &amp;quot;#F2A11F&amp;quot;), 
                      labels = c(&amp;quot;None&amp;quot;, &amp;quot;Some&amp;quot;)) +
   coord_fixed(ratio = 1.5, xlim=c(0.5,16.5), ylim=c(0.5, 3.5)) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-09-17-multiples-escalas-de-colores-en-ggplot2.en_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-it-works&#34;&gt;How it works&lt;/h2&gt;

&lt;p&gt;The code is a bit too long and tedious to show in this article, but you can find it on &lt;a href=&#34;https://gist.github.com/eliocamp/eabafab2825779b88905954d84c82b32&#34;&gt;this gist&lt;/a&gt;. Here are the important bits.&lt;/p&gt;

&lt;p&gt;First, the &lt;code&gt;new_scale()&lt;/code&gt; function does nothing.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;new_scale &amp;lt;- function(new_aes) {
   structure(ggplot2::standardise_aes_names(new_aes), class = &amp;quot;new_aes&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It merely returns an object of class &lt;code&gt;new_aes&lt;/code&gt; with a character vector with the &amp;ldquo;new&amp;rdquo; scales. All the magic is in the &lt;code&gt;+&lt;/code&gt; operator. &lt;code&gt;ggplot2&lt;/code&gt; objects are &amp;ldquo;summed&amp;rdquo; with &lt;code&gt;ggplot_add()&lt;/code&gt; function which allows to define the &amp;ldquo;add&amp;rdquo; operation for any arbitrary object to a ggplot. For the case of &lt;code&gt;new_aes&lt;/code&gt; object, this is what happens:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot_add.new_aes &amp;lt;- function(object, plot, object_name) {
   plot$layers &amp;lt;- lapply(plot$layers, bump_aes, new_aes = object)
   plot$scales$scales &amp;lt;- lapply(plot$scales$scales, bump_aes, new_aes = object)
   plot$labels &amp;lt;- bump_aes(plot$labels, new_aes = object)
   plot
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It modifies each layer, scale and label and renames the relevant aesthetic to something other than &amp;ldquo;fill&amp;rdquo; or &amp;ldquo;colour&amp;rdquo;. There&amp;rsquo;s also a bit of minimally invasive surgery to geoms so that they don&amp;rsquo;t reject the newly grafted aesthetic. Is somewhat ad-hoc, to be honest, and probably not very robuts, but it works!&lt;/p&gt;

&lt;p&gt;There are many other ways to implement this and I went through &lt;a href=&#34;https://twitter.com/d_olivaw/status/1040722632675610626&#34;&gt;some iterations&lt;/a&gt;. The current implementation is friendly and consistent with the main &lt;code&gt;ggplot2&lt;/code&gt; &amp;ldquo;adding&amp;rdquo; idea, but it has some limitations and annoyances that prevent me from being 100% on board with it. I would love to get some feedback from the community 🤞!&lt;/p&gt;

&lt;h2 id=&#34;a-more-real-ish-example&#34;&gt;A more real-ish example&lt;/h2&gt;

&lt;p&gt;Why is any of this useful to me, you say? As I wrote before, being able to plot temperature and pressure in the same map with two different scales is very neat.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(metR)
library(magrittr)
time &amp;lt;- &amp;quot;1998-01-01&amp;quot;
# Temperature and sea level pressure for January 1st 1998
atmos &amp;lt;- ReadNetCDF(&amp;quot;~/DATOS/NCEP Reanalysis/air.mon.mean.nc&amp;quot;, 
                    subset = list(level = 850, 
                                  time = time)) %&amp;gt;% 
   .[, slp:= ReadNetCDF(&amp;quot;~/DATOS/NCEP Reanalysis/slp.mon.mean.nc&amp;quot;, 
                        subset = list(time = time), out = &amp;quot;vector&amp;quot;)] %&amp;gt;% 
   .[, lon := ConvertLongitude(lon)]

ggplot(atmos, aes(lon, lat)) +
   geom_world() +
   geom_contour(aes(z = slp, color = ..level..), binwidth = 4) +
   scale_color_viridis_c(&amp;quot;Sea level pressure&amp;quot;) +
   
   new_scale_color() +   # same as `new_scale(&amp;quot;color&amp;quot;)`
   
   geom_contour(aes(z = air, color = ..level..), binwidth = 4) +
   scale_color_distiller(&amp;quot;Air Temperature&amp;quot;, palette = &amp;quot;Spectral&amp;quot;)  +
   
   scale_x_longitude(limits = c(-150, 0)) +
   scale_y_latitude(ticks = 15) +
   ggalt::coord_proj(&amp;quot;+proj=moll +lon_0=-75&amp;quot;, 
                     ylim = c(-60, 0), xlim = c(-150, 0))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-09-17-multiples-escalas-de-colores-en-ggplot2.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Visualising the relationship between pressure and temperature is very important for the analysis of the growth of atmospheric perturbations.&lt;/p&gt;

&lt;p&gt;Of course, with great power comes great responsibility 🕸. Mixing multiple scales for the same aesthetic should be done sparingly and only if absolutely necessary. First always ask yourself if the same information cannot be shown in a better way.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ggplot2&lt;/code&gt; doesn&amp;rsquo;t cease to amaze me. Is not only a very powerful package to construct any kind of complex plots in a stupidly simple way, but it&amp;rsquo;s also exceptionally extensible by allowing this kind of deep user customisation. ¡Long live the &lt;code&gt;ggplo2&lt;/code&gt; ✊!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wrapping around ggplot2 with ggperiodic</title>
      <link>/en/2018/08/periodic-data-ggplot2-ggperiodic/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/en/2018/08/periodic-data-ggplot2-ggperiodic/</guid>
      <description>

&lt;p&gt;As an atmospheric scientists, a lot of my research consists on plotting and looking at global fields of atmospheric variables like pressure, temperature and the like. Since our planet is a sphere (well, &lt;a href=&#34;https://chem.tufts.edu/answersinscience/relativityofwrong.htm&#34;&gt;almost&lt;/a&gt;), it is unbound and so longitude is a &lt;em&gt;periodic&lt;/em&gt; dimension. That is, to the right of 180°E you go back to 180°W. But ggplot2 and other plotting systems, for the most part, assume linear dimensions.&lt;/p&gt;

&lt;p&gt;To show why this is a problem, let us plot a fairly basic scalar field defined in a regular grid with 2.5° of resolution for the southern hemisphere.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data, aes(lon, lat)) +
   geom_contour_fill(aes(z = gh)) +
   map.SH +
   scale_fill_viridis_c(&amp;quot;Geopotential\nHeight&amp;quot;) +
   coord_polar()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-08-21-wrapping-around-ggplot2_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Did you spot it? The field is defined between 0° and 357.5°. Because 360° is the same as 0°, you would be double counting if you had a value at both extremes. But since ggplot2 only &amp;lsquo;sees&amp;rsquo; the data you feed to it, it fails to plot the implied data between 357.5° and 360°.&lt;/p&gt;

&lt;h2 id=&#34;defining-the-problem&#34;&gt;Defining the problem&lt;/h2&gt;

&lt;p&gt;The scope of the problem as I see it is much broader than global maps of atmospheric data.&lt;/p&gt;

&lt;p&gt;We have a periodic function defined at regular &lt;em&gt;or irregular&lt;/em&gt; locations inside one period. Since this finite number of locations actually define the infinite domain of the function, when we plot we want to &lt;em&gt;wrap&lt;/em&gt; these locations around any arbitrary domain we need. This should be fast and automatic.&lt;/p&gt;

&lt;p&gt;This translates, I think, to having two distinct domains. On the one hand there&amp;rsquo;s the &lt;em&gt;period&lt;/em&gt; defined by the sampled data, and on the other there&amp;rsquo;s the &lt;em&gt;range&lt;/em&gt; we want to &lt;em&gt;wrap&lt;/em&gt; this data around. The first is a property of the &lt;em&gt;data&lt;/em&gt;, the second one is a property of the &lt;em&gt;visualisation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Somewhere on the plotting process, then, &lt;code&gt;ggplot2&lt;/code&gt; must repeat the data so that it wraps it around the desired range.&lt;/p&gt;

&lt;h2 id=&#34;solving-the-problem&#34;&gt;Solving the problem&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/eliocamp/ggperiodic&#34;&gt;ggperiodic&lt;/a&gt; package embodies these ideas. First, we define the period of each of the periodic variables on our data. In this case, &lt;code&gt;lon&lt;/code&gt; is periodic between 0° and 306°&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggperiodic)
data &amp;lt;- periodic(data, lon = c(0, 360))
head(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##     lon lat level       gh       time
## 1:  0.0 -30   200 12333.66 2017-01-01
## 2:  2.5 -30   200 12333.17 2017-01-01
## 3:  5.0 -30   200 12335.23 2017-01-01
## 4:  7.5 -30   200 12339.44 2017-01-01
## 5: 10.0 -30   200 12344.92 2017-01-01
## 6: 12.5 -30   200 12351.60 2017-01-01
## lon = [0; 360]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now &lt;code&gt;data&lt;/code&gt; is of a new class of &amp;ldquo;periodic_df&amp;rdquo;, but so far the actual content of &lt;code&gt;data&lt;/code&gt; has remain unchanged. The magic comes on the second step 🌟. Now we can &lt;code&gt;wrap&lt;/code&gt; the data in any arbitrary range. For example, lets change longitude to be between -180° and 180°&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data180 &amp;lt;- wrap(data, lon = c(-180, 180))
head(data180)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##       lon lat level       gh       time
## 1: -180.0 -30   200 12311.90 2017-01-01
## 2: -177.5 -30   200 12310.48 2017-01-01
## 3: -175.0 -30   200 12311.84 2017-01-01
## 4: -172.5 -30   200 12316.52 2017-01-01
## 5: -170.0 -30   200 12324.02 2017-01-01
## 6: -167.5 -30   200 12333.00 2017-01-01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You &lt;em&gt;could&lt;/em&gt; do this manually every time you what to plot your data, but there&amp;rsquo;s a better way. When ggplot2 gets a &lt;code&gt;data&lt;/code&gt; argument, it doesn&amp;rsquo;t just pass it along. First, it feeds it to a function called &lt;code&gt;fortify()&lt;/code&gt;. ggperiodic implements &lt;code&gt;fortify.periodic_df()&lt;/code&gt; so that the wrapping can be performed automatically at plotting time.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data, aes(lon, lat)) +
   geom_contour_fill(aes(z = gh)) +
   map.SH +
   scale_fill_viridis_c(&amp;quot;Geopotential\nHeight&amp;quot;) +
   coord_polar()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-08-21-wrapping-around-ggplot2_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is completely automatic 🤖, robust to transformations and very friendly to the user. By default the data is wrapped around the same range as the period, but that can be changed using the same syntax as with &lt;code&gt;wrap()&lt;/code&gt;. For example, it could be useful to show three whole periods so that any 360° range could be seen with no interruptions.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data, aes(lon, lat), lon = c(0, 360)*3) +
   geom_contour_fill(aes(z = gh)) +
   scale_fill_viridis_c(&amp;quot;Geopotential\nHeight&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-08-21-wrapping-around-ggplot2_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since ggplot2 also uses &lt;code&gt;fortify()&lt;/code&gt; for data passed to geoms, it also works there.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot() +
   geom_contour_fill(data = data, aes(lon, lat, z = gh), lon = c(-180, 180)) +
   map.SH2 +
   scale_fill_viridis_c(&amp;quot;Geopotential\nHeight&amp;quot;) +
   coord_polar()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown parameters: lon
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-08-21-wrapping-around-ggplot2_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this case works well but there are some limitations related to the somewhat ugly hack I had to use to pass the extra parameters to &lt;code&gt;fortify.periodic_df()&lt;/code&gt;. If used on a layer, the name of the periodic dimension must not be the same as any possible aesthetic or any other arguments passed to the geom, i.e. having &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;binwidth&lt;/code&gt; as the periodic dimension is verboten. Also there&amp;rsquo;s an annoying warning 😤.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve tried to make the periodic information &lt;em&gt;sticky&lt;/em&gt; (thanks to the &lt;a href=&#34;https://github.com/decisionpatterns/sticky&#34;&gt;sticky&lt;/a&gt; 📦) across data manipulations, but I&amp;rsquo;ve still haven&amp;rsquo;t tested thoroughly. And since I mostly use data.table, I&amp;rsquo;m not familiar enough with dplyr to do know the whole range of possible transformations. &lt;a href=&#34;https://github.com/eliocamp/ggperiodic/issues&#34;&gt;Issues&lt;/a&gt; are welcome!&lt;/p&gt;

&lt;p&gt;In any case, if or when you get tired of all this nonsense, you can just remove all periodicity information and go on with your life.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data &amp;lt;- unperiodic(data)
head(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##     lon lat level       gh       time
## 1:  0.0 -30   200 12333.66 2017-01-01
## 2:  2.5 -30   200 12333.17 2017-01-01
## 3:  5.0 -30   200 12335.23 2017-01-01
## 4:  7.5 -30   200 12339.44 2017-01-01
## 5: 10.0 -30   200 12344.92 2017-01-01
## 6: 12.5 -30   200 12351.60 2017-01-01
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>How to make a generic stat in ggplot2</title>
      <link>/en/2018/05/how-to-make-a-generic-stat-in-ggplot2/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/en/2018/05/how-to-make-a-generic-stat-in-ggplot2/</guid>
      <description>&lt;p&gt;For a while now I&amp;rsquo;ve been thinking that, yes, &lt;code&gt;ggplot2&lt;/code&gt; is awesome and offers a lot of &lt;code&gt;geoms&lt;/code&gt; and &lt;code&gt;stats&lt;/code&gt;, but it would be great if it could be extended with new user-generated &lt;code&gt;geoms&lt;/code&gt; and &lt;code&gt;stats&lt;/code&gt;. Then I learnt that &lt;code&gt;ggplot2&lt;/code&gt; actually has a pretty great extension system so I could create my own geoms I needed for my work or &lt;a href=&#34;https://twitter.com/d_olivaw/status/993669229810503680&#34;&gt;just for fun&lt;/a&gt;. But still, creating a geom from scratch is an involved process that doesn&amp;rsquo;t lend itself to simple transformations.&lt;/p&gt;

&lt;p&gt;Finally, I thought of a possible solution: create a &lt;em&gt;generic&lt;/em&gt; &lt;code&gt;stat&lt;/code&gt; &amp;ndash;a tabula rasa, if you will&amp;ndash; that can work on the data with any function. Natively &lt;code&gt;ggplot2&lt;/code&gt; offers &lt;code&gt;stat_summary()&lt;/code&gt;, but it&amp;rsquo;s only meant to be used with, well, summary statistics. What I wanted was something completely generic and this is my first try.&lt;/p&gt;

&lt;p&gt;Below is the code for &lt;code&gt;stat_rasa()&lt;/code&gt; (better name pending). It works just like any other &lt;code&gt;stat&lt;/code&gt; except that it works with any function that takes a data.frame and returns a transformed data.frame that can be interpreted by the chosen &lt;code&gt;geom&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# ggproto object
StatRasa &amp;lt;- ggplot2::ggproto(&amp;quot;StatRasa&amp;quot;, ggplot2::Stat,
  compute_group = function(data, scales, fun, fun.args) {
     # Change default arguments of the function to the 
     # values in fun.args
     args &amp;lt;- formals(fun)
     for (i in seq_along(fun.args)) {
        if (names(fun.args[i]) %in% names(fun.args)) {
           args[[names(fun.args[i])]] &amp;lt;- fun.args[[i]]
        } 
     }
     formals(fun) &amp;lt;- args
     
     # Apply function to data
     fun(data)
})

# stat function used in ggplot
stat_rasa &amp;lt;- function(mapping = NULL, data = NULL,
                      geom = &amp;quot;point&amp;quot;, 
                      position = &amp;quot;identity&amp;quot;,
                      fun = NULL,
                      ...,
                      show.legend = NA,
                      inherit.aes = TRUE) {
   # Check arguments 
   if (!is.function(fun)) stop(&amp;quot;fun must be a function&amp;quot;)
   
   # Pass dotted arguments to a list
   fun.args &amp;lt;- match.call(expand.dots = FALSE)$`...`
   
   ggplot2::layer(
      data = data,
      mapping = mapping,
      stat = StatRasa,
      geom = geom,
      position = position,
      show.legend = show.legend,
      inherit.aes = inherit.aes,
      check.aes = FALSE,
      check.param = FALSE,
      params = list(
         fun = fun, 
         fun.args = fun.args,
         na.rm = FALSE,
         ...
      )
   )
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For example, let&amp;rsquo;s say we want to quickly glance at detrended data. We then create a very simple function&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Detrend &amp;lt;- function(data, method = &amp;quot;lm&amp;quot;, span = 0.2) {
   if (method == &amp;quot;lm&amp;quot;) {
      data$y &amp;lt;- resid(lm(y ~ x, data = data))
   } else {
      data$y &amp;lt;- resid(loess(y ~ x, span = span, data = data))
   }
   as.data.frame(data)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and pass it to &lt;code&gt;stat_rasa()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
set.seed(42)
x &amp;lt;- seq(-1, 3, length.out = 30)
y &amp;lt;- x^2 + rnorm(30)*0.5
df &amp;lt;- data.frame(x = x, y = y)
ggplot(df, aes(x, y)) +
   geom_line() +
   stat_rasa(geom = &amp;quot;line&amp;quot;, fun = Detrend, method = &amp;quot;smooth&amp;quot;,
             color = &amp;quot;steelblue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-05-16-how-to-make-a-generic-stat-in-ggplot2.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can get better legibility and less typing by creating a wrapper function with a more descriptive name.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;stat_detrend &amp;lt;- function(...) {
   stat_rasa(fun = Detrend, ...)
}

ggplot(df, aes(x, y)) +
   geom_line() +
   stat_detrend(method = &amp;quot;lm&amp;quot;, color = &amp;quot;blue&amp;quot;, geom = &amp;quot;line&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-05-16-how-to-make-a-generic-stat-in-ggplot2.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Another case could be calculating contours from an irregular grid. Since &lt;code&gt;ggplot2::stat_contour()&lt;/code&gt; uses &lt;code&gt;grDevices::contourLines()&lt;/code&gt;, it needs values defined in a regular grid, but there&amp;rsquo;s a package called &lt;code&gt;contoureR&lt;/code&gt; that can compute contours from irregularly spaced observations. With &lt;code&gt;stat_rasa()&lt;/code&gt; we can integrate it with &lt;code&gt;ggplot2&lt;/code&gt; effortlessly by creating a small function and using &lt;code&gt;geom = &amp;quot;path&amp;quot;&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;IrregularContour &amp;lt;- function(data, breaks = scales::fullseq, 
                             binwidth = NULL,
                             bins = 10) {
   if (is.function(breaks)) {
      # If no parameters set, use pretty bins to calculate binwidth
      if (is.null(binwidth)) {
         binwidth &amp;lt;- diff(range(data$z)) / bins
      }
      
      breaks &amp;lt;- breaks(range(data$z), binwidth)
   }
   
   cl &amp;lt;- contoureR::getContourLines(x = data$x, y = data$y, z = data$z, 
                                    levels = breaks)
   
   if (length(cl) == 0) {
      warning(&amp;quot;Not possible to generate contour data&amp;quot;, call. = FALSE)
      return(data.frame())
   }
   cl &amp;lt;- cl[, 3:7]
   colnames(cl) &amp;lt;- c(&amp;quot;piece&amp;quot;, &amp;quot;group&amp;quot;, &amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;level&amp;quot;)
   return(cl)
}

stat_contour_irregular &amp;lt;- function(...) {
   stat_rasa(fun = IrregularContour, geom = &amp;quot;path&amp;quot;, ...)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(42)
df &amp;lt;- data.frame(x = rnorm(500),
                 y = rnorm(500))
df$z &amp;lt;- with(df, -x*y*exp(-x^2 - y^2))

ggplot(df, aes(x, y)) +
   geom_point(aes(color = z)) +
   stat_contour_irregular(aes(z = z, color = ..level..), bins = 15) +
   scale_color_viridis_c()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../post/2018-05-16-how-to-make-a-generic-stat-in-ggplot2.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And voilà.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s always things to improve. For example, the possibility of using a custom function to compute parameters that depend on the data, but I believe that as it stands covers 80% of simple applications. I should also use a better name, but naming things is hard work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to make a shaded relief in R</title>
      <link>/en/2018/02/how-to-make-shaded-relief-in-r/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/en/2018/02/how-to-make-shaded-relief-in-r/</guid>
      <description>&lt;p&gt;While trying to build a circular colour scale to plot angles and wind direction, I stumbled upon an easy way to make shaded reliefs in R. You known, when you look at cool maps of mountain areas where peaks and valleys are easily distinguishable from their shadows like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/shading.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What I accidentally discovered is that one way of approximating this look is by taking the directional derivatives of height and then plotting the cosine of its angle from the sun. After some further research I learned that this is actually done in cartography and is called &lt;a href=&#34;http://www.reliefshading.com/analytical/shading-methods/&#34;&gt;&lt;em&gt;aspect-based shading&lt;/em&gt;&lt;/a&gt;. I also learned that it&amp;rsquo;s not the best method, and I&amp;rsquo;m itching to try others. But for now, let&amp;rsquo;s keep things simple and &lt;a href=&#34;https://kkulma.github.io/2017-12-29-end-of-year-thoughts/&#34;&gt;get stuff actually done&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Just as an example, I will be using our old friend, the &lt;code&gt;volcano&lt;/code&gt; database. I will be also using &lt;code&gt;data.table&lt;/code&gt; syntax because that how I roll. Deal with it, &lt;code&gt;dplyr&lt;/code&gt; lovers 😎.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(data.table)
library(ggplot2)
data(volcano)
volcano &amp;lt;- as.data.table(melt(volcano, varnames = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;),
                              value.name = &amp;quot;h&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So then I take the derivative (this is a function I made in my personal package, but bear with me 🙏) and take the angle. The minus sign are there&amp;hellip; well, because it works &amp;ndash;I&amp;rsquo;m not sure about the exact maths here.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;volcano[, c(&amp;quot;dx&amp;quot;, &amp;quot;dy&amp;quot;) := metR::Derivate(h ~ x + y)]
volcano[, angle := atan2(-dy, -dx)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And with that, we can set the angle from which the Sun is shinning (usually from the top left) and with a little bit of code, we get an acceptable result.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sun.angle &amp;lt;- pi/3
ggplot(volcano, aes(x, y)) +
   geom_raster(aes(fill = cos(angle + sun.angle)), alpha = 1, interpolate = TRUE) +
   scale_fill_gradient2(low = &amp;quot;white&amp;quot;, high = &amp;quot;white&amp;quot;, mid = &amp;quot;gray20&amp;quot;, 
                        midpoint = sun.angle, guide = &amp;quot;none&amp;quot;) +
   coord_fixed() +
   theme_void() 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;2018-01-24-como-hacer-efecto-de-relieve-en-r.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Excellent! 💜&lt;/p&gt;

&lt;p&gt;But hey, don&amp;rsquo;t leave, there&amp;rsquo;s more. What if you want to use this &lt;em&gt;gorgeous&lt;/em&gt; shading as a background to map &lt;em&gt;other&lt;/em&gt; data? For example, let&amp;rsquo;s say you had surface temperature readings, or sulphur concentration data. Since our &lt;code&gt;scale_fill&lt;/code&gt; is being taken by the shading and &lt;code&gt;ggplot2&lt;/code&gt; does not allow for more than one scale per aesthetic, you couldn&amp;rsquo;t use another &lt;code&gt;geom_raster()&lt;/code&gt; to &amp;ldquo;paint&amp;rdquo; the data over this background.&lt;/p&gt;

&lt;p&gt;One solution is to take the plot we made above, extract the raster grob (GRaphical OBject) and put it over another plot as an annotation. This is akin to a plot transplant and &amp;ndash;just as organ transplants&amp;ndash; it&amp;rsquo;s an ugly mess that will become a forgotten practice of a less civilized age once we master 3D printing of organs. But it works and is the best we&amp;rsquo;ve got so far.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shade &amp;lt;- ggplot(volcano, aes(x, y)) +
   geom_raster(aes(fill = cos(angle + sun.angle)), alpha = 0.5, interpolate = TRUE) +
   scale_fill_gradient2(low = &amp;quot;white&amp;quot;, high = &amp;quot;white&amp;quot;, mid = &amp;quot;black&amp;quot;, 
                        midpoint = sun.angle, guide = &amp;quot;none&amp;quot;)

grob.shade &amp;lt;- ggplotGrob(shade)
grob.shade &amp;lt;- grob.shade$grobs[[6]]$children[[3]]

ggplot(volcano, aes(x, y)) +
   geom_raster(aes(fill = h), alpha = 1, interpolate = TRUE) +
   annotation_custom(grob = grob.shade) +
   scale_fill_viridis_c(guide = &amp;quot;none&amp;quot;, option = &amp;quot;A&amp;quot;) +
   coord_fixed() +
   theme_void() 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;2018-01-24-como-hacer-efecto-de-relieve-en-r.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Lucky for us, at least for this kind of plot transplant, there&amp;rsquo;s already a better way: just make a &lt;code&gt;geom&lt;/code&gt;! Once we are inside the guts of &lt;code&gt;ggplot2&lt;/code&gt; we are no longer bound by the tyranny of scales can do the craziest things. In this case, we use a modified version of &lt;code&gt;geom_tile()&lt;/code&gt; that performs all the calculations we need and builds the grayscale pattern (modifiable by the user via the &lt;code&gt;light&lt;/code&gt; and &lt;code&gt;dark&lt;/code&gt; aesthetics). It allows changing &lt;code&gt;sun.angle&lt;/code&gt; and decide whether to use &lt;code&gt;raster&lt;/code&gt; or &lt;code&gt;rect&lt;/code&gt; and whether to interpolate for a smoother finish. I give to you &lt;code&gt;geom_relief()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;geom_relief &amp;lt;- function(mapping = NULL, data = NULL,
                        stat = &amp;quot;identity&amp;quot;, position = &amp;quot;identity&amp;quot;,
                        ...,
                        raster = TRUE,
                        interpolate = TRUE,
                        na.rm = FALSE,
                        show.legend = NA,
                        inherit.aes = TRUE) {
   ggplot2::layer(
      data = data,
      mapping = mapping,
      stat = stat,
      geom = GeomRelief,
      position = position,
      show.legend = show.legend,
      inherit.aes = inherit.aes,
      params = list(
         raster = raster,
         interpolate = interpolate,
         na.rm = na.rm,
         ...
      )
   )
}

GeomRelief &amp;lt;- ggplot2::ggproto(&amp;quot;GeomRelief&amp;quot;, GeomTile,
  required_aes = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;),
  default_aes = ggplot2::aes(color = NA, fill = &amp;quot;grey35&amp;quot;, size = 0.5, linetype = 1,
                             alpha = NA, light = &amp;quot;white&amp;quot;, dark = &amp;quot;gray20&amp;quot;, sun.angle = 60),
  draw_panel = function(data, panel_scales, coord, raster, interpolate) {
     if (!coord$is_linear()) {
        stop(&amp;quot;non lineal coordinates are not implemented in GeomRelief&amp;quot;, call. = FALSE)
     } else {
        coords &amp;lt;- as.data.table(coord$transform(data, panel_scales))
        
        # This is the only part that&#39;s actually new. The rest is essentially 
        # copy-pasted from geom_raster and geom_tile
        coords[, sun.angle := (sun.angle + 90)*pi/180]
        coords[, dx := .derv(z, x), by = y]
        coords[, dy := .derv(z, y), by = x]
        coords[, shade := (cos(atan2(-dy, -dx) - sun.angle) + 1)/2]
        coords[is.na(shade), shade := 0]
        coords[, fill := .rgb2hex(colorRamp(c(dark, light), space = &amp;quot;Lab&amp;quot;)(shade)),
               by = .(dark, light)]
        
        # From geom_raster and geom_tile
        if (raster == TRUE){
           if (!inherits(coord, &amp;quot;CoordCartesian&amp;quot;)) {
              stop(&amp;quot;geom_raster only works with Cartesian coordinates&amp;quot;, call. = FALSE)
           }
           # Convert vector of data to raster
           x_pos &amp;lt;- as.integer((coords$x - min(coords$x)) / resolution(coords$x, FALSE))
           y_pos &amp;lt;- as.integer((coords$y - min(coords$y)) / resolution(coords$y, FALSE))
           
           nrow &amp;lt;- max(y_pos) + 1
           ncol &amp;lt;- max(x_pos) + 1
           
           raster &amp;lt;- matrix(NA_character_, nrow = nrow, ncol = ncol)
           raster[cbind(nrow - y_pos, x_pos + 1)] &amp;lt;- alpha(coords$fill, coords$alpha)
           
           # Figure out dimensions of raster on plot
           x_rng &amp;lt;- c(min(coords$xmin, na.rm = TRUE), max(coords$xmax, na.rm = TRUE))
           y_rng &amp;lt;- c(min(coords$ymin, na.rm = TRUE), max(coords$ymax, na.rm = TRUE))
           
           grid::rasterGrob(raster,
                            x = mean(x_rng), y = mean(y_rng),
                            width = diff(x_rng), height = diff(y_rng),
                            default.units = &amp;quot;native&amp;quot;, interpolate = interpolate
           )
           
        } else {
           ggplot2:::ggname(&amp;quot;geom_rect&amp;quot;, grid::rectGrob(
              coords$xmin, coords$ymax,
              width = coords$xmax - coords$xmin,
              height = coords$ymax - coords$ymin,
              default.units = &amp;quot;native&amp;quot;,
              just = c(&amp;quot;left&amp;quot;, &amp;quot;top&amp;quot;),
              gp = grid::gpar(
                 col = coords$fill,
                 fill = alpha(coords$fill, coords$alpha),
                 lwd = coords$size * .pt,
                 lty = coords$linetype,
                 lineend = &amp;quot;butt&amp;quot;
              )
           ))
           
        }
     }
  }
)

rect_to_poly &amp;lt;- function(xmin, xmax, ymin, ymax) {
   data.frame(
      y = c(ymax, ymax, ymin, ymin, ymax),
      x = c(xmin, xmax, xmax, xmin, xmin)
   )
}

.rgb2hex &amp;lt;- function(array) {
   rgb(array[, 1], array[, 2], array[, 3], maxColorValue = 255)
}


.derv &amp;lt;- function(x, y, order = 1, cyclical = FALSE, fill = FALSE) {
   N &amp;lt;- length(x)
   d &amp;lt;- y[2] - y[1]
   if (order &amp;gt;= 3) {
      dxdy &amp;lt;- .derv(.derv(x, y, order = 2, cyclical = cyclical, fill = fill),
                    y, order = order - 2, cyclical = cyclical, fill = fill)
   } else {
      if (order == 1) {
         dxdy &amp;lt;- (x[c(2:N, 1)] - x[c(N, 1:(N-1))])/(2*d)
      } else if (order == 2) {
         dxdy &amp;lt;- (x[c(2:N, 1)] + x[c(N, 1:(N-1))] - 2*x)/d^2
      }
      if (!cyclical) {
         if (!fill) {
            dxdy[c(1, N)] &amp;lt;- NA
         }
         if (fill) {
            dxdy[1] &amp;lt;- (-11/6*x[1] + 3*x[2] - 3/2*x[3] + 1/3*x[4])/d
            dxdy[N] &amp;lt;- (11/6*x[N] - 3*x[N-1] + 3/2*x[N-2] - 1/3*x[N-3])/d
         }
      }
      
   }
   return(dxdy)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s use it to show real topographic data from The Andes near the Aconcagua, courtesy of &lt;a href=&#34;https://www.ngdc.noaa.gov/mgg/global/&#34;&gt;NOAA&amp;rsquo;s ETOPO1&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;aconcagua &amp;lt;- metR::GetTopography(-70.0196223 - 3 + 360, -70.0196223 + 3 + 360,
                                 -32.6531782 + 2, -32.6531782 - 2, 
                                 resolution = 1/60)
aconcagua[, c(&amp;quot;light&amp;quot;, &amp;quot;dark&amp;quot;) := .(ifelse(h &amp;gt; 0, &amp;quot;white&amp;quot;, &amp;quot;slategray2&amp;quot;),
                                ifelse(h &amp;gt; 0, &amp;quot;gray20&amp;quot;, &amp;quot;midnightblue&amp;quot;))] 
ggplot(aconcagua, aes(lon, lat)) +
   geom_relief(aes(z = h, light = light, dark = dark), 
               raster = TRUE, interpolate = TRUE, sun.angle = 60) +
   coord_fixed(expand = FALSE) +
   theme_void()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;2018-01-24-como-hacer-efecto-de-relieve-en-r.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The result, if you ask me: delicious  👌&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>